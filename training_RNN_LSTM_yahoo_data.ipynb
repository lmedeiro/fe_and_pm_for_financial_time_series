{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the binary library cannot be imported. You cannot train maps, but you can load and analyze ones that you have already saved.\n",
      "The problem occurs because either compilation failed when you installed Somoclu or a path is missing from the dependencies when you are trying to import it. Please refer to the documentation to see your options.\n"
     ]
    }
   ],
   "source": [
    "from PipelineResources import * # This is where we have all of the resources that will be used in the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = pd.read_pickle('upm_yahoo.pckl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training, validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Test: Use a CNN Model to predict whether or not the next day will close above 1.5 %. \n",
    "The goal behind this exercise is to establish a baseline model and performance. In addition, it is also work out the way the data will be stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample size is: 4755\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = nasdaq.index.size\n",
    "print(\" Sample size is: {}\".format(number_of_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open_change',\n",
       " 'next_day_open_change',\n",
       " 'open_change_wrt_close',\n",
       " 'next_day_open_change_wrt_close',\n",
       " 'high_change',\n",
       " 'low_change',\n",
       " 'volume_change',\n",
       " 'high_low_range',\n",
       " 'close_change',\n",
       " 'high_low_range_with_ref_close',\n",
       " 'high_low_range_with_ref_open',\n",
       " 'next_day_open_change_wrt_high',\n",
       " 'next_day_open_change_wrt_low']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we just import the general dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of days per samples: 1\n",
      "(4751,)\n",
      "[0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "(4751, 13)\n",
      "(3563, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_state = 1\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = get_input_sets(nasdaq, chosen_features, chosen_label, x_test=False,\n",
    "                                                               number_of_days_per_sample=1)\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, y_train = double_class_rows(x_train, y_train, class_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075\n",
      "967\n",
      "(221,)\n",
      "(221, 13)\n",
      "3240\n",
      "2916\n",
      "(647,)\n",
      "(647, 13)\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = decrease_class_rows(x_val, y_val, class_number=0, percentage_cut=0.90)\n",
    "x_train, y_train = decrease_class_rows(x_train, y_train, class_number=0, percentage_cut=0.90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = MinMaxScaler(feature_range=(0,1))\n",
    "#scaler.fit(x_train)\n",
    "#x_train = scaler.transform(x_train)\n",
    "#x_val = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify dataset channels if desired\n",
    "The current approach is to add a channel with FFT information about the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647, 2, 13)\n",
      "(221, 2, 13)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, x_test = modify_dataset_channels(x_train, x_val, x_test=False, compute_fft=True, multi_channel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train[:,1,:]\n",
    "#x_train = x_train.reshape([x_train.shape[0], 1, x_train.shape[1]])\n",
    "#x_val = x_val[:,1,:]\n",
    "#x_val = x_val.reshape([x_val.shape[0], 1, x_val.shape[1]])\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_0(nn.Module):\n",
    "    def __init__(self, n_channels, n_features, n_hidden_d, n_classes,\n",
    "                lstm_layers=1, dropout=0):\n",
    "        super(LSTM_0, self).__init__()\n",
    "        self.name = 'LSTM_0'\n",
    "        if lstm_layers > 1:\n",
    "            self.lstm_0 = nn.LSTM(n_features, n_hidden_d, lstm_layers, dropout=dropout)\n",
    "            #self.lstm_0 = nn.GRU(n_features, n_hidden_d, lstm_layers, dropout=dropout)\n",
    "        else:\n",
    "            self.lstm_0 = nn.LSTM(n_features, n_hidden_d, lstm_layers)\n",
    "        self.fc0 = nn.Linear(n_hidden_d * n_channels, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #bp()\n",
    "        x = x.float()\n",
    "        lstm_out, (h,c) = self.lstm_0(x)\n",
    "        x = self.fc0(lstm_out.view(lstm_out.shape[0], lstm_out.shape[1] * lstm_out.shape[2]))\n",
    "        #bp()\n",
    "        x = F.softmax(x, dim=1)\n",
    "        #x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input tensor: torch.Size([647, 2, 13])\n",
      "loss: 0.6929499506950378\n",
      "The shapes seem to be ok.\n"
     ]
    }
   ],
   "source": [
    "model_name = LSTM_0.__name__\n",
    "device = torch.device('cuda:0')\n",
    "n_channels = x_train.shape[1]\n",
    "n_features = x_train.shape[2]\n",
    "n_hidden_d = 10\n",
    "n_classes = 2\n",
    "lstm_layers = 1\n",
    "dropout = 0.1\n",
    "net = LSTM_0(n_channels, n_features, n_hidden_d=10, n_classes=2,\n",
    "            lstm_layers = 1, dropout=dropout)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    #bp()\n",
    "    input_data = torch.tensor(x_train).float()\n",
    "    labels = torch.tensor(y_train).long()\n",
    "    input_data = input_data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    print('Shape of the input tensor:', input_data.shape)\n",
    "    y = net(input_data)\n",
    "    loss = criterion(y, labels)\n",
    "    print('loss: {}'.format(loss))\n",
    "    assert y.shape == torch.Size([y_train.shape[0], 2]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "print('The shapes seem to be ok.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    f1_train    train_loss     dur\n",
      "-------  ----------  ------------  ------\n",
      "      1      \u001b[36m0.6639\u001b[0m        \u001b[32m0.6945\u001b[0m  0.0331\n",
      "      2      0.6027        \u001b[32m0.6939\u001b[0m  0.0273\n",
      "      3      0.0243        \u001b[32m0.6935\u001b[0m  0.0270\n",
      "      4      0.0183        \u001b[32m0.6931\u001b[0m  0.0270\n",
      "      5      0.0737        \u001b[32m0.6929\u001b[0m  0.0269\n",
      "      6      0.1878        \u001b[32m0.6929\u001b[0m  0.0271\n",
      "      7      0.5178        \u001b[32m0.6928\u001b[0m  0.0285\n",
      "      8      0.6625        \u001b[32m0.6924\u001b[0m  0.0265\n",
      "      9      \u001b[36m0.6667\u001b[0m        \u001b[32m0.6924\u001b[0m  0.0270\n",
      "     10      \u001b[36m0.6680\u001b[0m        \u001b[32m0.6919\u001b[0m  0.0268\n",
      "     11      0.6660        0.6925  0.0261\n",
      "     12      0.6660        0.6923  0.0268\n",
      "     13      0.6653        \u001b[32m0.6916\u001b[0m  0.0265\n",
      "     14      0.6660        \u001b[32m0.6915\u001b[0m  0.0268\n",
      "     15      0.6588        \u001b[32m0.6910\u001b[0m  0.0269\n",
      "     16      0.6411        \u001b[32m0.6903\u001b[0m  0.0223\n",
      "     17      0.6316        \u001b[32m0.6899\u001b[0m  0.0243\n",
      "     18      0.6076        \u001b[32m0.6891\u001b[0m  0.0241\n",
      "     19      0.5601        \u001b[32m0.6885\u001b[0m  0.0276\n",
      "     20      0.5884        \u001b[32m0.6875\u001b[0m  0.0295\n",
      "     21      0.5805        \u001b[32m0.6871\u001b[0m  0.0275\n",
      "     22      0.6195        \u001b[32m0.6859\u001b[0m  0.0263\n",
      "     23      0.6578        0.6861  0.0219\n",
      "     24      0.6471        \u001b[32m0.6857\u001b[0m  0.0203\n",
      "     25      0.6239        \u001b[32m0.6831\u001b[0m  0.0215\n",
      "     26      0.5455        \u001b[32m0.6812\u001b[0m  0.0203\n",
      "     27      0.5209        \u001b[32m0.6802\u001b[0m  0.0212\n",
      "     28      0.4970        \u001b[32m0.6785\u001b[0m  0.0193\n",
      "     29      0.5523        \u001b[32m0.6775\u001b[0m  0.0214\n",
      "     30      0.6072        \u001b[32m0.6772\u001b[0m  0.0190\n",
      "     31      0.6124        \u001b[32m0.6756\u001b[0m  0.0234\n",
      "     32      0.6016        \u001b[32m0.6736\u001b[0m  0.0244\n",
      "     33      0.6061        \u001b[32m0.6733\u001b[0m  0.0238\n",
      "     34      0.6240        \u001b[32m0.6700\u001b[0m  0.0261\n",
      "     35      0.5635        \u001b[32m0.6682\u001b[0m  0.0216\n",
      "     36      0.5461        \u001b[32m0.6663\u001b[0m  0.0213\n",
      "     37      0.5664        \u001b[32m0.6652\u001b[0m  0.0292\n",
      "     38      0.5970        \u001b[32m0.6617\u001b[0m  0.0337\n",
      "     39      0.5768        \u001b[32m0.6601\u001b[0m  0.0311\n",
      "     40      0.5362        \u001b[32m0.6592\u001b[0m  0.0279\n",
      "     41      0.5811        \u001b[32m0.6565\u001b[0m  0.0286\n",
      "     42      0.6034        \u001b[32m0.6535\u001b[0m  0.0284\n",
      "     43      0.6100        \u001b[32m0.6502\u001b[0m  0.0272\n",
      "     44      0.5755        0.6506  0.0297\n",
      "     45      0.5745        \u001b[32m0.6473\u001b[0m  0.0309\n",
      "     46      0.5909        \u001b[32m0.6440\u001b[0m  0.0242\n",
      "     47      0.5861        \u001b[32m0.6424\u001b[0m  0.0235\n",
      "     48      0.6122        \u001b[32m0.6389\u001b[0m  0.0272\n",
      "     49      0.6166        \u001b[32m0.6375\u001b[0m  0.0309\n",
      "     50      0.6056        \u001b[32m0.6341\u001b[0m  0.0299\n",
      "     51      0.5838        0.6348  0.0291\n",
      "     52      0.5746        \u001b[32m0.6320\u001b[0m  0.0237\n",
      "     53      0.6062        \u001b[32m0.6315\u001b[0m  0.0245\n",
      "     54      0.5979        \u001b[32m0.6298\u001b[0m  0.0249\n",
      "     55      0.5876        \u001b[32m0.6295\u001b[0m  0.0236\n",
      "     56      0.6000        \u001b[32m0.6269\u001b[0m  0.0246\n",
      "     57      0.6218        \u001b[32m0.6235\u001b[0m  0.0239\n",
      "     58      0.5926        0.6257  0.0213\n",
      "     59      0.6180        \u001b[32m0.6225\u001b[0m  0.0223\n",
      "     60      0.6101        \u001b[32m0.6197\u001b[0m  0.0218\n",
      "     61      0.6025        0.6197  0.0226\n",
      "     62      0.6388        \u001b[32m0.6168\u001b[0m  0.0234\n",
      "     63      0.6274        \u001b[32m0.6143\u001b[0m  0.0253\n",
      "     64      0.6120        0.6155  0.0232\n",
      "     65      0.6591        0.6152  0.0221\n",
      "     66      \u001b[36m0.6834\u001b[0m        0.6172  0.0248\n",
      "     67      0.6623        \u001b[32m0.6104\u001b[0m  0.0265\n",
      "     68      0.5853        0.6150  0.0265\n",
      "     69      0.6046        0.6148  0.0246\n",
      "     70      0.6443        \u001b[32m0.6101\u001b[0m  0.0256\n",
      "     71      0.6733        \u001b[32m0.6079\u001b[0m  0.0272\n",
      "     72      0.6288        \u001b[32m0.6077\u001b[0m  0.0272\n",
      "     73      0.6325        \u001b[32m0.6048\u001b[0m  0.0210\n",
      "     74      0.6549        \u001b[32m0.6045\u001b[0m  0.0216\n",
      "     75      0.6528        0.6047  0.0210\n",
      "     76      0.6632        \u001b[32m0.6043\u001b[0m  0.0203\n",
      "     77      0.6550        \u001b[32m0.6026\u001b[0m  0.0214\n",
      "     78      0.6465        0.6038  0.0205\n",
      "     79      0.6621        \u001b[32m0.6010\u001b[0m  0.0227\n",
      "     80      \u001b[36m0.6845\u001b[0m        0.6012  0.0252\n",
      "     81      \u001b[36m0.6979\u001b[0m        0.6033  0.0269\n",
      "     82      0.6805        \u001b[32m0.5991\u001b[0m  0.0266\n",
      "     83      0.6594        0.6010  0.0244\n",
      "     84      0.6486        0.5992  0.0226\n",
      "     85      0.6777        \u001b[32m0.5981\u001b[0m  0.0235\n",
      "     86      0.6754        \u001b[32m0.5977\u001b[0m  0.0259\n",
      "     87      0.6609        \u001b[32m0.5962\u001b[0m  0.0230\n",
      "     88      0.6357        0.5994  0.0223\n",
      "     89      0.6575        0.5968  0.0216\n",
      "     90      0.6863        \u001b[32m0.5950\u001b[0m  0.0223\n",
      "     91      0.6779        \u001b[32m0.5941\u001b[0m  0.0213\n",
      "     92      0.6833        \u001b[32m0.5929\u001b[0m  0.0252\n",
      "     93      \u001b[36m0.7083\u001b[0m        0.5949  0.0262\n",
      "     94      \u001b[36m0.7102\u001b[0m        0.5956  0.0273\n",
      "     95      0.6976        \u001b[32m0.5928\u001b[0m  0.0214\n",
      "     96      0.6801        \u001b[32m0.5919\u001b[0m  0.0253\n",
      "     97      0.6608        \u001b[32m0.5907\u001b[0m  0.0199\n",
      "     98      0.6678        0.5941  0.0227\n",
      "     99      0.6576        \u001b[32m0.5898\u001b[0m  0.0263\n",
      "    100      0.6712        0.5933  0.0273\n",
      "    101      0.6974        0.5919  0.0259\n",
      "    102      0.7091        0.5913  0.0303\n",
      "    103      0.6815        0.5908  0.0304\n",
      "    104      0.6573        0.5910  0.0290\n",
      "    105      0.6869        \u001b[32m0.5886\u001b[0m  0.0256\n",
      "    106      0.7013        0.5891  0.0231\n",
      "    107      0.6857        \u001b[32m0.5872\u001b[0m  0.0242\n",
      "    108      0.6792        0.5918  0.0234\n",
      "    109      0.7053        0.5894  0.0229\n",
      "    110      0.6916        0.5873  0.0253\n",
      "    111      0.6872        \u001b[32m0.5869\u001b[0m  0.0247\n",
      "    112      0.6781        0.5885  0.0271\n",
      "    113      0.6900        0.5882  0.0272\n",
      "    114      0.7070        0.5869  0.0283\n",
      "    115      0.6974        \u001b[32m0.5860\u001b[0m  0.0255\n",
      "    116      0.7018        0.5862  0.0276\n",
      "    117      0.7062        \u001b[32m0.5857\u001b[0m  0.0267\n",
      "    118      0.6977        0.5870  0.0291\n",
      "    119      0.6678        0.5881  0.0300\n",
      "    120      0.6782        0.5873  0.0305\n",
      "    121      0.6897        \u001b[32m0.5842\u001b[0m  0.0304\n",
      "    122      \u001b[36m0.7209\u001b[0m        0.5868  0.0222\n",
      "    123      0.7100        0.5864  0.0230\n",
      "    124      0.6835        0.5859  0.0231\n",
      "    125      0.6997        \u001b[32m0.5829\u001b[0m  0.0233\n",
      "    126      0.7200        0.5847  0.0224\n",
      "    127      0.7045        0.5836  0.0248\n",
      "    128      0.6919        0.5852  0.0296\n",
      "    129      0.6947        0.5837  0.0293\n",
      "    130      0.7070        0.5871  0.0297\n",
      "    131      0.7030        0.5838  0.0303\n",
      "    132      0.7007        0.5843  0.0267\n",
      "    133      0.7086        0.5833  0.0277\n",
      "    134      0.7152        0.5836  0.0277\n",
      "    135      \u001b[36m0.7234\u001b[0m        0.5846  0.0272\n",
      "    136      0.7118        \u001b[32m0.5818\u001b[0m  0.0264\n",
      "    137      0.6713        0.5870  0.0278\n",
      "    138      0.7007        0.5848  0.0307\n",
      "    139      0.7191        0.5851  0.0291\n",
      "    140      0.7055        0.5838  0.0309\n",
      "    141      0.6921        0.5825  0.0301\n",
      "    142      0.6866        0.5836  0.0235\n",
      "    143      0.6995        0.5819  0.0222\n",
      "    144      0.7094        \u001b[32m0.5809\u001b[0m  0.0236\n",
      "    145      0.7078        \u001b[32m0.5803\u001b[0m  0.0243\n",
      "    146      0.6897        0.5829  0.0242\n",
      "    147      0.6987        0.5814  0.0254\n",
      "    148      0.6971        0.5833  0.0230\n",
      "    149      0.7027        0.5833  0.0232\n",
      "    150      0.7065        \u001b[32m0.5797\u001b[0m  0.0264\n",
      "    151      0.6678        0.5850  0.0277\n",
      "    152      0.6894        0.5861  0.0272\n",
      "    153      0.7118        0.5848  0.0241\n",
      "    154      0.7061        0.5809  0.0330\n",
      "    155      0.6995        0.5828  0.0289\n",
      "    156      0.7096        0.5811  0.0293\n",
      "    157      0.7161        0.5810  0.0265\n",
      "    158      0.6998        0.5814  0.0270\n",
      "    159      0.6747        0.5822  0.0245\n",
      "    160      0.6935        0.5809  0.0240\n",
      "    161      0.7098        0.5804  0.0256\n",
      "    162      0.7224        0.5807  0.0249\n",
      "    163      0.6901        0.5829  0.0313\n",
      "    164      0.6769        0.5840  0.0280\n",
      "    165      0.7017        0.5810  0.0304\n",
      "    166      0.6935        0.5824  0.0272\n",
      "    167      0.7080        \u001b[32m0.5793\u001b[0m  0.0282\n",
      "    168      0.7190        0.5813  0.0302\n",
      "    169      0.7181        \u001b[32m0.5788\u001b[0m  0.0303\n",
      "    170      0.6948        0.5799  0.0295\n",
      "    171      0.6893        0.5831  0.0267\n",
      "    172      0.7130        0.5845  0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    173      \u001b[36m0.7284\u001b[0m        0.5810  0.0305\n",
      "    174      0.7041        \u001b[32m0.5786\u001b[0m  0.0298\n",
      "    175      0.6620        0.5859  0.0232\n",
      "    176      0.6848        0.5787  0.0226\n",
      "    177      0.7085        0.5793  0.0287\n",
      "    178      0.7179        0.5796  0.0279\n",
      "    179      0.7134        0.5793  0.0295\n",
      "    180      0.7093        \u001b[32m0.5779\u001b[0m  0.0291\n",
      "    181      0.7044        0.5802  0.0291\n",
      "    182      0.7083        0.5798  0.0297\n",
      "    183      0.7273        0.5794  0.0274\n",
      "    184      0.7116        0.5800  0.0292\n",
      "    185      0.6548        0.5856  0.0271\n",
      "    186      0.6607        0.5851  0.0287\n",
      "    187      0.7150        \u001b[32m0.5752\u001b[0m  0.0293\n",
      "    188      0.7221        0.5848  0.0297\n",
      "    189      \u001b[36m0.7300\u001b[0m        0.5811  0.0293\n",
      "    190      0.7040        0.5791  0.0258\n",
      "    191      0.7013        0.5774  0.0245\n",
      "    192      0.7131        0.5795  0.0255\n",
      "    193      0.7111        0.5816  0.0232\n",
      "    194      0.7267        0.5766  0.0210\n",
      "    195      0.7132        0.5784  0.0215\n",
      "    196      0.7057        0.5770  0.0244\n",
      "    197      0.7072        0.5805  0.0234\n",
      "    198      0.7085        0.5782  0.0246\n",
      "    199      0.7134        0.5755  0.0231\n",
      "    200      0.7125        0.5770  0.0203\n",
      "    201      0.7161        0.5780  0.0228\n",
      "    202      0.7187        0.5784  0.0207\n",
      "    203      0.7210        0.5764  0.0225\n",
      "    204      0.7053        0.5789  0.0210\n",
      "    205      0.6967        0.5775  0.0241\n",
      "    206      0.6992        0.5779  0.0242\n",
      "    207      0.7122        0.5778  0.0211\n",
      "    208      0.7210        0.5770  0.0232\n",
      "    209      0.7185        0.5781  0.0226\n",
      "    210      0.7074        0.5787  0.0263\n",
      "    211      0.7049        0.5767  0.0269\n",
      "    212      0.7066        0.5758  0.0248\n",
      "    213      0.7241        0.5775  0.0235\n",
      "    214      0.7202        0.5771  0.0244\n",
      "    215      0.7138        0.5773  0.0249\n",
      "    216      0.7002        0.5778  0.0253\n",
      "    217      0.7182        0.5753  0.0295\n",
      "    218      0.7214        0.5799  0.0292\n",
      "    219      0.7295        0.5803  0.0300\n",
      "    220      0.7157        0.5762  0.0299\n",
      "    221      0.6803        0.5786  0.0255\n",
      "    222      0.7101        \u001b[32m0.5750\u001b[0m  0.0271\n",
      "    223      0.7147        0.5757  0.0309\n",
      "    224      0.7181        0.5781  0.0312\n",
      "    225      0.7159        0.5785  0.0331\n",
      "    226      0.7175        0.5760  0.0290\n",
      "    227      0.7284        0.5788  0.0299\n",
      "    228      0.7210        0.5798  0.0270\n",
      "    229      0.7104        0.5769  0.0293\n",
      "    230      0.6998        0.5772  0.0275\n",
      "    231      0.7081        0.5778  0.0301\n",
      "    232      0.7201        0.5776  0.0298\n",
      "    233      0.7125        \u001b[32m0.5743\u001b[0m  0.0274\n",
      "    234      0.7020        0.5785  0.0286\n",
      "    235      0.6968        0.5770  0.0294\n",
      "    236      0.7197        0.5772  0.0258\n",
      "    237      0.7259        0.5781  0.0235\n",
      "    238      0.7190        0.5776  0.0230\n",
      "    239      0.7084        0.5764  0.0212\n",
      "    240      0.7016        0.5763  0.0189\n",
      "    241      0.7201        0.5758  0.0206\n",
      "    242      0.7239        0.5756  0.0190\n",
      "    243      0.7179        \u001b[32m0.5736\u001b[0m  0.0244\n",
      "    244      0.7034        0.5753  0.0263\n",
      "    245      0.7197        0.5746  0.0263\n",
      "    246      0.7256        0.5748  0.0277\n",
      "    247      0.7091        0.5749  0.0260\n",
      "    248      0.7059        0.5773  0.0255\n",
      "    249      0.7129        0.5751  0.0287\n",
      "    250      0.7134        0.5740  0.0298\n",
      "    251      0.7233        0.5756  0.0252\n",
      "    252      0.7180        0.5758  0.0227\n",
      "    253      0.7225        0.5773  0.0225\n",
      "    254      0.7191        0.5774  0.0215\n",
      "    255      0.7045        0.5776  0.0238\n",
      "    256      0.6701        0.5827  0.0290\n",
      "    257      0.6981        0.5796  0.0292\n",
      "    258      0.7264        0.5785  0.0258\n",
      "    259      \u001b[36m0.7315\u001b[0m        0.5774  0.0256\n",
      "    260      0.7179        \u001b[32m0.5729\u001b[0m  0.0247\n",
      "    261      0.7119        0.5754  0.0246\n",
      "    262      0.7065        0.5769  0.0250\n",
      "    263      0.7215        0.5751  0.0229\n",
      "    264      0.7152        0.5758  0.0228\n",
      "    265      0.7175        0.5767  0.0260\n",
      "    266      0.7159        0.5761  0.0243\n",
      "    267      0.7141        0.5776  0.0265\n",
      "    268      0.7235        0.5775  0.0270\n",
      "    269      0.7175        0.5764  0.0276\n",
      "    270      0.7106        0.5768  0.0298\n",
      "    271      0.7150        0.5734  0.0298\n",
      "    272      0.7179        0.5779  0.0279\n",
      "    273      0.7032        0.5791  0.0274\n",
      "    274      0.7166        0.5746  0.0284\n",
      "    275      0.7261        \u001b[32m0.5729\u001b[0m  0.0266\n",
      "    276      \u001b[36m0.7337\u001b[0m        0.5741  0.0295\n",
      "    277      0.6931        0.5805  0.0245\n",
      "    278      0.7039        0.5757  0.0230\n",
      "    279      0.7200        \u001b[32m0.5726\u001b[0m  0.0252\n",
      "    280      0.7214        0.5770  0.0285\n",
      "    281      0.7143        0.5766  0.0298\n",
      "    282      0.7214        0.5732  0.0234\n",
      "    283      0.7081        0.5754  0.0214\n",
      "    284      0.7150        0.5759  0.0206\n",
      "    285      0.7164        0.5746  0.0229\n",
      "    286      0.7101        0.5773  0.0221\n",
      "    287      0.7141        0.5737  0.0240\n",
      "    288      0.7205        0.5770  0.0252\n",
      "    289      0.7228        0.5773  0.0259\n",
      "    290      0.7195        0.5793  0.0278\n",
      "    291      0.7256        0.5749  0.0276\n",
      "    292      0.7129        0.5738  0.0279\n",
      "    293      0.7161        0.5762  0.0246\n",
      "    294      0.7213        0.5738  0.0273\n",
      "    295      0.7335        0.5727  0.0238\n",
      "    296      0.7197        0.5747  0.0236\n",
      "    297      0.7090        0.5744  0.0268\n",
      "    298      0.6967        0.5756  0.0232\n",
      "    299      0.7275        0.5783  0.0239\n",
      "    300      0.7193        0.5806  0.0252\n",
      "    301      0.7164        \u001b[32m0.5713\u001b[0m  0.0264\n",
      "    302      0.6961        0.5765  0.0247\n",
      "    303      0.7212        0.5753  0.0275\n",
      "    304      0.7275        0.5742  0.0262\n",
      "    305      0.7138        0.5783  0.0274\n",
      "    306      0.7101        0.5748  0.0262\n",
      "    307      0.7108        0.5739  0.0271\n",
      "    308      0.7019        0.5769  0.0252\n",
      "    309      0.6975        0.5771  0.0224\n",
      "    310      0.7161        0.5750  0.0242\n",
      "    311      0.7163        0.5726  0.0232\n",
      "    312      0.7176        0.5787  0.0215\n",
      "    313      0.7307        0.5746  0.0231\n",
      "    314      0.7245        0.5733  0.0228\n",
      "    315      0.7255        0.5730  0.0226\n",
      "    316      0.6946        0.5790  0.0231\n",
      "    317      0.7038        0.5806  0.0239\n",
      "    318      0.7129        0.5769  0.0230\n",
      "    319      0.7159        0.5754  0.0268\n",
      "    320      0.7307        0.5743  0.0256\n",
      "    321      0.7276        0.5716  0.0277\n",
      "    322      0.7206        0.5743  0.0285\n",
      "    323      0.7192        0.5728  0.0279\n",
      "    324      0.7264        0.5754  0.0299\n",
      "    325      0.7132        0.5750  0.0241\n",
      "    326      0.6946        0.5767  0.0245\n",
      "    327      0.7092        0.5747  0.0250\n",
      "    328      0.7278        0.5738  0.0282\n",
      "    329      0.7326        0.5729  0.0293\n",
      "    330      0.7033        0.5741  0.0287\n",
      "    331      0.7241        0.5753  0.0266\n",
      "    332      0.7205        0.5761  0.0246\n",
      "    333      0.7313        0.5723  0.0289\n",
      "    334      0.7048        0.5757  0.0290\n",
      "    335      0.7199        0.5747  0.0287\n",
      "    336      0.7205        0.5754  0.0301\n",
      "    337      0.6951        0.5757  0.0303\n",
      "    338      0.7074        0.5756  0.0264\n",
      "    339      0.7215        \u001b[32m0.5699\u001b[0m  0.0217\n",
      "    340      0.7209        0.5737  0.0210\n",
      "    341      \u001b[36m0.7337\u001b[0m        0.5802  0.0251\n",
      "    342      0.7248        0.5782  0.0299\n",
      "    343      0.7120        0.5738  0.0234\n",
      "    344      0.6981        0.5745  0.0269\n",
      "    345      0.7122        0.5755  0.0261\n",
      "    346      0.7316        0.5783  0.0282\n",
      "    347      0.7167        0.5741  0.0294\n",
      "    348      0.7162        0.5742  0.0227\n",
      "    349      0.7127        0.5744  0.0212\n",
      "    350      0.7270        0.5782  0.0254\n",
      "    351      0.7311        0.5750  0.0275\n",
      "    352      0.7244        0.5729  0.0261\n",
      "    353      0.7105        0.5752  0.0246\n",
      "    354      0.7063        0.5739  0.0222\n",
      "    355      0.7138        0.5749  0.0221\n",
      "    356      0.7287        0.5733  0.0225\n",
      "    357      0.7201        0.5733  0.0254\n",
      "    358      0.7150        0.5702  0.0229\n",
      "    359      0.7157        0.5759  0.0245\n",
      "    360      0.7175        0.5733  0.0218\n",
      "    361      0.7335        0.5705  0.0242\n",
      "    362      0.7170        0.5767  0.0254\n",
      "    363      0.7233        0.5724  0.0241\n",
      "    364      0.7163        0.5766  0.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    365      0.7292        0.5760  0.0238\n",
      "    366      0.7298        0.5723  0.0248\n",
      "    367      0.7039        0.5747  0.0234\n",
      "    368      0.7069        0.5741  0.0251\n",
      "    369      0.7221        0.5707  0.0233\n",
      "    370      0.7314        0.5736  0.0259\n",
      "    371      0.7304        0.5718  0.0253\n",
      "    372      0.7166        0.5741  0.0275\n",
      "    373      0.7166        0.5749  0.0260\n",
      "    374      0.7252        0.5720  0.0278\n",
      "    375      0.7250        0.5741  0.0286\n",
      "    376      0.7284        0.5701  0.0252\n",
      "    377      0.7097        0.5768  0.0225\n",
      "    378      0.7089        0.5777  0.0268\n",
      "    379      0.7304        0.5741  0.0244\n",
      "    380      0.7256        0.5703  0.0243\n",
      "    381      0.7192        0.5748  0.0247\n",
      "    382      0.7230        0.5757  0.0264\n",
      "    383      0.7074        0.5738  0.0290\n",
      "    384      0.7267        0.5733  0.0257\n",
      "    385      0.7296        \u001b[32m0.5696\u001b[0m  0.0223\n",
      "    386      0.7126        0.5759  0.0232\n",
      "    387      0.7124        0.5762  0.0244\n",
      "    388      0.7276        0.5765  0.0235\n",
      "    389      0.7301        0.5753  0.0223\n",
      "    390      0.7278        0.5763  0.0225\n",
      "    391      0.7245        0.5772  0.0285\n",
      "    392      0.7150        0.5712  0.0242\n",
      "    393      0.7098        0.5730  0.0262\n",
      "    394      0.7273        0.5700  0.0268\n",
      "    395      \u001b[36m0.7352\u001b[0m        0.5763  0.0240\n",
      "    396      0.7297        0.5795  0.0261\n",
      "    397      0.7134        0.5759  0.0266\n",
      "    398      0.7115        \u001b[32m0.5693\u001b[0m  0.0231\n",
      "    399      0.7239        0.5745  0.0229\n",
      "    400      0.7262        0.5739  0.0231\n",
      "    401      0.7244        0.5715  0.0229\n",
      "    402      0.7208        0.5701  0.0239\n",
      "    403      0.7256        0.5719  0.0285\n",
      "    404      0.7320        0.5707  0.0235\n",
      "    405      0.7334        0.5712  0.0278\n",
      "    406      0.7279        0.5730  0.0236\n",
      "    407      0.7096        0.5734  0.0235\n",
      "    408      0.7235        0.5711  0.0245\n",
      "    409      0.7207        0.5748  0.0240\n",
      "    410      0.7339        0.5700  0.0225\n",
      "    411      0.7195        0.5729  0.0233\n",
      "    412      0.7163        0.5767  0.0236\n",
      "    413      0.7246        0.5699  0.0256\n",
      "    414      0.7276        0.5732  0.0235\n",
      "    415      0.7315        0.5720  0.0219\n",
      "    416      0.7241        0.5714  0.0211\n",
      "    417      0.7255        0.5708  0.0214\n",
      "    418      0.7270        0.5731  0.0191\n",
      "    419      0.7220        0.5716  0.0213\n",
      "    420      0.7084        0.5743  0.0212\n",
      "    421      0.7241        0.5724  0.0191\n",
      "    422      \u001b[36m0.7368\u001b[0m        0.5697  0.0198\n",
      "    423      0.7188        0.5733  0.0216\n",
      "    424      0.7250        0.5719  0.0281\n",
      "    425      0.7105        0.5736  0.0266\n",
      "    426      0.7176        0.5714  0.0237\n",
      "    427      0.7147        0.5778  0.0248\n",
      "    428      0.7284        0.5819  0.0272\n",
      "    429      \u001b[36m0.7393\u001b[0m        0.5713  0.0220\n",
      "    430      0.7227        0.5718  0.0219\n",
      "    431      0.7017        0.5718  0.0241\n",
      "    432      0.7119        0.5708  0.0309\n",
      "    433      0.7281        0.5726  0.0292\n",
      "    434      0.7383        0.5754  0.0226\n",
      "    435      0.7172        0.5798  0.0222\n",
      "    436      0.7148        0.5732  0.0227\n",
      "    437      0.7164        0.5734  0.0267\n",
      "    438      0.7304        0.5708  0.0278\n",
      "    439      0.7215        0.5769  0.0254\n",
      "    440      0.7161        0.5720  0.0252\n",
      "    441      0.7028        0.5751  0.0276\n",
      "    442      0.7261        0.5706  0.0270\n",
      "    443      0.7317        0.5727  0.0248\n",
      "    444      \u001b[36m0.7423\u001b[0m        \u001b[32m0.5688\u001b[0m  0.0271\n",
      "    445      0.7302        0.5698  0.0248\n",
      "    446      0.7169        0.5693  0.0241\n",
      "    447      0.7225        0.5762  0.0257\n",
      "    448      0.7380        \u001b[32m0.5653\u001b[0m  0.0209\n",
      "    449      0.7188        0.5750  0.0213\n",
      "    450      0.7190        0.5693  0.0206\n",
      "    451      0.7296        0.5703  0.0196\n",
      "    452      0.7092        0.5755  0.0215\n",
      "    453      0.7020        0.5763  0.0267\n",
      "    454      0.7290        0.5713  0.0273\n",
      "    455      0.7065        0.5726  0.0270\n",
      "    456      0.7217        0.5709  0.0298\n",
      "    457      0.7239        0.5700  0.0294\n",
      "    458      0.7273        0.5702  0.0281\n",
      "    459      0.6988        0.5754  0.0252\n",
      "    460      0.7099        0.5758  0.0310\n",
      "    461      0.7264        0.5713  0.0301\n",
      "    462      0.7157        0.5737  0.0300\n",
      "    463      0.7159        0.5715  0.0259\n",
      "    464      0.7304        0.5722  0.0259\n",
      "    465      0.7227        0.5696  0.0275\n",
      "    466      0.7131        0.5722  0.0255\n",
      "    467      0.7296        0.5662  0.0292\n",
      "    468      0.7134        0.5741  0.0279\n",
      "    469      0.7157        0.5741  0.0283\n",
      "    470      0.7342        0.5691  0.0267\n",
      "    471      0.7343        0.5733  0.0224\n",
      "    472      0.7270        0.5731  0.0233\n",
      "    473      0.7068        0.5734  0.0217\n",
      "    474      0.7360        0.5689  0.0226\n",
      "    475      0.7317        0.5708  0.0246\n",
      "    476      0.7312        0.5731  0.0288\n",
      "    477      0.7335        0.5719  0.0268\n",
      "    478      0.7246        0.5696  0.0270\n",
      "    479      0.7126        0.5696  0.0274\n",
      "    480      0.7214        0.5694  0.0272\n",
      "    481      0.7310        0.5715  0.0251\n",
      "    482      0.7362        0.5708  0.0252\n",
      "    483      0.7182        0.5700  0.0265\n",
      "    484      0.7047        0.5716  0.0259\n",
      "    485      0.7224        0.5678  0.0241\n",
      "    486      0.7250        0.5706  0.0282\n",
      "    487      0.7267        0.5714  0.0270\n",
      "    488      0.7281        0.5699  0.0240\n",
      "    489      0.7267        0.5690  0.0254\n",
      "    490      0.7319        0.5696  0.0292\n",
      "    491      \u001b[36m0.7438\u001b[0m        0.5707  0.0276\n",
      "    492      0.7318        0.5695  0.0252\n",
      "    493      0.7196        0.5702  0.0233\n",
      "    494      0.7195        0.5712  0.0249\n",
      "    495      0.7385        0.5715  0.0214\n",
      "    496      0.7308        0.5754  0.0228\n",
      "    497      0.7367        0.5723  0.0229\n",
      "    498      0.7278        0.5706  0.0240\n",
      "    499      0.7184        0.5698  0.0238\n",
      "    500      0.7244        0.5682  0.0230\n",
      "Accuracy of Net: 0.73\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.76      0.74       324\n",
      "          1       0.74      0.70      0.72       323\n",
      "\n",
      "avg / total       0.73      0.73      0.73       647\n",
      "\n",
      "Accuracy of Net: 0.71\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.73      0.71       108\n",
      "          1       0.73      0.70      0.71       113\n",
      "\n",
      "avg / total       0.72      0.71      0.71       221\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = None\n",
    "n_channels = x_train.shape[1]\n",
    "n_features = x_train.shape[2]\n",
    "n_hidden_d = 5\n",
    "n_classes = 2\n",
    "lstm_layers = 1\n",
    "dropout = 0.1\n",
    "device = torch.device('cuda:0')\n",
    "accuracy_epoch_scoring_val = EpochScoring(scoring='f1',name='f1_val', lower_is_better=False, on_train=False)\n",
    "accuracy_epoch_scoring_train = EpochScoring(scoring='f1',name='f1_train', lower_is_better=False, on_train=True)\n",
    "n_epochs = 500\n",
    "\n",
    "model_name = LSTM_0.__name__\n",
    "model = NeuralNetClassifier(module=LSTM_0, criterion=nn.CrossEntropyLoss,\n",
    "                          module__n_channels=n_channels,\n",
    "                          module__n_features=n_features,\n",
    "                          module__n_hidden_d=n_hidden_d,\n",
    "                          module__n_classes=n_classes,\n",
    "                          module__lstm_layers=lstm_layers,\n",
    "                          module__dropout= dropout,\n",
    "                          optimizer=optim.Adam, \n",
    "                          optimizer__lr=0.01,\n",
    "                          #optimizer__weight_decay=0.001,\n",
    "                          max_epochs=n_epochs, \n",
    "                          batch_size=200,\n",
    "                          iterator_train__shuffle=True,\n",
    "                          device=device,\n",
    "                          warm_start=True,train_split=None,\n",
    "                          callbacks=[accuracy_epoch_scoring_val, accuracy_epoch_scoring_train],\n",
    "                         )\n",
    "\"\"\"noise_rounds = 10\n",
    "for _ in range(noise_rounds):\n",
    "    x_noise = add_noise(x, noise_distribution=np.random.normal, std=np.random.uniform(0,1))\n",
    "    #x_noise = add_noise(x)\n",
    "    net.partial_fit(x_noise, y)\n",
    "\n",
    "    #net.partial_fit(x,y)\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train)\n",
    "pred_test = model.predict(x_train)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_train, prefix_information=model_name,\n",
    "                          dataset_name='train', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "pred_test = model.predict(x_val)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_val, prefix_information=model_name,\n",
    "                          dataset_name='val', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>open_change</th>\n",
       "      <th>open_change_pct</th>\n",
       "      <th>next_day_open_change</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_change_pct</th>\n",
       "      <th>volume_change</th>\n",
       "      <th>high_low_range</th>\n",
       "      <th>high_low_range_with_ref_open</th>\n",
       "      <th>high_low_range_with_ref_open_pct</th>\n",
       "      <th>high_low_range_with_ref_close</th>\n",
       "      <th>high_low_range_with_ref_close_pct</th>\n",
       "      <th>gt_1</th>\n",
       "      <th>gt_1.5</th>\n",
       "      <th>gt_2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>20.575001</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>6.877053</td>\n",
       "      <td>601912.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.072904</td>\n",
       "      <td>7.290401</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>7.109005</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>21.549999</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>21.549999</td>\n",
       "      <td>7.023720</td>\n",
       "      <td>1412912.0</td>\n",
       "      <td>0.025516</td>\n",
       "      <td>2.551635</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>...</td>\n",
       "      <td>134.737304</td>\n",
       "      <td>1.347373</td>\n",
       "      <td>1.449999</td>\n",
       "      <td>0.068720</td>\n",
       "      <td>6.872033</td>\n",
       "      <td>0.067285</td>\n",
       "      <td>6.728534</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>6.877053</td>\n",
       "      <td>670824.0</td>\n",
       "      <td>0.018957</td>\n",
       "      <td>1.895735</td>\n",
       "      <td>-0.018605</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.521884</td>\n",
       "      <td>-0.525219</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>6.976744</td>\n",
       "      <td>0.071090</td>\n",
       "      <td>7.109005</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>21.950001</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>21.299999</td>\n",
       "      <td>6.942239</td>\n",
       "      <td>1800878.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.454205</td>\n",
       "      <td>-0.094542</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>3.488372</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>3.521127</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>21.375000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>6.648907</td>\n",
       "      <td>1875000.0</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>-0.581395</td>\n",
       "      <td>-0.064327</td>\n",
       "      <td>...</td>\n",
       "      <td>4.115881</td>\n",
       "      <td>0.041159</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>6.315789</td>\n",
       "      <td>0.066176</td>\n",
       "      <td>6.617647</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-12</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>19.375000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>6.322978</td>\n",
       "      <td>1187362.0</td>\n",
       "      <td>-0.064327</td>\n",
       "      <td>-6.432749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.674027</td>\n",
       "      <td>-0.366740</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>0.045103</td>\n",
       "      <td>4.510309</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-13</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.350000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.995001</td>\n",
       "      <td>6.516905</td>\n",
       "      <td>1132234.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.642897</td>\n",
       "      <td>-0.046429</td>\n",
       "      <td>0.649999</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>3.249995</td>\n",
       "      <td>0.032508</td>\n",
       "      <td>3.250808</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-14</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>6.681498</td>\n",
       "      <td>745568.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.150714</td>\n",
       "      <td>-0.341507</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.034146</td>\n",
       "      <td>3.414634</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000-01-17</td>\n",
       "      <td>20.525000</td>\n",
       "      <td>21.200001</td>\n",
       "      <td>20.525000</td>\n",
       "      <td>20.950001</td>\n",
       "      <td>6.828163</td>\n",
       "      <td>1126256.0</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.021194</td>\n",
       "      <td>...</td>\n",
       "      <td>51.060131</td>\n",
       "      <td>0.510601</td>\n",
       "      <td>0.675001</td>\n",
       "      <td>0.032887</td>\n",
       "      <td>3.288677</td>\n",
       "      <td>0.032220</td>\n",
       "      <td>3.221962</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>20.959999</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>20.775000</td>\n",
       "      <td>20.775000</td>\n",
       "      <td>6.771129</td>\n",
       "      <td>1148256.0</td>\n",
       "      <td>0.021194</td>\n",
       "      <td>2.119362</td>\n",
       "      <td>-0.007634</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953375</td>\n",
       "      <td>0.019534</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.015506</td>\n",
       "      <td>1.550573</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>1.564380</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>18.975000</td>\n",
       "      <td>19.450001</td>\n",
       "      <td>6.339275</td>\n",
       "      <td>2270722.0</td>\n",
       "      <td>-0.007634</td>\n",
       "      <td>-0.763359</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>97.753985</td>\n",
       "      <td>0.977540</td>\n",
       "      <td>1.824999</td>\n",
       "      <td>0.087740</td>\n",
       "      <td>8.774034</td>\n",
       "      <td>0.093830</td>\n",
       "      <td>9.383028</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2000-01-20</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>18.525000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>6.062238</td>\n",
       "      <td>1879256.0</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-6.249995</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.239715</td>\n",
       "      <td>-0.172397</td>\n",
       "      <td>1.075000</td>\n",
       "      <td>0.055128</td>\n",
       "      <td>5.512821</td>\n",
       "      <td>0.057796</td>\n",
       "      <td>5.779570</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000-01-21</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.475000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>6.160016</td>\n",
       "      <td>569668.0</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>-3.076923</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>...</td>\n",
       "      <td>-69.686514</td>\n",
       "      <td>-0.696865</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>18.905001</td>\n",
       "      <td>19.170000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>6.111127</td>\n",
       "      <td>4740464.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>-0.014811</td>\n",
       "      <td>...</td>\n",
       "      <td>732.145039</td>\n",
       "      <td>7.321450</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>3.015075</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000-01-25</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>18.049999</td>\n",
       "      <td>18.254999</td>\n",
       "      <td>5.949792</td>\n",
       "      <td>1243892.0</td>\n",
       "      <td>-0.014811</td>\n",
       "      <td>-1.481095</td>\n",
       "      <td>-0.019866</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.760121</td>\n",
       "      <td>-0.737601</td>\n",
       "      <td>0.575001</td>\n",
       "      <td>0.030873</td>\n",
       "      <td>3.087254</td>\n",
       "      <td>0.031498</td>\n",
       "      <td>3.149828</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000-01-26</td>\n",
       "      <td>18.254999</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>5.834088</td>\n",
       "      <td>2005284.0</td>\n",
       "      <td>-0.019866</td>\n",
       "      <td>-1.986583</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>...</td>\n",
       "      <td>61.210459</td>\n",
       "      <td>0.612105</td>\n",
       "      <td>1.475000</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>8.079979</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>8.240223</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2000-01-27</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.850000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>6.127422</td>\n",
       "      <td>1334222.0</td>\n",
       "      <td>-0.013969</td>\n",
       "      <td>-1.396872</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.464686</td>\n",
       "      <td>-0.334647</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.047222</td>\n",
       "      <td>4.722222</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>4.521277</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000-01-28</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>19.525000</td>\n",
       "      <td>18.875000</td>\n",
       "      <td>19.150000</td>\n",
       "      <td>6.241497</td>\n",
       "      <td>1092374.0</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>4.861111</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.126519</td>\n",
       "      <td>-0.181265</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.034437</td>\n",
       "      <td>3.443709</td>\n",
       "      <td>0.033943</td>\n",
       "      <td>3.394256</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>19.150000</td>\n",
       "      <td>19.375000</td>\n",
       "      <td>18.924999</td>\n",
       "      <td>19.150000</td>\n",
       "      <td>6.241497</td>\n",
       "      <td>979920.0</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>1.456954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.294460</td>\n",
       "      <td>-0.102945</td>\n",
       "      <td>0.450001</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>2.349875</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>2.349875</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>19.150000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>18.025000</td>\n",
       "      <td>5.874828</td>\n",
       "      <td>1411062.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.054830</td>\n",
       "      <td>...</td>\n",
       "      <td>43.997673</td>\n",
       "      <td>0.439977</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>7.049608</td>\n",
       "      <td>0.074896</td>\n",
       "      <td>7.489598</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2000-02-02</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>18.799999</td>\n",
       "      <td>17.875000</td>\n",
       "      <td>17.875000</td>\n",
       "      <td>5.825939</td>\n",
       "      <td>1353100.0</td>\n",
       "      <td>-0.054830</td>\n",
       "      <td>-5.483029</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.107686</td>\n",
       "      <td>-0.041077</td>\n",
       "      <td>0.924999</td>\n",
       "      <td>0.051105</td>\n",
       "      <td>5.110492</td>\n",
       "      <td>0.051748</td>\n",
       "      <td>5.174820</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2000-02-03</td>\n",
       "      <td>18.375000</td>\n",
       "      <td>18.375000</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>5.834088</td>\n",
       "      <td>921596.0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.519337</td>\n",
       "      <td>-0.020408</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.890030</td>\n",
       "      <td>-0.318900</td>\n",
       "      <td>0.575001</td>\n",
       "      <td>0.031293</td>\n",
       "      <td>3.129257</td>\n",
       "      <td>0.032123</td>\n",
       "      <td>3.212296</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2000-02-04</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>5.736310</td>\n",
       "      <td>1351380.0</td>\n",
       "      <td>-0.020408</td>\n",
       "      <td>-2.040816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.634751</td>\n",
       "      <td>0.466348</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0.042614</td>\n",
       "      <td>4.261364</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2000-02-07</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>6.062238</td>\n",
       "      <td>1603826.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028055</td>\n",
       "      <td>...</td>\n",
       "      <td>18.680608</td>\n",
       "      <td>0.186806</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.052778</td>\n",
       "      <td>5.277778</td>\n",
       "      <td>0.051075</td>\n",
       "      <td>5.107527</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2000-02-08</td>\n",
       "      <td>18.504999</td>\n",
       "      <td>18.725000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.866682</td>\n",
       "      <td>1654716.0</td>\n",
       "      <td>0.028055</td>\n",
       "      <td>2.805550</td>\n",
       "      <td>-0.027290</td>\n",
       "      <td>...</td>\n",
       "      <td>3.173037</td>\n",
       "      <td>0.031730</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.047285</td>\n",
       "      <td>4.728452</td>\n",
       "      <td>0.048611</td>\n",
       "      <td>4.861111</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2000-02-09</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>17.004999</td>\n",
       "      <td>17.004999</td>\n",
       "      <td>5.542385</td>\n",
       "      <td>1812798.0</td>\n",
       "      <td>-0.027290</td>\n",
       "      <td>-2.728987</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>9.553422</td>\n",
       "      <td>0.095534</td>\n",
       "      <td>1.295000</td>\n",
       "      <td>0.071944</td>\n",
       "      <td>7.194444</td>\n",
       "      <td>0.076154</td>\n",
       "      <td>7.615408</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2000-02-10</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.800000</td>\n",
       "      <td>16.049999</td>\n",
       "      <td>5.231123</td>\n",
       "      <td>2384764.0</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>-5.555556</td>\n",
       "      <td>-0.052941</td>\n",
       "      <td>...</td>\n",
       "      <td>31.551557</td>\n",
       "      <td>0.315516</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>7.058824</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>7.476636</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2000-02-11</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.200001</td>\n",
       "      <td>5.280014</td>\n",
       "      <td>2475450.0</td>\n",
       "      <td>-0.052941</td>\n",
       "      <td>-5.294118</td>\n",
       "      <td>0.024845</td>\n",
       "      <td>...</td>\n",
       "      <td>3.802724</td>\n",
       "      <td>0.038027</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.055901</td>\n",
       "      <td>5.590062</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>5.555555</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2000-02-14</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>16.225000</td>\n",
       "      <td>5.288161</td>\n",
       "      <td>880022.0</td>\n",
       "      <td>0.024845</td>\n",
       "      <td>2.484472</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.450019</td>\n",
       "      <td>-0.644500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>4.848485</td>\n",
       "      <td>0.049307</td>\n",
       "      <td>4.930663</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2000-02-15</td>\n",
       "      <td>16.225000</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>16.049999</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>5.449494</td>\n",
       "      <td>1069660.0</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>0.047766</td>\n",
       "      <td>...</td>\n",
       "      <td>21.549234</td>\n",
       "      <td>0.215492</td>\n",
       "      <td>0.700001</td>\n",
       "      <td>0.043143</td>\n",
       "      <td>4.314336</td>\n",
       "      <td>0.041866</td>\n",
       "      <td>4.186609</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>26.650000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.350000</td>\n",
       "      <td>26.809999</td>\n",
       "      <td>26.809999</td>\n",
       "      <td>1175301.0</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.376652</td>\n",
       "      <td>0.010131</td>\n",
       "      <td>...</td>\n",
       "      <td>29.247696</td>\n",
       "      <td>0.292477</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>2.439024</td>\n",
       "      <td>0.024245</td>\n",
       "      <td>2.424469</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>26.920000</td>\n",
       "      <td>26.930000</td>\n",
       "      <td>26.510000</td>\n",
       "      <td>26.570000</td>\n",
       "      <td>26.570000</td>\n",
       "      <td>1169442.0</td>\n",
       "      <td>0.010131</td>\n",
       "      <td>1.013133</td>\n",
       "      <td>-0.013001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.498511</td>\n",
       "      <td>-0.004985</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.015602</td>\n",
       "      <td>1.560178</td>\n",
       "      <td>0.015807</td>\n",
       "      <td>1.580730</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>2019-04-16</td>\n",
       "      <td>26.570000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>25.379999</td>\n",
       "      <td>25.629999</td>\n",
       "      <td>25.629999</td>\n",
       "      <td>2009631.0</td>\n",
       "      <td>-0.013001</td>\n",
       "      <td>-1.300149</td>\n",
       "      <td>-0.039142</td>\n",
       "      <td>...</td>\n",
       "      <td>71.845290</td>\n",
       "      <td>0.718453</td>\n",
       "      <td>1.220001</td>\n",
       "      <td>0.045916</td>\n",
       "      <td>4.591648</td>\n",
       "      <td>0.047601</td>\n",
       "      <td>4.760051</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>2019-04-17</td>\n",
       "      <td>25.530001</td>\n",
       "      <td>25.700001</td>\n",
       "      <td>25.090000</td>\n",
       "      <td>25.170000</td>\n",
       "      <td>25.170000</td>\n",
       "      <td>2302131.0</td>\n",
       "      <td>-0.039142</td>\n",
       "      <td>-3.914185</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>14.554911</td>\n",
       "      <td>0.145549</td>\n",
       "      <td>0.610001</td>\n",
       "      <td>0.023893</td>\n",
       "      <td>2.389350</td>\n",
       "      <td>0.024235</td>\n",
       "      <td>2.423524</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>25.160000</td>\n",
       "      <td>25.590000</td>\n",
       "      <td>25.070000</td>\n",
       "      <td>25.420000</td>\n",
       "      <td>25.420000</td>\n",
       "      <td>1496052.0</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-1.449279</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.014471</td>\n",
       "      <td>-0.350145</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>2.066773</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>2.045633</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>25.420000</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>25.260000</td>\n",
       "      <td>25.730000</td>\n",
       "      <td>25.730000</td>\n",
       "      <td>1682258.0</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>1.033386</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>...</td>\n",
       "      <td>12.446493</td>\n",
       "      <td>0.124465</td>\n",
       "      <td>0.530001</td>\n",
       "      <td>0.020850</td>\n",
       "      <td>2.084976</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>2.059856</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>25.730000</td>\n",
       "      <td>26.070000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.719999</td>\n",
       "      <td>25.719999</td>\n",
       "      <td>1927029.0</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>1.219512</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>...</td>\n",
       "      <td>14.550146</td>\n",
       "      <td>0.145501</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>2.603964</td>\n",
       "      <td>0.026050</td>\n",
       "      <td>2.604977</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>25.799999</td>\n",
       "      <td>26.510000</td>\n",
       "      <td>25.340000</td>\n",
       "      <td>26.160000</td>\n",
       "      <td>26.160000</td>\n",
       "      <td>1724743.0</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.272052</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.497299</td>\n",
       "      <td>-0.104973</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>0.045349</td>\n",
       "      <td>4.534884</td>\n",
       "      <td>0.044725</td>\n",
       "      <td>4.472477</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>26.299999</td>\n",
       "      <td>26.459999</td>\n",
       "      <td>25.870001</td>\n",
       "      <td>25.870001</td>\n",
       "      <td>25.870001</td>\n",
       "      <td>1311738.0</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>1.937985</td>\n",
       "      <td>-0.011407</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.945886</td>\n",
       "      <td>-0.239459</td>\n",
       "      <td>0.589998</td>\n",
       "      <td>0.022433</td>\n",
       "      <td>2.243338</td>\n",
       "      <td>0.022806</td>\n",
       "      <td>2.280626</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.180000</td>\n",
       "      <td>25.760000</td>\n",
       "      <td>25.840000</td>\n",
       "      <td>25.840000</td>\n",
       "      <td>849949.0</td>\n",
       "      <td>-0.011407</td>\n",
       "      <td>-1.140681</td>\n",
       "      <td>-0.006154</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.204362</td>\n",
       "      <td>-0.352044</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>1.615385</td>\n",
       "      <td>0.016254</td>\n",
       "      <td>1.625387</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>25.840000</td>\n",
       "      <td>25.850000</td>\n",
       "      <td>24.940001</td>\n",
       "      <td>25.110001</td>\n",
       "      <td>25.110001</td>\n",
       "      <td>1630535.0</td>\n",
       "      <td>-0.006154</td>\n",
       "      <td>-0.615385</td>\n",
       "      <td>-0.025155</td>\n",
       "      <td>...</td>\n",
       "      <td>91.839157</td>\n",
       "      <td>0.918392</td>\n",
       "      <td>0.909999</td>\n",
       "      <td>0.035217</td>\n",
       "      <td>3.521668</td>\n",
       "      <td>0.036241</td>\n",
       "      <td>3.624050</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>25.190001</td>\n",
       "      <td>25.520000</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>1545305.0</td>\n",
       "      <td>-0.025155</td>\n",
       "      <td>-2.515476</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.227119</td>\n",
       "      <td>-0.052271</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.026598</td>\n",
       "      <td>2.659786</td>\n",
       "      <td>0.026378</td>\n",
       "      <td>2.637795</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>25.299999</td>\n",
       "      <td>25.590000</td>\n",
       "      <td>25.299999</td>\n",
       "      <td>25.309999</td>\n",
       "      <td>25.309999</td>\n",
       "      <td>859297.0</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>0.436673</td>\n",
       "      <td>-0.017787</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.393049</td>\n",
       "      <td>-0.443930</td>\n",
       "      <td>0.290001</td>\n",
       "      <td>0.011462</td>\n",
       "      <td>1.146249</td>\n",
       "      <td>0.011458</td>\n",
       "      <td>1.145796</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>25.010000</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>25.010000</td>\n",
       "      <td>25.010000</td>\n",
       "      <td>894182.0</td>\n",
       "      <td>-0.017787</td>\n",
       "      <td>-1.778652</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>...</td>\n",
       "      <td>4.059714</td>\n",
       "      <td>0.040597</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.016499</td>\n",
       "      <td>1.649899</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>1.639344</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>25.030001</td>\n",
       "      <td>25.090000</td>\n",
       "      <td>24.240000</td>\n",
       "      <td>24.350000</td>\n",
       "      <td>24.350000</td>\n",
       "      <td>2082526.0</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.724350</td>\n",
       "      <td>-0.027167</td>\n",
       "      <td>...</td>\n",
       "      <td>132.897330</td>\n",
       "      <td>1.328973</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.033959</td>\n",
       "      <td>3.395925</td>\n",
       "      <td>0.034908</td>\n",
       "      <td>3.490760</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>2019-05-08</td>\n",
       "      <td>24.350000</td>\n",
       "      <td>24.680000</td>\n",
       "      <td>24.049999</td>\n",
       "      <td>24.299999</td>\n",
       "      <td>24.299999</td>\n",
       "      <td>1414913.0</td>\n",
       "      <td>-0.027167</td>\n",
       "      <td>-2.716744</td>\n",
       "      <td>-0.006982</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.057847</td>\n",
       "      <td>-0.320578</td>\n",
       "      <td>0.630001</td>\n",
       "      <td>0.025873</td>\n",
       "      <td>2.587273</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>2.592597</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>24.180000</td>\n",
       "      <td>24.180000</td>\n",
       "      <td>23.530001</td>\n",
       "      <td>23.959999</td>\n",
       "      <td>23.959999</td>\n",
       "      <td>2230327.0</td>\n",
       "      <td>-0.006982</td>\n",
       "      <td>-0.698152</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>...</td>\n",
       "      <td>57.629974</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.649999</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>2.688168</td>\n",
       "      <td>0.027129</td>\n",
       "      <td>2.712851</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>24.209999</td>\n",
       "      <td>24.459999</td>\n",
       "      <td>24.180000</td>\n",
       "      <td>24.320000</td>\n",
       "      <td>24.320000</td>\n",
       "      <td>1424154.0</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.124065</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.145955</td>\n",
       "      <td>-0.361460</td>\n",
       "      <td>0.279999</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>1.156543</td>\n",
       "      <td>0.011513</td>\n",
       "      <td>1.151312</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>2019-05-13</td>\n",
       "      <td>24.280001</td>\n",
       "      <td>24.280001</td>\n",
       "      <td>23.379999</td>\n",
       "      <td>23.530001</td>\n",
       "      <td>23.530001</td>\n",
       "      <td>2231387.0</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.289145</td>\n",
       "      <td>-0.027183</td>\n",
       "      <td>...</td>\n",
       "      <td>56.681581</td>\n",
       "      <td>0.566816</td>\n",
       "      <td>0.900002</td>\n",
       "      <td>0.037068</td>\n",
       "      <td>3.706763</td>\n",
       "      <td>0.038249</td>\n",
       "      <td>3.824913</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>2019-05-14</td>\n",
       "      <td>23.620001</td>\n",
       "      <td>23.820000</td>\n",
       "      <td>23.450001</td>\n",
       "      <td>23.570000</td>\n",
       "      <td>23.570000</td>\n",
       "      <td>1564659.0</td>\n",
       "      <td>-0.027183</td>\n",
       "      <td>-2.718287</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.879532</td>\n",
       "      <td>-0.298795</td>\n",
       "      <td>0.369999</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>1.566465</td>\n",
       "      <td>0.015698</td>\n",
       "      <td>1.569788</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>23.680000</td>\n",
       "      <td>23.770000</td>\n",
       "      <td>23.260000</td>\n",
       "      <td>23.510000</td>\n",
       "      <td>23.510000</td>\n",
       "      <td>1489304.0</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.254018</td>\n",
       "      <td>-0.007179</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.816065</td>\n",
       "      <td>-0.048161</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>2.153716</td>\n",
       "      <td>0.021693</td>\n",
       "      <td>2.169290</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>2019-05-16</td>\n",
       "      <td>23.510000</td>\n",
       "      <td>23.860001</td>\n",
       "      <td>23.330000</td>\n",
       "      <td>23.820000</td>\n",
       "      <td>23.820000</td>\n",
       "      <td>1194126.0</td>\n",
       "      <td>-0.007179</td>\n",
       "      <td>-0.717905</td>\n",
       "      <td>0.013611</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.819862</td>\n",
       "      <td>-0.198199</td>\n",
       "      <td>0.530001</td>\n",
       "      <td>0.022544</td>\n",
       "      <td>2.254364</td>\n",
       "      <td>0.022250</td>\n",
       "      <td>2.225025</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>23.840000</td>\n",
       "      <td>23.420000</td>\n",
       "      <td>23.719999</td>\n",
       "      <td>23.719999</td>\n",
       "      <td>1326094.0</td>\n",
       "      <td>0.013611</td>\n",
       "      <td>1.361123</td>\n",
       "      <td>-0.004616</td>\n",
       "      <td>...</td>\n",
       "      <td>11.051430</td>\n",
       "      <td>0.110514</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.017625</td>\n",
       "      <td>1.762484</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>1.770658</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>23.719999</td>\n",
       "      <td>23.799999</td>\n",
       "      <td>23.020000</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>23.219999</td>\n",
       "      <td>1180990.0</td>\n",
       "      <td>-0.004616</td>\n",
       "      <td>-0.461607</td>\n",
       "      <td>-0.015177</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.942211</td>\n",
       "      <td>-0.109422</td>\n",
       "      <td>0.779999</td>\n",
       "      <td>0.032884</td>\n",
       "      <td>3.288360</td>\n",
       "      <td>0.033592</td>\n",
       "      <td>3.359169</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>23.360001</td>\n",
       "      <td>23.559999</td>\n",
       "      <td>23.170000</td>\n",
       "      <td>23.459999</td>\n",
       "      <td>23.459999</td>\n",
       "      <td>1349072.0</td>\n",
       "      <td>-0.015177</td>\n",
       "      <td>-1.517698</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>...</td>\n",
       "      <td>14.232297</td>\n",
       "      <td>0.142323</td>\n",
       "      <td>0.389999</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>1.669516</td>\n",
       "      <td>0.016624</td>\n",
       "      <td>1.662400</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>23.559999</td>\n",
       "      <td>23.680000</td>\n",
       "      <td>23.410000</td>\n",
       "      <td>23.480000</td>\n",
       "      <td>23.480000</td>\n",
       "      <td>1017770.0</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.856156</td>\n",
       "      <td>-0.011460</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.557770</td>\n",
       "      <td>-0.245578</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>1.146010</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>1.149915</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4939</th>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>23.290001</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>22.760000</td>\n",
       "      <td>22.770000</td>\n",
       "      <td>22.770000</td>\n",
       "      <td>1531335.0</td>\n",
       "      <td>-0.011460</td>\n",
       "      <td>-1.146002</td>\n",
       "      <td>-0.012881</td>\n",
       "      <td>...</td>\n",
       "      <td>50.459829</td>\n",
       "      <td>0.504598</td>\n",
       "      <td>0.539999</td>\n",
       "      <td>0.023186</td>\n",
       "      <td>2.318587</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>2.371537</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>22.990000</td>\n",
       "      <td>23.240000</td>\n",
       "      <td>22.860001</td>\n",
       "      <td>22.879999</td>\n",
       "      <td>22.879999</td>\n",
       "      <td>1607082.0</td>\n",
       "      <td>-0.012881</td>\n",
       "      <td>-1.288111</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>...</td>\n",
       "      <td>4.946468</td>\n",
       "      <td>0.049465</td>\n",
       "      <td>0.379999</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>1.652888</td>\n",
       "      <td>0.016608</td>\n",
       "      <td>1.660835</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>23.150000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>22.969999</td>\n",
       "      <td>22.969999</td>\n",
       "      <td>506398.0</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.478469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-68.489598</td>\n",
       "      <td>-0.684896</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>1.082251</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>1.088376</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>22.930000</td>\n",
       "      <td>23.139999</td>\n",
       "      <td>22.510000</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>2690023.0</td>\n",
       "      <td>-0.007359</td>\n",
       "      <td>-0.735931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>431.207272</td>\n",
       "      <td>4.312073</td>\n",
       "      <td>0.629999</td>\n",
       "      <td>0.027475</td>\n",
       "      <td>2.747488</td>\n",
       "      <td>0.027913</td>\n",
       "      <td>2.791311</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4755 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Open       High        Low      Close  Adj Close  \\\n",
       "0    2000-01-03  20.575001  22.000000  20.500000  21.100000   6.877053   \n",
       "1    2000-01-04  21.100000  21.549999  20.100000  21.549999   7.023720   \n",
       "2    2000-01-05  21.500000  21.500000  20.000000  21.100000   6.877053   \n",
       "5    2000-01-10  21.500000  21.950001  21.200001  21.299999   6.942239   \n",
       "6    2000-01-11  21.375000  21.600000  20.250000  20.400000   6.648907   \n",
       "7    2000-01-12  20.000000  20.250000  19.375000  19.400000   6.322978   \n",
       "8    2000-01-13  20.000000  20.350000  19.700001  19.995001   6.516905   \n",
       "9    2000-01-14  20.000000  20.600000  19.900000  20.500000   6.681498   \n",
       "10   2000-01-17  20.525000  21.200001  20.525000  20.950001   6.828163   \n",
       "11   2000-01-18  20.959999  21.100000  20.775000  20.775000   6.771129   \n",
       "12   2000-01-19  20.799999  20.799999  18.975000  19.450001   6.339275   \n",
       "13   2000-01-20  19.500000  19.600000  18.525000  18.600000   6.062238   \n",
       "14   2000-01-21  18.900000  19.000000  18.475000  18.900000   6.160016   \n",
       "15   2000-01-24  18.905001  19.170000  18.600000  18.750000   6.111127   \n",
       "16   2000-01-25  18.625000  18.625000  18.049999  18.254999   5.949792   \n",
       "17   2000-01-26  18.254999  18.875000  17.400000  17.900000   5.834088   \n",
       "18   2000-01-27  18.000000  18.850000  18.000000  18.799999   6.127422   \n",
       "19   2000-01-28  18.875000  19.525000  18.875000  19.150000   6.241497   \n",
       "20   2000-01-31  19.150000  19.375000  18.924999  19.150000   6.241497   \n",
       "21   2000-02-01  19.150000  19.250000  17.900000  18.025000   5.874828   \n",
       "22   2000-02-02  18.100000  18.799999  17.875000  17.875000   5.825939   \n",
       "23   2000-02-03  18.375000  18.375000  17.799999  17.900000   5.834088   \n",
       "24   2000-02-04  18.000000  18.250000  17.500000  17.600000   5.736310   \n",
       "25   2000-02-07  18.000000  18.600000  17.650000  18.600000   6.062238   \n",
       "26   2000-02-08  18.504999  18.725000  17.850000  18.000000   5.866682   \n",
       "27   2000-02-09  18.000000  18.299999  17.004999  17.004999   5.542385   \n",
       "28   2000-02-10  17.000000  17.000000  15.800000  16.049999   5.231123   \n",
       "29   2000-02-11  16.100000  17.000000  16.100000  16.200001   5.280014   \n",
       "30   2000-02-14  16.500000  16.750000  15.950000  16.225000   5.288161   \n",
       "31   2000-02-15  16.225000  16.750000  16.049999  16.719999   5.449494   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4913 2019-04-12  26.650000  27.000000  26.350000  26.809999  26.809999   \n",
       "4914 2019-04-15  26.920000  26.930000  26.510000  26.570000  26.570000   \n",
       "4915 2019-04-16  26.570000  26.600000  25.379999  25.629999  25.629999   \n",
       "4916 2019-04-17  25.530001  25.700001  25.090000  25.170000  25.170000   \n",
       "4917 2019-04-18  25.160000  25.590000  25.070000  25.420000  25.420000   \n",
       "4918 2019-04-23  25.420000  25.790001  25.260000  25.730000  25.730000   \n",
       "4919 2019-04-24  25.730000  26.070000  25.400000  25.719999  25.719999   \n",
       "4920 2019-04-25  25.799999  26.510000  25.340000  26.160000  26.160000   \n",
       "4921 2019-04-26  26.299999  26.459999  25.870001  25.870001  25.870001   \n",
       "4922 2019-04-29  26.000000  26.180000  25.760000  25.840000  25.840000   \n",
       "4923 2019-04-30  25.840000  25.850000  24.940001  25.110001  25.110001   \n",
       "4924 2019-05-02  25.190001  25.520000  24.850000  25.400000  25.400000   \n",
       "4925 2019-05-03  25.299999  25.590000  25.299999  25.309999  25.309999   \n",
       "4926 2019-05-06  24.850000  25.010000  24.600000  25.010000  25.010000   \n",
       "4927 2019-05-07  25.030001  25.090000  24.240000  24.350000  24.350000   \n",
       "4928 2019-05-08  24.350000  24.680000  24.049999  24.299999  24.299999   \n",
       "4929 2019-05-09  24.180000  24.180000  23.530001  23.959999  23.959999   \n",
       "4930 2019-05-10  24.209999  24.459999  24.180000  24.320000  24.320000   \n",
       "4931 2019-05-13  24.280001  24.280001  23.379999  23.530001  23.530001   \n",
       "4932 2019-05-14  23.620001  23.820000  23.450001  23.570000  23.570000   \n",
       "4933 2019-05-15  23.680000  23.770000  23.260000  23.510000  23.510000   \n",
       "4934 2019-05-16  23.510000  23.860001  23.330000  23.820000  23.820000   \n",
       "4935 2019-05-17  23.830000  23.840000  23.420000  23.719999  23.719999   \n",
       "4936 2019-05-20  23.719999  23.799999  23.020000  23.219999  23.219999   \n",
       "4937 2019-05-21  23.360001  23.559999  23.170000  23.459999  23.459999   \n",
       "4938 2019-05-22  23.559999  23.680000  23.410000  23.480000  23.480000   \n",
       "4939 2019-05-23  23.290001  23.299999  22.760000  22.770000  22.770000   \n",
       "4940 2019-05-24  22.990000  23.240000  22.860001  22.879999  22.879999   \n",
       "4941 2019-05-27  23.100000  23.150000  22.900000  22.969999  22.969999   \n",
       "4942 2019-05-28  22.930000  23.139999  22.510000  22.570000  22.570000   \n",
       "\n",
       "         Volume  open_change  open_change_pct  next_day_open_change   ...    \\\n",
       "0      601912.0     0.000000         0.000000              0.025516   ...     \n",
       "1     1412912.0     0.025516         2.551635              0.018957   ...     \n",
       "2      670824.0     0.018957         1.895735             -0.018605   ...     \n",
       "5     1800878.0     0.000000         0.000000             -0.005814   ...     \n",
       "6     1875000.0    -0.005814        -0.581395             -0.064327   ...     \n",
       "7     1187362.0    -0.064327        -6.432749              0.000000   ...     \n",
       "8     1132234.0     0.000000         0.000000              0.000000   ...     \n",
       "9      745568.0     0.000000         0.000000              0.026250   ...     \n",
       "10    1126256.0     0.026250         2.625000              0.021194   ...     \n",
       "11    1148256.0     0.021194         2.119362             -0.007634   ...     \n",
       "12    2270722.0    -0.007634        -0.763359             -0.062500   ...     \n",
       "13    1879256.0    -0.062500        -6.249995             -0.030769   ...     \n",
       "14     569668.0    -0.030769        -3.076923              0.000265   ...     \n",
       "15    4740464.0     0.000265         0.026460             -0.014811   ...     \n",
       "16    1243892.0    -0.014811        -1.481095             -0.019866   ...     \n",
       "17    2005284.0    -0.019866        -1.986583             -0.013969   ...     \n",
       "18    1334222.0    -0.013969        -1.396872              0.048611   ...     \n",
       "19    1092374.0     0.048611         4.861111              0.014570   ...     \n",
       "20     979920.0     0.014570         1.456954              0.000000   ...     \n",
       "21    1411062.0     0.000000         0.000000             -0.054830   ...     \n",
       "22    1353100.0    -0.054830        -5.483029              0.015193   ...     \n",
       "23     921596.0     0.015193         1.519337             -0.020408   ...     \n",
       "24    1351380.0    -0.020408        -2.040816              0.000000   ...     \n",
       "25    1603826.0     0.000000         0.000000              0.028055   ...     \n",
       "26    1654716.0     0.028055         2.805550             -0.027290   ...     \n",
       "27    1812798.0    -0.027290        -2.728987             -0.055556   ...     \n",
       "28    2384764.0    -0.055556        -5.555556             -0.052941   ...     \n",
       "29    2475450.0    -0.052941        -5.294118              0.024845   ...     \n",
       "30     880022.0     0.024845         2.484472             -0.016667   ...     \n",
       "31    1069660.0    -0.016667        -1.666667              0.047766   ...     \n",
       "...         ...          ...              ...                   ...   ...     \n",
       "4913  1175301.0     0.003767         0.376652              0.010131   ...     \n",
       "4914  1169442.0     0.010131         1.013133             -0.013001   ...     \n",
       "4915  2009631.0    -0.013001        -1.300149             -0.039142   ...     \n",
       "4916  2302131.0    -0.039142        -3.914185             -0.014493   ...     \n",
       "4917  1496052.0    -0.014493        -1.449279              0.010334   ...     \n",
       "4918  1682258.0     0.010334         1.033386              0.012195   ...     \n",
       "4919  1927029.0     0.012195         1.219512              0.002721   ...     \n",
       "4920  1724743.0     0.002721         0.272052              0.019380   ...     \n",
       "4921  1311738.0     0.019380         1.937985             -0.011407   ...     \n",
       "4922   849949.0    -0.011407        -1.140681             -0.006154   ...     \n",
       "4923  1630535.0    -0.006154        -0.615385             -0.025155   ...     \n",
       "4924  1545305.0    -0.025155        -2.515476              0.004367   ...     \n",
       "4925   859297.0     0.004367         0.436673             -0.017787   ...     \n",
       "4926   894182.0    -0.017787        -1.778652              0.007244   ...     \n",
       "4927  2082526.0     0.007244         0.724350             -0.027167   ...     \n",
       "4928  1414913.0    -0.027167        -2.716744             -0.006982   ...     \n",
       "4929  2230327.0    -0.006982        -0.698152              0.001241   ...     \n",
       "4930  1424154.0     0.001241         0.124065              0.002891   ...     \n",
       "4931  2231387.0     0.002891         0.289145             -0.027183   ...     \n",
       "4932  1564659.0    -0.027183        -2.718287              0.002540   ...     \n",
       "4933  1489304.0     0.002540         0.254018             -0.007179   ...     \n",
       "4934  1194126.0    -0.007179        -0.717905              0.013611   ...     \n",
       "4935  1326094.0     0.013611         1.361123             -0.004616   ...     \n",
       "4936  1180990.0    -0.004616        -0.461607             -0.015177   ...     \n",
       "4937  1349072.0    -0.015177        -1.517698              0.008562   ...     \n",
       "4938  1017770.0     0.008562         0.856156             -0.011460   ...     \n",
       "4939  1531335.0    -0.011460        -1.146002             -0.012881   ...     \n",
       "4940  1607082.0    -0.012881        -1.288111              0.004785   ...     \n",
       "4941   506398.0     0.004785         0.478469              0.000000   ...     \n",
       "4942  2690023.0    -0.007359        -0.735931              0.000000   ...     \n",
       "\n",
       "      volume_change_pct  volume_change  high_low_range  \\\n",
       "0              0.000000       0.000000        1.500000   \n",
       "1            134.737304       1.347373        1.449999   \n",
       "2            -52.521884      -0.525219        1.500000   \n",
       "5             -9.454205      -0.094542        0.750000   \n",
       "6              4.115881       0.041159        1.350000   \n",
       "7            -36.674027      -0.366740        0.875000   \n",
       "8             -4.642897      -0.046429        0.649999   \n",
       "9            -34.150714      -0.341507        0.700000   \n",
       "10            51.060131       0.510601        0.675001   \n",
       "11             1.953375       0.019534        0.325000   \n",
       "12            97.753985       0.977540        1.824999   \n",
       "13           -17.239715      -0.172397        1.075000   \n",
       "14           -69.686514      -0.696865        0.525000   \n",
       "15           732.145039       7.321450        0.570000   \n",
       "16           -73.760121      -0.737601        0.575001   \n",
       "17            61.210459       0.612105        1.475000   \n",
       "18           -33.464686      -0.334647        0.850000   \n",
       "19           -18.126519      -0.181265        0.650000   \n",
       "20           -10.294460      -0.102945        0.450001   \n",
       "21            43.997673       0.439977        1.350000   \n",
       "22            -4.107686      -0.041077        0.924999   \n",
       "23           -31.890030      -0.318900        0.575001   \n",
       "24            46.634751       0.466348        0.750000   \n",
       "25            18.680608       0.186806        0.950000   \n",
       "26             3.173037       0.031730        0.875000   \n",
       "27             9.553422       0.095534        1.295000   \n",
       "28            31.551557       0.315516        1.200000   \n",
       "29             3.802724       0.038027        0.900000   \n",
       "30           -64.450019      -0.644500        0.800000   \n",
       "31            21.549234       0.215492        0.700001   \n",
       "...                 ...            ...             ...   \n",
       "4913          29.247696       0.292477        0.650000   \n",
       "4914          -0.498511      -0.004985        0.420000   \n",
       "4915          71.845290       0.718453        1.220001   \n",
       "4916          14.554911       0.145549        0.610001   \n",
       "4917         -35.014471      -0.350145        0.520000   \n",
       "4918          12.446493       0.124465        0.530001   \n",
       "4919          14.550146       0.145501        0.670000   \n",
       "4920         -10.497299      -0.104973        1.170000   \n",
       "4921         -23.945886      -0.239459        0.589998   \n",
       "4922         -35.204362      -0.352044        0.420000   \n",
       "4923          91.839157       0.918392        0.909999   \n",
       "4924          -5.227119      -0.052271        0.670000   \n",
       "4925         -44.393049      -0.443930        0.290001   \n",
       "4926           4.059714       0.040597        0.410000   \n",
       "4927         132.897330       1.328973        0.850000   \n",
       "4928         -32.057847      -0.320578        0.630001   \n",
       "4929          57.629974       0.576300        0.649999   \n",
       "4930         -36.145955      -0.361460        0.279999   \n",
       "4931          56.681581       0.566816        0.900002   \n",
       "4932         -29.879532      -0.298795        0.369999   \n",
       "4933          -4.816065      -0.048161        0.510000   \n",
       "4934         -19.819862      -0.198199        0.530001   \n",
       "4935          11.051430       0.110514        0.420000   \n",
       "4936         -10.942211      -0.109422        0.779999   \n",
       "4937          14.232297       0.142323        0.389999   \n",
       "4938         -24.557770      -0.245578        0.270000   \n",
       "4939          50.459829       0.504598        0.539999   \n",
       "4940           4.946468       0.049465        0.379999   \n",
       "4941         -68.489598      -0.684896        0.250000   \n",
       "4942         431.207272       4.312073        0.629999   \n",
       "\n",
       "      high_low_range_with_ref_open  high_low_range_with_ref_open_pct  \\\n",
       "0                         0.072904                          7.290401   \n",
       "1                         0.068720                          6.872033   \n",
       "2                         0.069767                          6.976744   \n",
       "5                         0.034884                          3.488372   \n",
       "6                         0.063158                          6.315789   \n",
       "7                         0.043750                          4.375000   \n",
       "8                         0.032500                          3.249995   \n",
       "9                         0.035000                          3.500000   \n",
       "10                        0.032887                          3.288677   \n",
       "11                        0.015506                          1.550573   \n",
       "12                        0.087740                          8.774034   \n",
       "13                        0.055128                          5.512821   \n",
       "14                        0.027778                          2.777778   \n",
       "15                        0.030151                          3.015075   \n",
       "16                        0.030873                          3.087254   \n",
       "17                        0.080800                          8.079979   \n",
       "18                        0.047222                          4.722222   \n",
       "19                        0.034437                          3.443709   \n",
       "20                        0.023499                          2.349875   \n",
       "21                        0.070496                          7.049608   \n",
       "22                        0.051105                          5.110492   \n",
       "23                        0.031293                          3.129257   \n",
       "24                        0.041667                          4.166667   \n",
       "25                        0.052778                          5.277778   \n",
       "26                        0.047285                          4.728452   \n",
       "27                        0.071944                          7.194444   \n",
       "28                        0.070588                          7.058824   \n",
       "29                        0.055901                          5.590062   \n",
       "30                        0.048485                          4.848485   \n",
       "31                        0.043143                          4.314336   \n",
       "...                            ...                               ...   \n",
       "4913                      0.024390                          2.439024   \n",
       "4914                      0.015602                          1.560178   \n",
       "4915                      0.045916                          4.591648   \n",
       "4916                      0.023893                          2.389350   \n",
       "4917                      0.020668                          2.066773   \n",
       "4918                      0.020850                          2.084976   \n",
       "4919                      0.026040                          2.603964   \n",
       "4920                      0.045349                          4.534884   \n",
       "4921                      0.022433                          2.243338   \n",
       "4922                      0.016154                          1.615385   \n",
       "4923                      0.035217                          3.521668   \n",
       "4924                      0.026598                          2.659786   \n",
       "4925                      0.011462                          1.146249   \n",
       "4926                      0.016499                          1.649899   \n",
       "4927                      0.033959                          3.395925   \n",
       "4928                      0.025873                          2.587273   \n",
       "4929                      0.026882                          2.688168   \n",
       "4930                      0.011565                          1.156543   \n",
       "4931                      0.037068                          3.706763   \n",
       "4932                      0.015665                          1.566465   \n",
       "4933                      0.021537                          2.153716   \n",
       "4934                      0.022544                          2.254364   \n",
       "4935                      0.017625                          1.762484   \n",
       "4936                      0.032884                          3.288360   \n",
       "4937                      0.016695                          1.669516   \n",
       "4938                      0.011460                          1.146010   \n",
       "4939                      0.023186                          2.318587   \n",
       "4940                      0.016529                          1.652888   \n",
       "4941                      0.010823                          1.082251   \n",
       "4942                      0.027475                          2.747488   \n",
       "\n",
       "      high_low_range_with_ref_close  high_low_range_with_ref_close_pct   gt_1  \\\n",
       "0                          0.071090                           7.109005  False   \n",
       "1                          0.067285                           6.728534   True   \n",
       "2                          0.071090                           7.109005  False   \n",
       "5                          0.035211                           3.521127   True   \n",
       "6                          0.066176                           6.617647  False   \n",
       "7                          0.045103                           4.510309  False   \n",
       "8                          0.032508                           3.250808   True   \n",
       "9                          0.034146                           3.414634   True   \n",
       "10                         0.032220                           3.221962   True   \n",
       "11                         0.015644                           1.564380  False   \n",
       "12                         0.093830                           9.383028  False   \n",
       "13                         0.057796                           5.779570  False   \n",
       "14                         0.027778                           2.777778   True   \n",
       "15                         0.030400                           3.040000  False   \n",
       "16                         0.031498                           3.149828  False   \n",
       "17                         0.082402                           8.240223  False   \n",
       "18                         0.045213                           4.521277   True   \n",
       "19                         0.033943                           3.394256   True   \n",
       "20                         0.023499                           2.349875  False   \n",
       "21                         0.074896                           7.489598  False   \n",
       "22                         0.051748                           5.174820  False   \n",
       "23                         0.032123                           3.212296  False   \n",
       "24                         0.042614                           4.261364  False   \n",
       "25                         0.051075                           5.107527   True   \n",
       "26                         0.048611                           4.861111  False   \n",
       "27                         0.076154                           7.615408  False   \n",
       "28                         0.074766                           7.476636  False   \n",
       "29                         0.055556                           5.555555  False   \n",
       "30                         0.049307                           4.930663  False   \n",
       "31                         0.041866                           4.186609   True   \n",
       "...                             ...                                ...    ...   \n",
       "4913                       0.024245                           2.424469  False   \n",
       "4914                       0.015807                           1.580730  False   \n",
       "4915                       0.047601                           4.760051  False   \n",
       "4916                       0.024235                           2.423524  False   \n",
       "4917                       0.020456                           2.045633  False   \n",
       "4918                       0.020599                           2.059856   True   \n",
       "4919                       0.026050                           2.604977  False   \n",
       "4920                       0.044725                           4.472477   True   \n",
       "4921                       0.022806                           2.280626  False   \n",
       "4922                       0.016254                           1.625387  False   \n",
       "4923                       0.036241                           3.624050  False   \n",
       "4924                       0.026378                           2.637795   True   \n",
       "4925                       0.011458                           1.145796  False   \n",
       "4926                       0.016393                           1.639344  False   \n",
       "4927                       0.034908                           3.490760  False   \n",
       "4928                       0.025926                           2.592597  False   \n",
       "4929                       0.027129                           2.712851  False   \n",
       "4930                       0.011513                           1.151312   True   \n",
       "4931                       0.038249                           3.824913  False   \n",
       "4932                       0.015698                           1.569788  False   \n",
       "4933                       0.021693                           2.169290  False   \n",
       "4934                       0.022250                           2.225025   True   \n",
       "4935                       0.017707                           1.770658  False   \n",
       "4936                       0.033592                           3.359169  False   \n",
       "4937                       0.016624                           1.662400   True   \n",
       "4938                       0.011499                           1.149915  False   \n",
       "4939                       0.023715                           2.371537  False   \n",
       "4940                       0.016608                           1.660835  False   \n",
       "4941                       0.010884                           1.088376  False   \n",
       "4942                       0.027913                           2.791311  False   \n",
       "\n",
       "      gt_1.5  gt_2.5  \n",
       "0      False   False  \n",
       "1       True   False  \n",
       "2      False   False  \n",
       "5       True   False  \n",
       "6      False   False  \n",
       "7      False   False  \n",
       "8       True    True  \n",
       "9       True    True  \n",
       "10      True   False  \n",
       "11     False   False  \n",
       "12     False   False  \n",
       "13     False   False  \n",
       "14      True   False  \n",
       "15     False   False  \n",
       "16     False   False  \n",
       "17     False   False  \n",
       "18      True    True  \n",
       "19      True   False  \n",
       "20     False   False  \n",
       "21     False   False  \n",
       "22     False   False  \n",
       "23     False   False  \n",
       "24     False   False  \n",
       "25      True    True  \n",
       "26     False   False  \n",
       "27     False   False  \n",
       "28     False   False  \n",
       "29     False   False  \n",
       "30     False   False  \n",
       "31      True    True  \n",
       "...      ...     ...  \n",
       "4913   False   False  \n",
       "4914   False   False  \n",
       "4915   False   False  \n",
       "4916   False   False  \n",
       "4917   False   False  \n",
       "4918   False   False  \n",
       "4919   False   False  \n",
       "4920    True   False  \n",
       "4921   False   False  \n",
       "4922   False   False  \n",
       "4923   False   False  \n",
       "4924   False   False  \n",
       "4925   False   False  \n",
       "4926   False   False  \n",
       "4927   False   False  \n",
       "4928   False   False  \n",
       "4929   False   False  \n",
       "4930    True   False  \n",
       "4931   False   False  \n",
       "4932   False   False  \n",
       "4933   False   False  \n",
       "4934   False   False  \n",
       "4935   False   False  \n",
       "4936   False   False  \n",
       "4937   False   False  \n",
       "4938   False   False  \n",
       "4939   False   False  \n",
       "4940   False   False  \n",
       "4941   False   False  \n",
       "4942   False   False  \n",
       "\n",
       "[4755 rows x 37 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open_change                       0.003460\n",
      "next_day_open_change             -0.003762\n",
      "open_change_wrt_close             0.005675\n",
      "next_day_open_change_wrt_close    0.001260\n",
      "high_change                      -0.004059\n",
      "low_change                       -0.003811\n",
      "volume_change                    -0.280394\n",
      "high_low_range                    0.529999\n",
      "close_change                      0.000631\n",
      "high_low_range_with_ref_close     0.016698\n",
      "high_low_range_with_ref_open      0.016614\n",
      "next_day_open_change_wrt_high    -0.003762\n",
      "next_day_open_change_wrt_low      0.013070\n",
      "Name: 4755, dtype: float64\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e6b9cb51f360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_input_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/skorch/classifier.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m    188\u001b[0m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0myp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0my_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mforward_iter\u001b[0;34m(self, X, training, device)\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m             \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, Xi, training)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/skorch/net.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_x_and_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-41b9b94023c9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#bp()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#bp()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;31m# type: (Tensor, Optional[Tuple[Tensor, Tensor]]) -> Tuple[Tensor, Tuple[Tensor, Tensor]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "test_input_df = nasdaq[chosen_features]\n",
    "test_input = test_input_df.loc[test_input_df.index.size]\n",
    "print(test_input)\n",
    "model.predict(test_input.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Net: 0.93\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.94       340\n",
      "          1       0.96      0.82      0.88       182\n",
      "\n",
      "avg / total       0.93      0.93      0.92       522\n",
      "\n",
      "Accuracy of Net: 0.78\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.87      0.83       113\n",
      "          1       0.73      0.62      0.67        64\n",
      "\n",
      "avg / total       0.78      0.78      0.78       177\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test = model.predict(x_train)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_train, prefix_information=model_name,\n",
    "                          dataset_name='train', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "plt.savefig(fname='latex/figures/' + 'LSTM_Training_results' + '.pdf', format='pdf', dpi=300)\n",
    "pred_test = model.predict(x_val)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_val, prefix_information=model_name,\n",
    "                          dataset_name='val', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "plt.savefig(fname='latex/figures/' + 'LSTM_Test_results' + '.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'module__C_k_p_s_1': ([2, 3, 1], [3, 0, 1], [4, 0, 1], [3, 3, 1], [2, 2, 1], [3, 1, 1], [4, 2, 1], [3, 3, 1], [2, 0, 1], [2, 1, 1]), 'module__C_k_p_s_2': ([4, 0, 1], [2, 1, 1], [2, 3, 1], [4, 0, 1], [2, 2, 1], [3, 2, 1], [2, 3, 1], [4, 2, 1], [2, 1, 1], [3, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "M = 10\n",
    "optimizer__lr= np.random.uniform(1e-2, 1e-4, M)\n",
    "weight_decay = np.random.uniform(1e-2,0.3 , M)\n",
    "optimizer__weight_decay = np.random.uniform(1e-2,0.3 , M)\n",
    "max_epochs = np.random.randint(2, 100, M)\n",
    "mid_layer_channels = np.array(np.random.uniform(5, 64, M), dtype=int)\n",
    "#batch_size = [4, 10, 20, 30]\n",
    "optimizers = (optim.SGD, optim.Adam)\n",
    "#C_k_p_s_1 = ([5, 0, 1],[4, 0, 1], [3, 0, 1], [2, 0, 1], [1, 0, 1])\n",
    "C_k_p_s_1 = tuple([[np.random.randint(2, 5, size=1)[0],np.random.randint(0, 4, size=1)[0], np.random.randint(1, 2, size=1)[0]]  for _ in range(M)])\n",
    "C_k_p_s_2 = tuple([[np.random.randint(2, 5, size=1)[0],np.random.randint(0, 4, size=1)[0], np.random.randint(1, 2, size=1)[0]]  for _ in range(M)])\n",
    "p = [np.random.uniform(0.0, 0.5, size=5) for _ in range(M)]\n",
    "p.append([0.1,0.1, 0.1, 0.1, 0.1])\n",
    "p.append([0.0,0.0, 0.0, 0.0, 0.0])\n",
    "p = tuple(p)\n",
    "#C_k_p_s_1 = [5, 0, 1], M_k_s_1 = [2, 2], C_k_p_s_2 = [5, 0, 1], M_k_s_2 = [2, 2] \n",
    "# mid_layer_channels=16 p=[0.1,0.1, 0.1, 0.1, 0.1]\n",
    "parameters = {#'optimizer__lr': optimizer__lr, \n",
    "    #'optimizer': optimizers, \n",
    "    #'optimizer__weight_decay': optimizer__weight_decay,\n",
    "    'module__C_k_p_s_1': C_k_p_s_1, \n",
    "    'module__C_k_p_s_2': C_k_p_s_2,\n",
    "    #'module__mid_layer_channels': mid_layer_channels, \n",
    "    #'module__p': p, \n",
    "    #'max_epochs': max_epochs\n",
    "}\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0000\u001b[0m        \u001b[32m0.5306\u001b[0m       \u001b[35m0.7794\u001b[0m        \u001b[31m0.5064\u001b[0m  0.1300\n",
      "      2  0.0000        \u001b[32m0.5091\u001b[0m       0.7794        0.5166  0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3  0.0000        \u001b[32m0.5083\u001b[0m       0.7794        0.5142  0.1328\n",
      "      4  0.0000        \u001b[32m0.5059\u001b[0m       0.7794        0.5068  0.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0.0000        \u001b[32m0.5031\u001b[0m       0.7794        \u001b[31m0.5041\u001b[0m  0.1332\n",
      "      6  0.0000        \u001b[32m0.5020\u001b[0m       0.7794        \u001b[31m0.5014\u001b[0m  0.1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        \u001b[32m0.5011\u001b[0m       0.7794        0.5041  0.1493\n",
      "      8  0.0000        0.5018       0.7794        0.5027  0.1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0000        \u001b[32m0.5000\u001b[0m       0.7794        0.5028  0.1477\n",
      "     10  0.0000        \u001b[32m0.5000\u001b[0m       0.7794        0.5015  0.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  0.0000        \u001b[32m0.4979\u001b[0m       0.7794        \u001b[31m0.5001\u001b[0m  0.1683\n",
      "     12  0.0000        \u001b[32m0.4978\u001b[0m       0.7794        0.5010  0.1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13  0.0000        \u001b[32m0.4972\u001b[0m       0.7794        0.5025  0.1540\n",
      "     14  \u001b[36m0.0492\u001b[0m        \u001b[32m0.4947\u001b[0m       \u001b[35m0.7832\u001b[0m        0.5014  0.1431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15  0.0331        \u001b[32m0.4939\u001b[0m       0.7813        \u001b[31m0.4993\u001b[0m  0.1486\n",
      "     16  \u001b[36m0.1481\u001b[0m        \u001b[32m0.4900\u001b[0m       \u001b[35m0.7850\u001b[0m        \u001b[31m0.4856\u001b[0m  0.1324\n",
      "     17  0.0794        \u001b[32m0.4798\u001b[0m       0.7832        \u001b[31m0.4746\u001b[0m  0.1440\n",
      "     18  \u001b[36m0.3106\u001b[0m        \u001b[32m0.4641\u001b[0m       \u001b[35m0.7925\u001b[0m        \u001b[31m0.4567\u001b[0m  0.1347\n",
      "     19  \u001b[36m0.4731\u001b[0m        \u001b[32m0.4504\u001b[0m       \u001b[35m0.8168\u001b[0m        \u001b[31m0.4477\u001b[0m  0.1326\n",
      "     20  \u001b[36m0.4848\u001b[0m        0.4554       0.8093        \u001b[31m0.4412\u001b[0m  0.1450\n",
      "     21  \u001b[36m0.5047\u001b[0m        0.4584       0.8019        \u001b[31m0.4393\u001b[0m  0.1454\n",
      "     22  0.5025        \u001b[32m0.4421\u001b[0m       0.8150        \u001b[31m0.4379\u001b[0m  0.1452\n",
      "     23  0.4951        \u001b[32m0.4293\u001b[0m       0.8056        0.4424  0.1461\n",
      "     24  0.5000        \u001b[32m0.4200\u001b[0m       0.8168        \u001b[31m0.4318\u001b[0m  0.1380\n",
      "     25  \u001b[36m0.5121\u001b[0m        0.4209       0.8112        0.4390  0.1418\n",
      "     26  \u001b[36m0.5297\u001b[0m        0.4238       0.8075        0.4484  0.1386\n",
      "     27  \u001b[36m0.5403\u001b[0m        0.4320       0.7869        0.4955  0.1455\n",
      "     28  \u001b[36m0.5417\u001b[0m        0.4302       0.7944        0.4615  0.1464\n",
      "     29  0.5417        \u001b[32m0.4129\u001b[0m       0.7944        0.4638  0.1495\n",
      "     30  0.5417        0.4150       0.7944        0.4544  0.1411\n",
      "     31  0.5394        \u001b[32m0.4081\u001b[0m       0.7925        0.4543  0.1483\n",
      "     32  \u001b[36m0.5462\u001b[0m        \u001b[32m0.4061\u001b[0m       0.7981        0.4572  0.1492\n",
      "     33  \u001b[36m0.5593\u001b[0m        \u001b[32m0.4007\u001b[0m       0.8056        0.4566  0.1475\n",
      "     34  0.5579        \u001b[32m0.3980\u001b[0m       0.8075        0.4487  0.1438\n",
      "     35  \u001b[36m0.5630\u001b[0m        0.4025       0.8056        0.4526  0.1404\n",
      "     36  0.5514        0.4000       \u001b[35m0.8206\u001b[0m        0.4342  0.1392\n",
      "     37  \u001b[36m0.5688\u001b[0m        \u001b[32m0.3936\u001b[0m       \u001b[35m0.8243\u001b[0m        \u001b[31m0.4299\u001b[0m  0.1271\n",
      "     38  \u001b[36m0.5714\u001b[0m        \u001b[32m0.3926\u001b[0m       0.8206        0.4432  0.1407\n",
      "     39  0.5676        \u001b[32m0.3914\u001b[0m       0.8206        0.4413  0.1353\n",
      "     40  0.5540        \u001b[32m0.3882\u001b[0m       0.8224        \u001b[31m0.4278\u001b[0m  0.1455\n",
      "     41  \u001b[36m0.5767\u001b[0m        \u001b[32m0.3826\u001b[0m       \u001b[35m0.8299\u001b[0m        0.4279  0.1399\n",
      "     42  0.5430        0.3839       0.8112        0.4433  0.1446\n",
      "     43  \u001b[36m0.5856\u001b[0m        0.3925       0.8280        \u001b[31m0.4202\u001b[0m  0.1356\n",
      "     44  0.5308        0.3919       0.8150        \u001b[31m0.4198\u001b[0m  0.1341\n",
      "     45  0.5797        0.3841       \u001b[35m0.8374\u001b[0m        0.4201  0.1308\n",
      "     46  0.5611        \u001b[32m0.3812\u001b[0m       0.8187        0.4263  0.1722\n",
      "     47  0.5660        0.3823       0.8280        0.4212  0.1842\n",
      "     48  0.5208        0.3863       0.8280        \u001b[31m0.4133\u001b[0m  0.1486\n",
      "     49  0.5687        \u001b[32m0.3742\u001b[0m       0.8299        0.4205  0.1680\n",
      "     50  \u001b[36m0.5877\u001b[0m        0.3802       0.8243        0.4235  0.1885\n",
      "     51  0.5766        0.3820       0.8243        0.4307  0.1705\n",
      "     52  0.5728        0.3795       0.8299        0.4212  0.1566\n",
      "     53  0.4918        0.3821       0.8262        0.4180  0.1341\n",
      "     54  0.5753        \u001b[32m0.3686\u001b[0m       0.8262        0.4261  0.1520\n",
      "     55  0.5455        0.3713       0.8131        0.4271  0.1542\n",
      "     56  0.5340        0.3767       0.8206        \u001b[31m0.4104\u001b[0m  0.1600\n",
      "     57  0.5411        0.3729       0.8224        0.4259  0.1436\n",
      "     58  0.5472        \u001b[32m0.3667\u001b[0m       0.8206        0.4245  0.1456\n",
      "     59  0.5530        \u001b[32m0.3647\u001b[0m       0.8187        0.4364  0.1268\n",
      "     60  0.5463        0.3691       0.8168        0.4314  0.1370\n",
      "     61  0.5507        0.3650       0.8262        0.4276  0.1621\n",
      "     62  0.5646        0.3666       0.8299        0.4231  0.1842\n",
      "     63  0.5611        \u001b[32m0.3620\u001b[0m       0.8187        0.4310  0.1735\n",
      "     64  0.5429        0.3651       0.8206        0.4242  0.2001\n",
      "     65  0.5388        0.3654       0.8112        0.4322  0.1445\n",
      "     66  0.5395        0.3639       0.8150        0.4353  0.1317\n",
      "     67  0.5439        0.3648       0.8056        0.4471  0.1368\n",
      "     68  0.5370        \u001b[32m0.3585\u001b[0m       0.8131        0.4375  0.1733\n",
      "     69  0.5687        0.3681       0.8299        \u001b[31m0.4064\u001b[0m  0.1924\n",
      "     70  0.5472        0.3646       0.8206        0.4295  0.1824\n",
      "     71  0.5274        0.3665       0.8224        0.4167  0.1663\n",
      "     72  0.5314        \u001b[32m0.3553\u001b[0m       0.8187        0.4241  0.1300\n",
      "     73  0.5024        0.3554       0.8037        0.4325  0.1419\n",
      "     74  0.5395        0.3614       0.8150        0.4378  0.1491\n",
      "     75  0.5118        \u001b[32m0.3532\u001b[0m       0.8075        0.4350  0.1255\n",
      "     76  0.5530        \u001b[32m0.3506\u001b[0m       0.8187        0.4413  0.1445\n",
      "     77  0.5268        0.3664       0.8019        0.4511  0.1421\n",
      "     78  0.5258        0.3543       0.8112        0.4371  0.1629\n",
      "     79  0.5253        \u001b[32m0.3476\u001b[0m       0.8075        0.4483  0.1603\n",
      "     80  0.5388        0.3505       0.8112        0.4456  0.1815\n",
      "     81  0.5234        0.3480       0.8093        0.4530  0.1846\n",
      "     82  0.5405        \u001b[32m0.3465\u001b[0m       0.8093        0.4572  0.1547\n",
      "     83  0.5217        0.3480       0.8150        0.4371  0.1348\n",
      "     84  0.4975        0.3504       0.8112        0.4420  0.1531\n",
      "     85  0.5352        \u001b[32m0.3422\u001b[0m       0.8150        0.4395  0.1845\n",
      "     86  0.5217        0.3491       0.8150        0.4325  0.1449\n",
      "     87  0.5070        \u001b[32m0.3390\u001b[0m       0.8037        0.4479  0.1599\n",
      "     88  0.5281        0.3490       0.7963        0.4568  0.1561\n",
      "     89  0.4930        0.3452       0.7963        0.4496  0.1368\n",
      "     90  0.5487        0.3531       0.8093        0.4600  0.1722\n",
      "     91  0.5249        0.3416       0.8037        0.4537  0.1606\n",
      "     92  0.5138        0.3433       0.8019        0.4415  0.1676\n",
      "     93  0.5024        0.3411       0.8037        0.4412  0.1614\n",
      "     94  0.5202        \u001b[32m0.3358\u001b[0m       0.8000        0.4520  0.1631\n",
      "     95  0.5214        0.3398       0.7907        0.4614  0.1507\n",
      "     96  0.5225        0.3492       0.8019        0.4352  0.1346\n",
      "     97  0.4887        \u001b[32m0.3342\u001b[0m       0.7888        0.4457  0.1476\n",
      "     98  0.5315        0.3343       0.8056        0.4586  0.1452\n",
      "     99  0.5240        \u001b[32m0.3300\u001b[0m       0.7963        0.4664  0.1351\n",
      "    100  0.5232        \u001b[32m0.3298\u001b[0m       0.7888        0.4764  0.1370\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0000\u001b[0m        \u001b[32m0.5529\u001b[0m       \u001b[35m0.7888\u001b[0m        \u001b[31m0.5163\u001b[0m  0.1302\n",
      "      2  \u001b[36m0.0667\u001b[0m        \u001b[32m0.5101\u001b[0m       \u001b[35m0.7907\u001b[0m        \u001b[31m0.5033\u001b[0m  0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3  0.0000        \u001b[32m0.4993\u001b[0m       0.7888        0.5134  0.1516\n",
      "      4  0.0000        \u001b[32m0.4939\u001b[0m       0.7888        0.5117  0.1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0000\u001b[0m        \u001b[32m0.5355\u001b[0m       \u001b[35m0.7925\u001b[0m        \u001b[31m0.5023\u001b[0m  0.1445\n",
      "      2  0.0000        \u001b[32m0.4960\u001b[0m       0.7925        \u001b[31m0.4954\u001b[0m  0.1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3  0.0000        \u001b[32m0.4875\u001b[0m       0.7925        \u001b[31m0.4944\u001b[0m  0.1478\n",
      "      4  0.0000        \u001b[32m0.4847\u001b[0m       0.7925        0.4965  0.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0.0000        \u001b[32m0.4840\u001b[0m       0.7925        0.4990  0.1379\n",
      "      6  0.0000        0.4857       0.7925        0.5016  0.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        0.4877       0.7925        0.4981  0.1519\n",
      "      8  0.0000        0.4854       0.7925        0.4978  0.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0000        \u001b[32m0.4822\u001b[0m       0.7925        0.4987  0.1650\n",
      "     10  0.0000        \u001b[32m0.4798\u001b[0m       0.7925        0.4979  0.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  \u001b[36m0.0513\u001b[0m        \u001b[32m0.4792\u001b[0m       0.7925        0.4971  0.1326\n",
      "     12  \u001b[36m0.0522\u001b[0m        0.4796       \u001b[35m0.7963\u001b[0m        \u001b[31m0.4940\u001b[0m  0.1378\n",
      "     13  0.0179        \u001b[32m0.4788\u001b[0m       0.7944        0.4945  0.1699\n",
      "     14  0.0351        \u001b[32m0.4767\u001b[0m       0.7944        \u001b[31m0.4918\u001b[0m  0.1462\n",
      "     15  \u001b[36m0.0678\u001b[0m        \u001b[32m0.4734\u001b[0m       0.7944        \u001b[31m0.4892\u001b[0m  0.1414\n",
      "     16  0.0513        \u001b[32m0.4732\u001b[0m       0.7925        0.4906  0.1849\n",
      "     17  \u001b[36m0.0833\u001b[0m        \u001b[32m0.4658\u001b[0m       0.7944        \u001b[31m0.4827\u001b[0m  0.1743\n",
      "     18  \u001b[36m0.1270\u001b[0m        \u001b[32m0.4583\u001b[0m       0.7944        \u001b[31m0.4770\u001b[0m  0.1649\n",
      "     19  \u001b[36m0.2958\u001b[0m        \u001b[32m0.4491\u001b[0m       \u001b[35m0.8131\u001b[0m        \u001b[31m0.4710\u001b[0m  0.1710\n",
      "     20  \u001b[36m0.3537\u001b[0m        \u001b[32m0.4410\u001b[0m       0.8019        \u001b[31m0.4707\u001b[0m  0.1761\n",
      "     21  \u001b[36m0.3908\u001b[0m        \u001b[32m0.4325\u001b[0m       0.8019        \u001b[31m0.4623\u001b[0m  0.1584\n",
      "     22  \u001b[36m0.4815\u001b[0m        0.4329       0.7907        0.4902  0.1690\n",
      "     23  0.4410        \u001b[32m0.4297\u001b[0m       0.7963        0.4707  0.1861\n",
      "     24  0.4700        \u001b[32m0.4226\u001b[0m       0.8019        0.4725  0.1906\n",
      "     25  0.4623        \u001b[32m0.4193\u001b[0m       0.8000        0.4729  0.1896\n",
      "     26  0.4523        0.4210       0.7963        0.4724  0.1752\n",
      "     27  0.4335        \u001b[32m0.4181\u001b[0m       0.7850        0.4762  0.1787\n",
      "     28  0.4600        \u001b[32m0.4163\u001b[0m       0.7981        0.4753  0.1312\n",
      "     29  0.4301        0.4184       0.8019        \u001b[31m0.4595\u001b[0m  0.1313\n",
      "     30  0.4072        \u001b[32m0.4121\u001b[0m       \u001b[35m0.8150\u001b[0m        \u001b[31m0.4524\u001b[0m  0.1462\n",
      "     31  0.3911        \u001b[32m0.4107\u001b[0m       0.7963        0.4591  0.1315\n",
      "     32  0.4481        0.4111       0.8112        0.4565  0.1437\n",
      "     33  0.3648        0.4116       0.8112        \u001b[31m0.4461\u001b[0m  0.1393\n",
      "     34  0.3613        \u001b[32m0.4082\u001b[0m       0.8150        \u001b[31m0.4461\u001b[0m  0.1339\n",
      "     35  0.3553        \u001b[32m0.4042\u001b[0m       \u001b[35m0.8168\u001b[0m        \u001b[31m0.4411\u001b[0m  0.1487\n",
      "     36  0.4246        \u001b[32m0.4037\u001b[0m       0.8075        0.4523  0.1403\n",
      "     37  0.4694        \u001b[32m0.4033\u001b[0m       0.8056        0.4558  0.1453\n",
      "     38  0.4024        0.4054       0.8168        0.4459  0.1456\n",
      "     39  0.3265        \u001b[32m0.3991\u001b[0m       0.8150        \u001b[31m0.4395\u001b[0m  0.1495\n",
      "     40  0.3774        0.4013       0.8150        \u001b[31m0.4382\u001b[0m  0.1424\n",
      "     41  0.3733        0.4005       \u001b[35m0.8243\u001b[0m        0.4397  0.1363\n",
      "     42  0.2837        0.4022       0.8112        0.4503  0.1470\n",
      "     43  0.3871        0.4008       0.8224        0.4412  0.1391\n",
      "     44  0.3514        \u001b[32m0.3959\u001b[0m       0.8206        \u001b[31m0.4357\u001b[0m  0.1442\n",
      "     45  0.3871        \u001b[32m0.3942\u001b[0m       0.8224        0.4431  0.1343\n",
      "     46  0.3867        \u001b[32m0.3917\u001b[0m       \u001b[35m0.8280\u001b[0m        0.4423  0.1399\n",
      "     47  0.2878        0.3937       0.8150        0.4516  0.1278\n",
      "     48  0.3239        0.3945       0.8206        0.4530  0.1274\n",
      "     49  0.3380        0.3989       0.8243        0.4482  0.1279\n",
      "     50  0.2537        0.3925       0.8131        0.4544  0.1276\n",
      "     51  0.3194        0.3966       0.8168        0.4410  0.1286\n",
      "     52  0.3022        0.3929       0.8187        0.4527  0.1280\n",
      "     53  0.3022        0.3986       0.8187        0.4541  0.1393\n",
      "     54  0.3239        0.3967       0.8206        0.4457  0.1345\n",
      "     55  0.2958        0.4024       0.8131        0.4429  0.1409\n",
      "     56  0.3704        0.4097       0.8093        0.4436  0.1493\n",
      "     57  0.4235        0.3993       0.8168        0.4444  0.1509\n",
      "     58  0.3401        0.4008       0.8187        \u001b[31m0.4301\u001b[0m  0.1312\n",
      "     59  0.4407        0.3953       0.8150        0.4374  0.1267\n",
      "     60  0.4074        0.3983       0.8206        \u001b[31m0.4295\u001b[0m  0.1432\n",
      "     61  0.4458        0.3975       0.8280        0.4352  0.1410\n",
      "     62  0.4224        0.3942       0.8262        0.4363  0.1457\n",
      "     63  0.4049        0.4026       0.8187        0.4412  0.1363\n",
      "     64  0.3791        0.3921       0.8224        0.4409  0.1411\n",
      "     65  0.3949        0.3936       0.8224        0.4408  0.1432\n",
      "     66  0.3974        \u001b[32m0.3892\u001b[0m       0.8243        0.4423  0.1386\n",
      "     67  0.4294        0.4034       0.8262        0.4502  0.1480\n",
      "     68  0.4172        \u001b[32m0.3885\u001b[0m       0.8224        0.4440  0.1525\n",
      "     69  0.4172        \u001b[32m0.3832\u001b[0m       0.8224        0.4404  0.1866\n",
      "     70  0.3562        0.3853       0.8243        0.4477  0.1975\n",
      "     71  0.4000        0.3850       0.8262        0.4394  0.1477\n",
      "     72  0.3867        \u001b[32m0.3816\u001b[0m       0.8280        0.4411  0.1315\n",
      "     73  0.3586        0.3837       0.8262        0.4524  0.1435\n",
      "     74  0.3699        0.3824       0.8280        0.4628  0.1455\n",
      "     75  0.3562        0.3837       0.8243        0.4498  0.1342\n",
      "     76  0.4000        0.3885       0.8262        0.4525  0.1350\n",
      "     77  0.4364        0.3933       0.8262        0.4490  0.1760\n",
      "     78  0.4129        \u001b[32m0.3801\u001b[0m       \u001b[35m0.8299\u001b[0m        0.4385  0.1995\n",
      "     79  0.4699        0.3812       \u001b[35m0.8355\u001b[0m        0.4444  0.1913\n",
      "     80  0.4198        0.3812       0.8243        0.4452  0.1737\n",
      "     81  0.4417        0.3862       0.8299        0.4470  0.1856\n",
      "     82  0.4385        0.3824       0.8037        0.4634  0.1615\n",
      "     83  0.4260        0.3808       0.8187        0.4380  0.1381\n",
      "     84  0.4509        \u001b[32m0.3755\u001b[0m       0.8224        0.4474  0.1665\n",
      "     85  0.4444        0.3787       0.8224        0.4454  0.1861\n",
      "     86  0.4211        \u001b[32m0.3733\u001b[0m       0.8150        0.4512  0.1478\n",
      "     87  0.4103        0.3749       0.8280        0.4522  0.1333\n",
      "     88  \u001b[36m0.4914\u001b[0m        \u001b[32m0.3678\u001b[0m       0.8336        0.4499  0.1826\n",
      "     89  0.4751        \u001b[32m0.3641\u001b[0m       0.8224        0.4458  0.1528\n",
      "     90  0.4641        0.3694       0.8187        0.4511  0.1400\n",
      "     91  0.4699        0.3696       0.8187        0.4609  0.1727\n",
      "     92  0.4432        0.3724       0.8168        0.4478  0.1659\n",
      "     93  0.4253        0.3698       0.8131        0.4453  0.1626\n",
      "     94  0.4421        0.3700       0.8019        0.4632  0.1450\n",
      "     95  0.4831        0.3751       0.8280        0.4552  0.1500\n",
      "     96  \u001b[36m0.4920\u001b[0m        0.3684       0.8224        0.4519  0.1716\n",
      "     97  0.4674        0.3662       0.8168        0.4555  0.1348\n",
      "     98  0.4444        0.3683       0.8131        0.4673  0.1664\n",
      "     99  0.4724        0.3722       0.8037        0.4768  0.1454\n",
      "    100  0.4688        0.3682       0.8093        0.4819  0.1601\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.1884\u001b[0m        \u001b[32m0.5509\u001b[0m       \u001b[35m0.7907\u001b[0m        \u001b[31m0.5023\u001b[0m  0.1251\n",
      "      2  0.0000        \u001b[32m0.5087\u001b[0m       0.7794        0.5060  0.1499\n",
      "      3  0.0000        0.5090       0.7794        0.5085  0.1653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4  0.0000        \u001b[32m0.5079\u001b[0m       0.7794        0.5146  0.1688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0.0000        \u001b[32m0.5052\u001b[0m       0.7794        0.5074  0.1882\n",
      "      6  0.0000        \u001b[32m0.5029\u001b[0m       0.7794        0.5041  0.1625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        \u001b[32m0.5021\u001b[0m       0.7794        0.5045  0.1851\n",
      "      8  0.0000        \u001b[32m0.5019\u001b[0m       0.7794        \u001b[31m0.5014\u001b[0m  0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0000        \u001b[32m0.5001\u001b[0m       0.7794        0.5082  0.1574\n",
      "     10  0.0000        0.5016       0.7794        0.5028  0.1406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  0.0000        \u001b[32m0.4994\u001b[0m       0.7794        0.5016  0.2014\n",
      "     12  0.0000        0.5038       0.7794        0.5273  0.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13  0.0000        0.5046       0.7794        0.5054  0.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     14  0.0000        \u001b[32m0.4984\u001b[0m       0.7794        0.5014  0.1849\n",
      "     15  0.0000        \u001b[32m0.4972\u001b[0m       0.7794        \u001b[31m0.4989\u001b[0m  0.1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16  0.0000        \u001b[32m0.4956\u001b[0m       0.7794        \u001b[31m0.4982\u001b[0m  0.1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17  0.0000        \u001b[32m0.4942\u001b[0m       0.7794        0.4992  0.1827\n",
      "     18  0.0000        \u001b[32m0.4937\u001b[0m       0.7794        0.4983  0.1569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19  0.0000        \u001b[32m0.4921\u001b[0m       0.7794        0.5002  0.1878\n",
      "     20  0.0000        \u001b[32m0.4910\u001b[0m       0.7794        0.5040  0.1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     21  0.0000        \u001b[32m0.4905\u001b[0m       0.7794        0.5033  0.1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22  0.0000        \u001b[32m0.4884\u001b[0m       0.7794        0.4988  0.1795\n",
      "     23  0.0000        \u001b[32m0.4832\u001b[0m       0.7794        \u001b[31m0.4953\u001b[0m  0.1514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24  0.0000        \u001b[32m0.4765\u001b[0m       0.7794        \u001b[31m0.4842\u001b[0m  0.1480\n",
      "     25  0.0000        \u001b[32m0.4683\u001b[0m       0.7794        0.4964  0.1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     26  \u001b[36m0.4737\u001b[0m        0.4690       \u001b[35m0.8131\u001b[0m        0.4858  0.1797\n",
      "     27  0.3727        \u001b[32m0.4683\u001b[0m       0.8112        \u001b[31m0.4626\u001b[0m  0.1783\n",
      "     28  \u001b[36m0.4900\u001b[0m        \u001b[32m0.4585\u001b[0m       0.8093        0.4861  0.1470\n",
      "     29  0.4615        0.4671       \u001b[35m0.8168\u001b[0m        0.5007  0.1336\n",
      "     30  0.4167        0.4610       0.8168        0.4648  0.1740\n",
      "     31  0.4878        \u001b[32m0.4536\u001b[0m       0.8037        0.4746  0.1555\n",
      "     32  \u001b[36m0.4902\u001b[0m        \u001b[32m0.4518\u001b[0m       0.8056        \u001b[31m0.4598\u001b[0m  0.1406\n",
      "     33  \u001b[36m0.5130\u001b[0m        \u001b[32m0.4415\u001b[0m       0.7907        0.4745  0.1473\n",
      "     34  0.5045        0.4530       0.7944        0.4810  0.1776\n",
      "     35  0.5026        0.4483       \u001b[35m0.8224\u001b[0m        \u001b[31m0.4574\u001b[0m  0.1496\n",
      "     36  \u001b[36m0.5244\u001b[0m        \u001b[32m0.4335\u001b[0m       0.8000        0.4795  0.1344\n",
      "     37  0.5138        \u001b[32m0.4312\u001b[0m       0.8019        0.4627  0.1734\n",
      "     38  0.5133        \u001b[32m0.4303\u001b[0m       0.7944        0.4753  0.1478\n",
      "     39  0.4955        \u001b[32m0.4286\u001b[0m       0.7907        0.4724  0.1434\n",
      "     40  0.4683        \u001b[32m0.4230\u001b[0m       0.7963        0.4669  0.1879\n",
      "     41  0.5140        \u001b[32m0.4179\u001b[0m       0.8056        0.4634  0.1507\n",
      "     42  0.4906        \u001b[32m0.4149\u001b[0m       0.7981        \u001b[31m0.4545\u001b[0m  0.1678\n",
      "     43  0.5188        \u001b[32m0.4100\u001b[0m       0.7850        0.4690  0.1461\n",
      "     44  0.5067        0.4196       0.7925        0.4705  0.1379\n",
      "     45  0.4898        0.4151       0.8131        \u001b[31m0.4535\u001b[0m  0.1852\n",
      "     46  0.5000        0.4123       0.8093        \u001b[31m0.4504\u001b[0m  0.1476\n",
      "     47  0.5000        \u001b[32m0.4043\u001b[0m       0.8056        0.4521  0.1838\n",
      "     48  0.5075        \u001b[32m0.4020\u001b[0m       0.8150        0.4531  0.1500\n",
      "     49  0.4776        0.4055       0.8037        0.4566  0.1610\n",
      "     50  0.5213        \u001b[32m0.4014\u001b[0m       0.8112        0.4605  0.1696\n",
      "     51  0.4742        0.4062       0.8093        0.4615  0.1657\n",
      "     52  0.5185        \u001b[32m0.3956\u001b[0m       0.8056        0.4676  0.1655\n",
      "     53  0.4974        \u001b[32m0.3937\u001b[0m       0.8187        0.4622  0.1546\n",
      "     54  0.4873        \u001b[32m0.3923\u001b[0m       0.8112        \u001b[31m0.4471\u001b[0m  0.1633\n",
      "     55  0.4952        \u001b[32m0.3888\u001b[0m       0.8019        0.4604  0.1396\n",
      "     56  0.5000        0.3932       0.8131        0.4573  0.1765\n",
      "     57  0.5243        0.3901       0.8168        0.4521  0.1492\n",
      "     58  0.4737        0.3907       0.8131        0.4564  0.1577\n",
      "     59  \u001b[36m0.5283\u001b[0m        \u001b[32m0.3839\u001b[0m       0.8131        0.4599  0.1472\n",
      "     60  0.5283        \u001b[32m0.3814\u001b[0m       0.8131        0.4572  0.1754\n",
      "     61  \u001b[36m0.5286\u001b[0m        0.3817       0.8000        0.4637  0.1573\n",
      "     62  0.4876        0.3836       0.8075        0.4558  0.1520\n",
      "     63  0.4926        0.3868       0.8075        0.4633  0.1701\n",
      "     64  0.4898        0.4006       0.8131        \u001b[31m0.4307\u001b[0m  0.1626\n",
      "     65  0.5172        0.4005       0.7907        0.4739  0.1604\n",
      "     66  0.5126        0.3923       0.8187        0.4600  0.1591\n",
      "     67  0.4956        \u001b[32m0.3776\u001b[0m       0.7869        0.4731  0.1728\n",
      "     68  0.5273        \u001b[32m0.3770\u001b[0m       0.8056        0.4601  0.1615\n",
      "     69  0.5114        \u001b[32m0.3694\u001b[0m       0.8000        0.4663  0.1654\n",
      "     70  \u001b[36m0.5297\u001b[0m        0.3760       0.8075        0.4605  0.1418\n",
      "     71  0.5023        0.3734       0.7963        0.4792  0.1737\n",
      "     72  0.5258        0.3739       0.8112        0.4455  0.1686\n",
      "     73  0.5253        \u001b[32m0.3671\u001b[0m       0.8075        0.4493  0.1392\n",
      "     74  0.4977        \u001b[32m0.3648\u001b[0m       0.8000        0.4497  0.1700\n",
      "     75  0.5123        0.3741       0.8150        0.4617  0.1385\n",
      "     76  0.4979        \u001b[32m0.3624\u001b[0m       0.7776        0.4811  0.1661\n",
      "     77  \u001b[36m0.5438\u001b[0m        0.3630       0.8150        0.4539  0.1634\n",
      "     78  0.5299        \u001b[32m0.3515\u001b[0m       0.7944        0.4779  0.1689\n",
      "     79  0.5091        \u001b[32m0.3514\u001b[0m       0.7981        0.4585  0.1521\n",
      "     80  0.5158        0.3522       0.8000        0.4544  0.1611\n",
      "     81  0.5240        0.3538       0.7963        0.4768  0.1605\n",
      "     82  0.5089        0.3561       0.7944        0.4747  0.1812\n",
      "     83  0.4887        \u001b[32m0.3426\u001b[0m       0.7888        0.4849  0.1647\n",
      "     84  0.4935        0.3442       0.7813        0.4762  0.1454\n",
      "     85  0.5064        0.3463       0.7850        0.4908  0.1594\n",
      "     86  0.4933        0.3568       0.7888        0.4892  0.1715\n",
      "     87  0.4385        0.3935       0.8037        0.5201  0.1801\n",
      "     88  0.4828        0.3750       0.8037        0.4669  0.1531\n",
      "     89  0.5258        0.3480       0.8112        0.4816  0.1675\n",
      "     90  0.5205        \u001b[32m0.3418\u001b[0m       0.8037        0.5131  0.1275\n",
      "     91  0.5339        0.3420       0.8075        0.4949  0.1674\n",
      "     92  0.5000        \u001b[32m0.3326\u001b[0m       0.7869        0.4925  0.1521\n",
      "     93  0.5126        0.3337       0.7832        0.5354  0.1305\n",
      "     94  0.5118        0.3524       0.7682        0.5437  0.1356\n",
      "     95  0.4976        0.3476       0.8037        0.4837  0.1462\n",
      "     96  0.4874        0.3484       0.7720        0.5071  0.1458\n",
      "     97  0.4907        0.3544       0.7944        0.4828  0.1374\n",
      "     98  0.5000        0.3533       0.8056        0.4887  0.1755\n",
      "     99  0.5161        0.3519       0.8037        0.4780  0.1826\n",
      "    100  0.4796        0.3561       0.8093        0.5480  0.1433\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0000\u001b[0m        \u001b[32m0.6610\u001b[0m       \u001b[35m0.7888\u001b[0m        \u001b[31m0.5083\u001b[0m  0.1355\n",
      "      2  0.0000        \u001b[32m0.5035\u001b[0m       0.7888        0.5131  0.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3  0.0000        \u001b[32m0.4949\u001b[0m       0.7888        0.5168  0.1861\n",
      "      4  0.0000        \u001b[32m0.4937\u001b[0m       0.7888        0.5178  0.1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0.0000        \u001b[32m0.4926\u001b[0m       0.7888        0.5175  0.1430\n",
      "      6  0.0000        \u001b[32m0.4920\u001b[0m       0.7888        0.5169  0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        \u001b[32m0.4914\u001b[0m       0.7888        0.5176  0.1276\n",
      "      8  0.0000        0.4915       0.7888        0.5171  0.1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0000        \u001b[32m0.4904\u001b[0m       0.7888        0.5166  0.1340\n",
      "     10  0.0000        \u001b[32m0.4899\u001b[0m       0.7888        0.5165  0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  0.0000        \u001b[32m0.4894\u001b[0m       0.7888        0.5169  0.1464\n",
      "     12  0.0000        0.4896       0.7888        0.5176  0.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13  0.0000        \u001b[32m0.4888\u001b[0m       0.7888        0.5150  0.1336\n",
      "     14  0.0000        0.4889       0.7888        0.5156  0.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15  \u001b[36m0.0175\u001b[0m        0.4902       \u001b[35m0.7907\u001b[0m        0.5177  0.1447\n",
      "     16  \u001b[36m0.0504\u001b[0m        \u001b[32m0.4846\u001b[0m       0.7888        0.5161  0.1328\n",
      "     17  \u001b[36m0.0656\u001b[0m        0.4848       0.7869        0.5113  0.1444\n",
      "     18  \u001b[36m0.1260\u001b[0m        \u001b[32m0.4799\u001b[0m       \u001b[35m0.7925\u001b[0m        \u001b[31m0.5044\u001b[0m  0.1861\n",
      "     19  0.0656        \u001b[32m0.4770\u001b[0m       0.7869        \u001b[31m0.4958\u001b[0m  0.1919\n",
      "     20  \u001b[36m0.1926\u001b[0m        \u001b[32m0.4685\u001b[0m       \u001b[35m0.7963\u001b[0m        \u001b[31m0.4829\u001b[0m  0.1398\n",
      "     21  \u001b[36m0.2361\u001b[0m        \u001b[32m0.4622\u001b[0m       0.7944        0.4842  0.1271\n",
      "     22  \u001b[36m0.3165\u001b[0m        \u001b[32m0.4557\u001b[0m       \u001b[35m0.7981\u001b[0m        \u001b[31m0.4694\u001b[0m  0.1316\n",
      "     23  0.2411        0.4611       \u001b[35m0.8000\u001b[0m        0.4931  0.1305\n",
      "     24  0.2676        \u001b[32m0.4475\u001b[0m       \u001b[35m0.8056\u001b[0m        0.4864  0.1457\n",
      "     25  0.2981        \u001b[32m0.4457\u001b[0m       0.7888        0.4990  0.1724\n",
      "     26  \u001b[36m0.4468\u001b[0m        0.4487       0.8056        0.4950  0.1576\n",
      "     27  \u001b[36m0.4523\u001b[0m        \u001b[32m0.4453\u001b[0m       0.7963        0.4913  0.1716\n",
      "     28  0.4513        \u001b[32m0.4396\u001b[0m       0.8000        0.4879  0.1590\n",
      "     29  0.4330        \u001b[32m0.4343\u001b[0m       0.7944        0.4878  0.1290\n",
      "     30  0.4385        \u001b[32m0.4324\u001b[0m       0.8037        0.4901  0.1295\n",
      "     31  0.4420        \u001b[32m0.4273\u001b[0m       \u001b[35m0.8112\u001b[0m        0.4810  0.1682\n",
      "     32  0.3842        0.4280       0.7963        0.4868  0.1698\n",
      "     33  \u001b[36m0.4656\u001b[0m        \u001b[32m0.4260\u001b[0m       0.8112        0.4910  0.1595\n",
      "     34  0.4372        \u001b[32m0.4248\u001b[0m       0.8075        0.4824  0.1625\n",
      "     35  0.4656        \u001b[32m0.4213\u001b[0m       0.8112        0.4935  0.1365\n",
      "     36  0.4592        \u001b[32m0.4187\u001b[0m       0.8019        0.4912  0.1349\n",
      "     37  0.4615        0.4212       0.7907        0.4974  0.1788\n",
      "     38  0.4554        0.4187       0.7720        0.5001  0.1623\n",
      "     39  0.4364        \u001b[32m0.4161\u001b[0m       0.7682        0.5143  0.1810\n",
      "     40  0.4593        \u001b[32m0.4156\u001b[0m       0.7888        0.4961  0.1354\n",
      "     41  0.4609        \u001b[32m0.4068\u001b[0m       0.7682        0.4934  0.1300\n",
      "     42  0.4653        \u001b[32m0.4052\u001b[0m       0.7981        0.4869  0.1259\n",
      "     43  \u001b[36m0.4825\u001b[0m        0.4065       0.7794        0.4914  0.1686\n",
      "     44  0.4771        0.4070       0.7869        0.4907  0.1812\n",
      "     45  \u001b[36m0.5106\u001b[0m        0.4085       0.7850        0.5019  0.1458\n",
      "     46  0.4825        \u001b[32m0.4014\u001b[0m       0.7794        0.4989  0.1265\n",
      "     47  0.4848        0.4054       0.7776        \u001b[31m0.4685\u001b[0m  0.1409\n",
      "     48  0.4762        \u001b[32m0.3950\u001b[0m       0.7944        0.4708  0.1464\n",
      "     49  0.4456        0.4021       0.8000        0.4721  0.1706\n",
      "     50  0.4695        0.4091       0.7888        0.5005  0.1551\n",
      "     51  0.4388        \u001b[32m0.3929\u001b[0m       0.7944        0.4759  0.1666\n",
      "     52  0.4590        0.4022       \u001b[35m0.8150\u001b[0m        0.4688  0.1681\n",
      "     53  0.5045        0.3933       0.7944        0.4942  0.1428\n",
      "     54  \u001b[36m0.5138\u001b[0m        \u001b[32m0.3905\u001b[0m       0.8019        0.4861  0.1412\n",
      "     55  0.4951        \u001b[32m0.3861\u001b[0m       0.8056        \u001b[31m0.4650\u001b[0m  0.1540\n",
      "     56  0.4481        0.3877       0.8112        0.4754  0.1823\n",
      "     57  0.3787        0.3872       0.8037        0.4708  0.1439\n",
      "     58  0.4579        \u001b[32m0.3861\u001b[0m       0.7832        0.5247  0.1440\n",
      "     59  0.4793        0.3888       0.7888        0.5184  0.1688\n",
      "     60  0.5094        0.3943       0.8056        \u001b[31m0.4607\u001b[0m  0.1554\n",
      "     61  0.4758        \u001b[32m0.3757\u001b[0m       0.7776        0.4958  0.1542\n",
      "     62  0.4623        0.3839       0.8000        \u001b[31m0.4594\u001b[0m  0.1730\n",
      "     63  \u001b[36m0.5345\u001b[0m        0.3815       0.7981        0.5113  0.1685\n",
      "     64  0.4937        0.3824       0.7738        0.5122  0.1690\n",
      "     65  0.5023        0.3800       0.7963        0.4995  0.1551\n",
      "     66  0.4789        0.3763       0.7925        0.5109  0.1407\n",
      "     67  0.5198        \u001b[32m0.3746\u001b[0m       0.7963        0.4893  0.1359\n",
      "     68  0.5333        0.3758       0.7907        0.5000  0.1534\n",
      "     69  0.5152        0.3786       \u001b[35m0.8206\u001b[0m        \u001b[31m0.4353\u001b[0m  0.1761\n",
      "     70  0.5042        \u001b[32m0.3743\u001b[0m       0.7794        0.4972  0.1836\n",
      "     71  0.4943        \u001b[32m0.3696\u001b[0m       0.7514        0.5483  0.1526\n",
      "     72  0.5263        \u001b[32m0.3683\u001b[0m       0.7645        0.5442  0.1259\n",
      "     73  0.5311        0.3756       0.7888        0.4936  0.1284\n",
      "     74  \u001b[36m0.5397\u001b[0m        0.3729       0.7832        0.5008  0.1399\n",
      "     75  \u001b[36m0.5430\u001b[0m        0.3735       0.8112        0.4615  0.1521\n",
      "     76  0.5195        0.3692       0.7925        0.4833  0.1636\n",
      "     77  0.5388        \u001b[32m0.3645\u001b[0m       0.8112        0.4607  0.1814\n",
      "     78  \u001b[36m0.5487\u001b[0m        0.3666       0.8093        \u001b[31m0.4332\u001b[0m  0.1472\n",
      "     79  0.5277        0.3689       0.7925        0.4707  0.1289\n",
      "     80  0.5310        \u001b[32m0.3640\u001b[0m       0.8019        0.4688  0.1416\n",
      "     81  0.5167        \u001b[32m0.3613\u001b[0m       0.7832        0.4757  0.1459\n",
      "     82  0.5069        0.3685       0.8000        0.4364  0.1395\n",
      "     83  \u001b[36m0.5590\u001b[0m        0.3716       0.8112        \u001b[31m0.4270\u001b[0m  0.1702\n",
      "     84  0.5545        \u001b[32m0.3551\u001b[0m       0.8168        \u001b[31m0.4212\u001b[0m  0.1774\n",
      "     85  0.5240        0.3559       0.7963        0.4633  0.1555\n",
      "     86  0.5289        0.3608       0.7869        0.4988  0.1258\n",
      "     87  \u001b[36m0.5677\u001b[0m        0.3559       0.8150        0.4390  0.1345\n",
      "     88  0.5628        0.3636       0.8112        0.4600  0.1442\n",
      "     89  0.5236        \u001b[32m0.3518\u001b[0m       0.7925        0.5177  0.1466\n",
      "     90  0.5302        0.3613       0.8112        0.4420  0.1753\n",
      "     91  \u001b[36m0.5714\u001b[0m        \u001b[32m0.3500\u001b[0m       0.8206        \u001b[31m0.4189\u001b[0m  0.1670\n",
      "     92  0.5613        0.3516       0.7925        0.4706  0.1574\n",
      "     93  0.5408        \u001b[32m0.3480\u001b[0m       0.8000        0.4769  0.1337\n",
      "     94  \u001b[36m0.5887\u001b[0m        0.3500       \u001b[35m0.8224\u001b[0m        0.4632  0.1399\n",
      "     95  0.5702        \u001b[32m0.3399\u001b[0m       0.8056        0.4545  0.1466\n",
      "     96  0.5872        0.3431       0.8187        0.4413  0.1451\n",
      "     97  0.5804        \u001b[32m0.3355\u001b[0m       \u001b[35m0.8243\u001b[0m        0.4346  0.1293\n",
      "     98  0.5727        0.3450       0.8187        0.4658  0.1393\n",
      "     99  0.5308        0.3554       0.8150        0.4482  0.1349\n",
      "    100  \u001b[36m0.5963\u001b[0m        0.3509       \u001b[35m0.8355\u001b[0m        \u001b[31m0.3916\u001b[0m  0.1683\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0517\u001b[0m        \u001b[32m0.5306\u001b[0m       \u001b[35m0.7944\u001b[0m        \u001b[31m0.4982\u001b[0m  0.1530\n",
      "      2  \u001b[36m0.1791\u001b[0m        \u001b[32m0.5018\u001b[0m       0.7944        0.5002  0.1527\n",
      "      3  0.0000        \u001b[32m0.4857\u001b[0m       0.7925        0.5002  0.1461\n",
      "      4  0.0000        \u001b[32m0.4837\u001b[0m       0.7925        0.4986  0.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0.0000        0.4843       0.7925        0.4986  0.1509\n",
      "      6  0.0000        \u001b[32m0.4826\u001b[0m       0.7925        \u001b[31m0.4981\u001b[0m  0.1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        \u001b[32m0.4819\u001b[0m       0.7925        \u001b[31m0.4971\u001b[0m  0.1476\n",
      "      8  0.0000        \u001b[32m0.4814\u001b[0m       0.7925        0.4976  0.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0000        \u001b[32m0.4813\u001b[0m       0.7925        0.4987  0.1481\n",
      "     10  0.0000        \u001b[32m0.4808\u001b[0m       0.7925        0.4992  0.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  0.0000        0.4812       0.7925        0.5006  0.1347\n",
      "     12  0.0000        0.4819       0.7925        0.5009  0.1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13  0.0000        0.4829       0.7925        0.5058  0.1352\n",
      "     14  0.0000        0.4846       0.7925        0.5031  0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15  0.0000        0.4812       0.7925        0.5033  0.1350\n",
      "     16  0.0000        0.4841       0.7925        0.5009  0.1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17  0.0000        0.4824       0.7925        0.5075  0.1357\n",
      "     18  0.0000        0.4836       0.7925        0.5015  0.1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19  0.0000        0.4827       0.7925        0.5024  0.1310\n",
      "     20  0.0000        \u001b[32m0.4792\u001b[0m       0.7925        0.5011  0.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     21  0.0000        \u001b[32m0.4783\u001b[0m       0.7925        0.5029  0.1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22  0.0672        \u001b[32m0.4781\u001b[0m       0.7925        0.5023  0.1925\n",
      "     23  0.0000        0.4784       0.7925        0.5018  0.1739\n",
      "     24  0.0000        \u001b[32m0.4771\u001b[0m       0.7925        0.5007  0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25  0.0000        0.4789       0.7925        0.4993  0.1380\n",
      "     26  0.0000        0.4774       0.7925        0.5007  0.1310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27  0.0000        0.4856       0.7925        0.5009  0.1384\n",
      "     28  0.0000        0.4784       0.7925        0.5009  0.1505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     29  0.0000        \u001b[32m0.4766\u001b[0m       0.7925        0.5002  0.1845\n",
      "     30  0.0000        0.4768       0.7925        0.4997  0.1745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     31  0.0000        \u001b[32m0.4763\u001b[0m       0.7925        0.4972  0.1492\n",
      "     32  0.0000        \u001b[32m0.4757\u001b[0m       0.7925        \u001b[31m0.4969\u001b[0m  0.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     33  0.0000        \u001b[32m0.4745\u001b[0m       0.7925        0.4993  0.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34  0.0000        \u001b[32m0.4738\u001b[0m       0.7925        \u001b[31m0.4956\u001b[0m  0.1855\n",
      "     35  0.0000        0.4748       0.7925        \u001b[31m0.4953\u001b[0m  0.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     36  0.0000        \u001b[32m0.4720\u001b[0m       0.7925        \u001b[31m0.4919\u001b[0m  0.1418\n",
      "     37  0.0000        \u001b[32m0.4683\u001b[0m       0.7925        \u001b[31m0.4854\u001b[0m  0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     38  0.0000        0.4706       0.7925        0.4875  0.1286\n",
      "     39  0.0000        0.4685       0.7925        0.4884  0.1502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     40  0.0000        \u001b[32m0.4677\u001b[0m       0.7925        0.4887  0.1899\n",
      "     41  0.0000        \u001b[32m0.4628\u001b[0m       0.7925        \u001b[31m0.4826\u001b[0m  0.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     42  \u001b[36m0.3077\u001b[0m        0.4646       \u001b[35m0.7981\u001b[0m        \u001b[31m0.4817\u001b[0m  0.1510\n",
      "     43  0.0000        \u001b[32m0.4552\u001b[0m       0.7925        \u001b[31m0.4732\u001b[0m  0.1721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     44  0.0000        0.4690       0.7925        0.4879  0.1818\n",
      "     45  0.0000        \u001b[32m0.4547\u001b[0m       0.7925        0.4784  0.1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     46  0.0000        \u001b[32m0.4510\u001b[0m       0.7925        \u001b[31m0.4725\u001b[0m  0.1487\n",
      "     47  0.0000        \u001b[32m0.4464\u001b[0m       0.7925        0.4751  0.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     48  0.0000        0.4496       0.7925        0.4725  0.1586\n",
      "     49  0.0000        0.4475       0.7925        0.4749  0.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     50  \u001b[36m0.3750\u001b[0m        \u001b[32m0.4348\u001b[0m       0.7757        \u001b[31m0.4703\u001b[0m  0.1789\n",
      "     51  \u001b[36m0.3819\u001b[0m        0.4472       0.7701        \u001b[31m0.4625\u001b[0m  0.1538\n",
      "     52  \u001b[36m0.3941\u001b[0m        \u001b[32m0.4331\u001b[0m       0.7701        0.4649  0.1598\n",
      "     53  0.3895        \u001b[32m0.4306\u001b[0m       0.7832        0.4628  0.1691\n",
      "     54  \u001b[36m0.4255\u001b[0m        0.4318       0.7981        0.4671  0.1407\n",
      "     55  0.4227        \u001b[32m0.4220\u001b[0m       0.7907        \u001b[31m0.4544\u001b[0m  0.1273\n",
      "     56  0.4108        0.4300       0.7963        0.4608  0.1267\n",
      "     57  0.4000        \u001b[32m0.4166\u001b[0m       \u001b[35m0.8206\u001b[0m        0.4675  0.1271\n",
      "     58  0.3911        0.4183       0.7963        0.4627  0.1436\n",
      "     59  0.3882        0.4185       0.8056        0.4652  0.1320\n",
      "     60  0.3681        0.4221       0.8075        0.4612  0.1348\n",
      "     61  \u001b[36m0.4706\u001b[0m        \u001b[32m0.4163\u001b[0m       0.8150        0.4618  0.1272\n",
      "     62  0.4125        \u001b[32m0.4063\u001b[0m       \u001b[35m0.8243\u001b[0m        \u001b[31m0.4526\u001b[0m  0.1268\n",
      "     63  0.4068        0.4222       0.8037        0.4591  0.1427\n",
      "     64  0.2647        0.4084       0.8131        \u001b[31m0.4505\u001b[0m  0.1420\n",
      "     65  0.2763        \u001b[32m0.4015\u001b[0m       0.7944        \u001b[31m0.4420\u001b[0m  0.1290\n",
      "     66  0.4181        \u001b[32m0.4009\u001b[0m       0.8075        0.4491  0.1433\n",
      "     67  0.3837        \u001b[32m0.4003\u001b[0m       0.8019        0.4424  0.1377\n",
      "     68  0.4072        0.4056       0.8150        0.4450  0.1314\n",
      "     69  0.3899        \u001b[32m0.3943\u001b[0m       0.8187        \u001b[31m0.4296\u001b[0m  0.1311\n",
      "     70  0.3902        \u001b[32m0.3910\u001b[0m       0.8131        0.4440  0.1310\n",
      "     71  0.3289        0.3926       0.8093        0.4381  0.1452\n",
      "     72  0.3484        0.3974       0.8112        0.4301  0.1441\n",
      "     73  0.3377        \u001b[32m0.3887\u001b[0m       0.8093        0.4408  0.1436\n",
      "     74  0.2797        \u001b[32m0.3880\u001b[0m       0.8075        0.4368  0.1443\n",
      "     75  0.3289        0.3888       0.8093        0.4388  0.1274\n",
      "     76  0.3975        \u001b[32m0.3851\u001b[0m       0.8187        0.4507  0.1313\n",
      "     77  0.4471        \u001b[32m0.3823\u001b[0m       0.8243        0.4430  0.1311\n",
      "     78  0.4633        \u001b[32m0.3797\u001b[0m       0.8224        0.4443  0.1312\n",
      "     79  0.4348        \u001b[32m0.3744\u001b[0m       \u001b[35m0.8299\u001b[0m        0.4374  0.1350\n",
      "     80  0.4364        \u001b[32m0.3694\u001b[0m       0.8262        0.4419  0.1338\n",
      "     81  0.4353        0.3718       0.8206        0.4347  0.1283\n",
      "     82  0.3660        \u001b[32m0.3681\u001b[0m       0.8187        0.4319  0.1304\n",
      "     83  0.3899        0.3729       0.8187        0.4347  0.1303\n",
      "     84  \u001b[36m0.4740\u001b[0m        0.3732       0.8299        0.4366  0.1312\n",
      "     85  0.4000        \u001b[32m0.3628\u001b[0m       0.8206        0.4303  0.1419\n",
      "     86  0.4444        \u001b[32m0.3625\u001b[0m       0.8224        0.4334  0.1302\n",
      "     87  \u001b[36m0.4795\u001b[0m        \u001b[32m0.3546\u001b[0m       \u001b[35m0.8336\u001b[0m        \u001b[31m0.4295\u001b[0m  0.1286\n",
      "     88  0.4588        0.3617       0.8280        \u001b[31m0.4237\u001b[0m  0.1305\n",
      "     89  0.4294        0.3568       0.8262        0.4293  0.1366\n",
      "     90  0.4431        0.3630       0.8262        0.4238  0.1341\n",
      "     91  0.4074        \u001b[32m0.3534\u001b[0m       0.8206        0.4540  0.1312\n",
      "     92  0.4000        \u001b[32m0.3533\u001b[0m       0.8206        0.4325  0.1319\n",
      "     93  0.3158        \u001b[32m0.3499\u001b[0m       0.8056        0.4823  0.1279\n",
      "     94  0.3333        0.3545       0.8131        0.4444  0.1307\n",
      "     95  0.4343        \u001b[32m0.3482\u001b[0m       0.8150        0.4604  0.1272\n",
      "     96  0.4457        \u001b[32m0.3452\u001b[0m       0.8187        0.4484  0.1350\n",
      "     97  0.4524        0.3474       0.8280        0.4390  0.1319\n",
      "     98  0.4520        0.3512       0.8187        0.4481  0.1275\n",
      "     99  0.2979        0.3605       0.8150        0.5002  0.1337\n",
      "    100  0.3129        0.3646       0.8112        0.4965  0.1300\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0000\u001b[0m        \u001b[32m0.5275\u001b[0m       \u001b[35m0.7794\u001b[0m        \u001b[31m0.5047\u001b[0m  0.1262\n",
      "      2  0.0000        \u001b[32m0.5090\u001b[0m       0.7794        0.5119  0.1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3  0.0000        \u001b[32m0.5040\u001b[0m       0.7794        0.5048  0.1523\n",
      "      4  0.0000        \u001b[32m0.5035\u001b[0m       0.7794        0.5059  0.1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0.0000        \u001b[32m0.5011\u001b[0m       0.7794        \u001b[31m0.5014\u001b[0m  0.1344\n",
      "      6  0.0000        \u001b[32m0.4997\u001b[0m       0.7794        0.5030  0.1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        \u001b[32m0.4991\u001b[0m       0.7794        \u001b[31m0.5002\u001b[0m  0.1457\n",
      "      8  0.0000        \u001b[32m0.4914\u001b[0m       0.7794        \u001b[31m0.4985\u001b[0m  0.1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0000        \u001b[32m0.4878\u001b[0m       0.7794        \u001b[31m0.4852\u001b[0m  0.1335\n",
      "     10  0.0000        \u001b[32m0.4773\u001b[0m       0.7794        \u001b[31m0.4645\u001b[0m  0.1318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  0.0000        \u001b[32m0.4512\u001b[0m       0.7794        \u001b[31m0.4594\u001b[0m  0.1453\n",
      "     12  \u001b[36m0.2621\u001b[0m        \u001b[32m0.4335\u001b[0m       \u001b[35m0.8000\u001b[0m        \u001b[31m0.4188\u001b[0m  0.1307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13  \u001b[36m0.4599\u001b[0m        \u001b[32m0.4276\u001b[0m       \u001b[35m0.8112\u001b[0m        \u001b[31m0.4093\u001b[0m  0.1366\n",
      "     14  \u001b[36m0.5000\u001b[0m        0.4294       0.8056        0.4095  0.1424\n",
      "     15  \u001b[36m0.5542\u001b[0m        0.4295       0.7925        0.4224  0.1410\n",
      "     16  0.4681        \u001b[32m0.4144\u001b[0m       \u001b[35m0.8131\u001b[0m        \u001b[31m0.4071\u001b[0m  0.1345\n",
      "     17  0.5352        0.4164       \u001b[35m0.8150\u001b[0m        \u001b[31m0.3981\u001b[0m  0.1258\n",
      "     18  0.5171        \u001b[32m0.4135\u001b[0m       0.8150        0.4106  0.1257\n",
      "     19  0.4894        \u001b[32m0.4065\u001b[0m       \u001b[35m0.8206\u001b[0m        0.4079  0.1304\n",
      "     20  0.5446        0.4096       0.8093        0.3996  0.1348\n",
      "     21  0.5209        0.4068       0.8075        0.4073  0.1307\n",
      "     22  0.5258        \u001b[32m0.4038\u001b[0m       0.8112        0.4138  0.1407\n",
      "     23  0.5308        \u001b[32m0.4009\u001b[0m       0.8150        0.4030  0.1254\n",
      "     24  0.5488        \u001b[32m0.3986\u001b[0m       0.8187        0.4027  0.1262\n",
      "     25  0.5238        \u001b[32m0.3978\u001b[0m       0.8131        0.4031  0.1438\n",
      "     26  0.5403        0.3987       0.8187        0.4098  0.1426\n",
      "     27  0.5052        \u001b[32m0.3932\u001b[0m       0.8206        0.4011  0.1415\n",
      "     28  0.5288        0.3998       0.8168        0.4124  0.1311\n",
      "     29  0.5530        0.4031       0.8187        0.4039  0.1267\n",
      "     30  0.5302        \u001b[32m0.3929\u001b[0m       0.8112        0.4130  0.1443\n",
      "     31  0.5222        \u001b[32m0.3904\u001b[0m       0.8187        0.4007  0.1483\n",
      "     32  \u001b[36m0.5556\u001b[0m        \u001b[32m0.3894\u001b[0m       0.8206        0.3990  0.1453\n",
      "     33  0.5258        0.3922       \u001b[35m0.8280\u001b[0m        0.4007  0.1257\n",
      "     34  0.5556        0.3931       0.8206        0.4081  0.1375\n",
      "     35  0.5530        \u001b[32m0.3862\u001b[0m       0.8187        0.4049  0.1416\n",
      "     36  \u001b[36m0.5727\u001b[0m        \u001b[32m0.3854\u001b[0m       0.8187        0.3997  0.1426\n",
      "     37  0.5243        0.3869       0.8168        0.4066  0.1325\n",
      "     38  0.5566        \u001b[32m0.3853\u001b[0m       0.8243        0.4134  0.1293\n",
      "     39  0.5586        0.3863       0.8168        0.4082  0.1290\n",
      "     40  0.5502        0.3855       0.8075        0.4100  0.1435\n",
      "     41  0.5437        \u001b[32m0.3814\u001b[0m       0.8243        0.4093  0.1309\n",
      "     42  \u001b[36m0.5965\u001b[0m        \u001b[32m0.3804\u001b[0m       0.8280        0.4143  0.1308\n",
      "     43  0.5507        0.3844       0.8262        0.4018  0.1446\n",
      "     44  0.5561        0.3837       0.8150        0.4083  0.1442\n",
      "     45  0.5634        \u001b[32m0.3783\u001b[0m       0.8262        0.4069  0.1446\n",
      "     46  0.5628        \u001b[32m0.3749\u001b[0m       0.8112        0.4101  0.1445\n",
      "     47  0.5636        \u001b[32m0.3733\u001b[0m       0.8206        0.4057  0.1461\n",
      "     48  0.5625        \u001b[32m0.3707\u001b[0m       0.8168        0.4041  0.1490\n",
      "     49  0.5766        \u001b[32m0.3706\u001b[0m       0.8243        0.4043  0.1431\n",
      "     50  0.5913        \u001b[32m0.3689\u001b[0m       0.8243        0.4052  0.1457\n",
      "     51  0.5804        \u001b[32m0.3672\u001b[0m       0.8243        \u001b[31m0.3975\u001b[0m  0.1287\n",
      "     52  0.5776        \u001b[32m0.3645\u001b[0m       0.8168        0.4136  0.1389\n",
      "     53  0.5862        0.3678       0.8206        0.4168  0.1422\n",
      "     54  0.5689        0.3668       0.8187        0.4060  0.1406\n",
      "     55  0.5702        0.3672       0.8112        0.4162  0.1437\n",
      "     56  0.5566        0.3673       0.8243        0.4000  0.1405\n",
      "     57  0.5664        \u001b[32m0.3643\u001b[0m       0.8168        0.4002  0.1334\n",
      "     58  0.5714        \u001b[32m0.3634\u001b[0m       0.8150        0.4199  0.1301\n",
      "     59  0.4444        0.3944       0.8224        0.4136  0.1347\n",
      "     60  0.5780        0.3810       0.8280        0.4047  0.1399\n",
      "     61  0.5662        0.3649       0.8224        0.3977  0.1271\n",
      "     62  0.5801        \u001b[32m0.3566\u001b[0m       0.8187        0.4047  0.1262\n",
      "     63  0.5550        0.3592       0.8262        \u001b[31m0.3866\u001b[0m  0.1260\n",
      "     64  0.5320        0.3750       0.8224        0.3962  0.1265\n",
      "     65  0.5471        0.3651       0.8112        0.4039  0.1257\n",
      "     66  0.5306        0.3676       0.8280        0.3988  0.1262\n",
      "     67  0.5903        \u001b[32m0.3553\u001b[0m       0.8262        0.4248  0.1295\n",
      "     68  0.5556        \u001b[32m0.3482\u001b[0m       0.8206        0.4032  0.1358\n",
      "     69  0.5929        0.3623       0.8280        0.3991  0.1440\n",
      "     70  0.5417        0.3652       \u001b[35m0.8355\u001b[0m        \u001b[31m0.3783\u001b[0m  0.1440\n",
      "     71  0.5253        0.3610       0.8243        0.3794  0.1377\n",
      "     72  0.5026        0.3560       0.8224        0.3872  0.1335\n",
      "     73  0.4581        0.3680       0.8187        0.3816  0.1263\n",
      "     74  0.5128        0.3715       0.8224        0.4169  0.1276\n",
      "     75  0.4561        0.3732       0.8262        0.3882  0.1339\n",
      "     76  0.5333        0.3548       0.8299        \u001b[31m0.3782\u001b[0m  0.1299\n",
      "     77  0.4804        0.3631       0.8262        0.3876  0.1308\n",
      "     78  0.5427        0.3614       0.8299        \u001b[31m0.3774\u001b[0m  0.1376\n",
      "     79  0.5178        0.3551       0.8224        0.3825  0.1359\n",
      "     80  0.5411        0.3560       0.8224        0.3883  0.1354\n",
      "     81  0.5584        0.3611       \u001b[35m0.8374\u001b[0m        \u001b[31m0.3757\u001b[0m  0.1418\n",
      "     82  0.5446        \u001b[32m0.3454\u001b[0m       0.8280        0.3847  0.1299\n",
      "     83  0.4751        0.3589       0.8224        0.4001  0.1386\n",
      "     84  0.5213        0.3755       0.8318        0.3871  0.1661\n",
      "     85  0.4535        0.3627       0.8243        0.3850  0.1838\n",
      "     86  0.4751        0.3581       0.8224        0.3825  0.1782\n",
      "     87  0.4920        0.3563       0.8224        0.4058  0.1740\n",
      "     88  0.5408        0.3465       0.8318        0.3864  0.1724\n",
      "     89  0.5825        0.3497       \u001b[35m0.8393\u001b[0m        0.3897  0.1604\n",
      "     90  0.5659        \u001b[32m0.3378\u001b[0m       0.8336        0.3816  0.1652\n",
      "     91  0.5882        0.3434       \u001b[35m0.8430\u001b[0m        0.3903  0.1677\n",
      "     92  0.5158        0.3733       0.8280        0.4218  0.1481\n",
      "     93  0.5822        0.3605       0.8336        0.3840  0.1295\n",
      "     94  0.5128        0.3483       0.8224        0.4020  0.1693\n",
      "     95  0.5320        0.3444       0.8224        0.3887  0.1737\n",
      "     96  0.5392        0.3484       0.8243        0.4203  0.1381\n",
      "     97  0.5395        0.3388       0.8150        0.3941  0.1516\n",
      "     98  0.5498        \u001b[32m0.3357\u001b[0m       0.8224        0.3957  0.1651\n",
      "     99  0.5481        0.3357       0.8243        0.3812  0.1463\n",
      "    100  0.5392        \u001b[32m0.3351\u001b[0m       0.8243        0.3921  0.1557\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0000\u001b[0m        \u001b[32m0.5449\u001b[0m       \u001b[35m0.7888\u001b[0m        \u001b[31m0.5057\u001b[0m  0.1242\n",
      "      2  0.0000        \u001b[32m0.4938\u001b[0m       0.7888        0.5175  0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3  0.0000        \u001b[32m0.4923\u001b[0m       0.7888        0.5151  0.1654\n",
      "      4  0.0000        \u001b[32m0.4903\u001b[0m       0.7888        0.5145  0.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0.0000        \u001b[32m0.4898\u001b[0m       0.7888        0.5130  0.1361\n",
      "      6  0.0000        \u001b[32m0.4888\u001b[0m       0.7888        0.5121  0.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        \u001b[32m0.4882\u001b[0m       0.7888        0.5118  0.1299\n",
      "      8  \u001b[36m0.0175\u001b[0m        \u001b[32m0.4875\u001b[0m       \u001b[35m0.7907\u001b[0m        0.5108  0.1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0174        \u001b[32m0.4867\u001b[0m       0.7888        0.5104  0.1377\n",
      "     10  0.0174        \u001b[32m0.4857\u001b[0m       0.7888        0.5098  0.1327\n",
      "     11  0.0174        \u001b[32m0.4847\u001b[0m       0.7888        0.5088  0.1239\n",
      "     12  0.0174        \u001b[32m0.4839\u001b[0m       0.7888        0.5082  0.1418\n",
      "     13  \u001b[36m0.0345\u001b[0m        \u001b[32m0.4820\u001b[0m       0.7907        \u001b[31m0.5055\u001b[0m  0.1327\n",
      "     14  0.0174        \u001b[32m0.4800\u001b[0m       0.7888        \u001b[31m0.4929\u001b[0m  0.1334\n",
      "     15  0.0174        0.4838       0.7888        0.4960  0.1314\n",
      "     16  0.0342        \u001b[32m0.4673\u001b[0m       0.7888        \u001b[31m0.4626\u001b[0m  0.1302\n",
      "     17  \u001b[36m0.0513\u001b[0m        0.5087       \u001b[35m0.7925\u001b[0m        0.4938  0.1304\n",
      "     18  0.0175        0.4719       0.7907        0.4868  0.1364\n",
      "     19  0.0508        \u001b[32m0.4547\u001b[0m       0.7907        \u001b[31m0.4370\u001b[0m  0.1354\n",
      "     20  \u001b[36m0.3234\u001b[0m        0.4886       0.7888        0.4773  0.1236\n",
      "     21  \u001b[36m0.4687\u001b[0m        \u001b[32m0.4443\u001b[0m       \u001b[35m0.8093\u001b[0m        \u001b[31m0.4234\u001b[0m  0.1248\n",
      "     22  \u001b[36m0.5045\u001b[0m        0.4518       0.7944        0.4398  0.1230\n",
      "     23  \u001b[36m0.5455\u001b[0m        \u001b[32m0.4244\u001b[0m       \u001b[35m0.8224\u001b[0m        \u001b[31m0.4025\u001b[0m  0.1360\n",
      "     24  0.5143        \u001b[32m0.4175\u001b[0m       0.8093        0.4198  0.1237\n",
      "     25  0.5283        \u001b[32m0.4115\u001b[0m       0.8131        0.4116  0.1382\n",
      "     26  \u001b[36m0.5652\u001b[0m        \u001b[32m0.4020\u001b[0m       0.8131        0.4088  0.1696\n",
      "     27  \u001b[36m0.5728\u001b[0m        0.4035       \u001b[35m0.8355\u001b[0m        0.4038  0.1528\n",
      "     28  0.5495        \u001b[32m0.3951\u001b[0m       0.8131        0.4081  0.1342\n",
      "     29  0.4868        0.4066       0.8187        \u001b[31m0.3978\u001b[0m  0.1602\n",
      "     30  0.5634        \u001b[32m0.3902\u001b[0m       0.8262        0.4102  0.1737\n",
      "     31  0.5604        0.3931       0.8299        0.4079  0.1460\n",
      "     32  0.5688        \u001b[32m0.3860\u001b[0m       0.8243        0.4181  0.1341\n",
      "     33  0.5226        \u001b[32m0.3859\u001b[0m       0.8224        0.3993  0.1400\n",
      "     34  0.5688        0.3888       0.8243        0.4215  0.1600\n",
      "     35  \u001b[36m0.5792\u001b[0m        \u001b[32m0.3845\u001b[0m       0.8262        0.4177  0.1473\n",
      "     36  0.5000        \u001b[32m0.3834\u001b[0m       0.8131        0.4071  0.1255\n",
      "     37  0.5098        \u001b[32m0.3814\u001b[0m       0.8131        0.4116  0.1548\n",
      "     38  0.4949        \u001b[32m0.3802\u001b[0m       0.8131        0.4242  0.1543\n",
      "     39  0.4767        0.3829       0.8112        0.4110  0.1251\n",
      "     40  0.4607        \u001b[32m0.3790\u001b[0m       0.8075        0.4005  0.1345\n",
      "     41  0.5025        \u001b[32m0.3783\u001b[0m       0.8112        0.4135  0.1699\n",
      "     42  0.4742        0.3815       0.8093        \u001b[31m0.3938\u001b[0m  0.1625\n",
      "     43  0.4848        \u001b[32m0.3743\u001b[0m       0.8093        0.3971  0.1534\n",
      "     44  0.5192        0.3777       0.8131        0.4051  0.1483\n",
      "     45  0.4796        0.3747       0.8093        0.3997  0.1309\n",
      "     46  0.4687        \u001b[32m0.3732\u001b[0m       0.8093        \u001b[31m0.3889\u001b[0m  0.1539\n",
      "     47  0.4199        \u001b[32m0.3698\u001b[0m       0.8037        \u001b[31m0.3871\u001b[0m  0.1677\n",
      "     48  0.4409        0.3731       0.8056        0.3991  0.1742\n",
      "     49  0.4111        0.3779       0.8019        0.3898  0.1484\n",
      "     50  0.4000        0.3722       0.8037        \u001b[31m0.3870\u001b[0m  0.1709\n",
      "     51  0.3780        0.3742       0.8093        0.3880  0.1467\n",
      "     52  0.3952        0.3725       0.8112        \u001b[31m0.3864\u001b[0m  0.1717\n",
      "     53  0.4516        \u001b[32m0.3692\u001b[0m       0.8093        0.3946  0.1716\n",
      "     54  0.3713        \u001b[32m0.3683\u001b[0m       0.8037        0.4094  0.1438\n",
      "     55  0.4138        0.3696       0.8093        0.4097  0.1707\n",
      "     56  0.4926        0.3704       0.8075        0.4039  0.1629\n",
      "     57  0.4469        0.3737       0.8150        0.3869  0.1558\n",
      "     58  0.4656        \u001b[32m0.3654\u001b[0m       0.8112        0.3928  0.1777\n",
      "     59  0.4246        \u001b[32m0.3625\u001b[0m       0.8075        0.4057  0.1494\n",
      "     60  0.4649        0.3646       0.8150        \u001b[31m0.3786\u001b[0m  0.1418\n",
      "     61  0.4550        0.3630       0.8075        0.3899  0.1242\n",
      "     62  0.4114        0.3697       0.8075        0.4005  0.1416\n",
      "     63  0.4432        0.3641       0.8075        0.3863  0.1266\n",
      "     64  0.4138        \u001b[32m0.3605\u001b[0m       0.8093        0.3858  0.1334\n",
      "     65  0.4530        0.3628       0.8150        0.3871  0.1360\n",
      "     66  0.4503        0.3657       0.8037        0.3953  0.1365\n",
      "     67  0.4842        0.3605       0.8168        0.4032  0.1283\n",
      "     68  0.4277        0.3681       0.8150        0.3819  0.1407\n",
      "     69  0.4599        0.3630       0.8112        0.4085  0.1335\n",
      "     70  0.5481        \u001b[32m0.3576\u001b[0m       0.8243        0.3847  0.1259\n",
      "     71  0.4468        0.3586       0.8056        0.3873  0.1321\n",
      "     72  0.4896        \u001b[32m0.3555\u001b[0m       0.8168        0.3840  0.1254\n",
      "     73  0.4776        0.3570       0.8037        0.4128  0.1288\n",
      "     74  0.4699        0.3592       0.8187        0.3855  0.1451\n",
      "     75  0.4865        0.3572       0.8224        0.3897  0.1343\n",
      "     76  0.4497        \u001b[32m0.3548\u001b[0m       0.8262        0.3805  0.1471\n",
      "     77  0.4813        \u001b[32m0.3530\u001b[0m       0.8187        0.3866  0.1381\n",
      "     78  0.4457        0.3587       0.8093        0.4026  0.1480\n",
      "     79  0.5026        0.3562       0.8224        0.3793  0.1475\n",
      "     80  0.4556        \u001b[32m0.3523\u001b[0m       0.8168        \u001b[31m0.3764\u001b[0m  0.1473\n",
      "     81  0.5025        \u001b[32m0.3490\u001b[0m       0.8150        0.3874  0.1621\n",
      "     82  0.5532        0.3530       0.8037        0.4094  0.1827\n",
      "     83  0.5727        0.3521       0.8187        0.4063  0.1656\n",
      "     84  0.4974        0.3547       0.8224        0.3862  0.1755\n",
      "     85  0.4693        0.3650       0.8224        0.3910  0.1399\n",
      "     86  0.4778        0.3499       0.8243        0.3843  0.1429\n",
      "     87  0.3758        0.3494       0.8075        0.3875  0.1331\n",
      "     88  0.4923        0.3566       0.8150        0.3891  0.1317\n",
      "     89  0.4719        \u001b[32m0.3474\u001b[0m       0.8243        0.3995  0.1449\n",
      "     90  0.3905        0.3708       0.8075        0.3866  0.1317\n",
      "     91  0.4277        \u001b[32m0.3460\u001b[0m       0.8150        0.3769  0.1435\n",
      "     92  0.3553        0.3509       0.8168        0.3928  0.1411\n",
      "     93  0.5388        0.3638       0.8112        0.4281  0.1940\n",
      "     94  0.4277        0.3504       0.8150        0.3934  0.1640\n",
      "     95  0.4868        0.3488       0.8187        0.3923  0.1459\n",
      "     96  0.4382        \u001b[32m0.3436\u001b[0m       0.8131        0.4268  0.1400\n",
      "     97  0.4368        0.3557       0.8168        0.3869  0.1688\n",
      "     98  0.4796        0.3504       0.8093        0.3981  0.1796\n",
      "     99  0.5507        0.3455       0.8262        0.4091  0.1726\n",
      "    100  0.5437        0.3546       0.8243        0.4148  0.1327\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0000\u001b[0m        \u001b[32m0.5751\u001b[0m       \u001b[35m0.7925\u001b[0m        \u001b[31m0.4994\u001b[0m  0.1297\n",
      "      2  0.0000        \u001b[32m0.4962\u001b[0m       0.7925        0.5002  0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3  0.0000        \u001b[32m0.4892\u001b[0m       0.7925        \u001b[31m0.4971\u001b[0m  0.1406\n",
      "      4  0.0000        \u001b[32m0.4863\u001b[0m       0.7925        \u001b[31m0.4964\u001b[0m  0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0.0000        \u001b[32m0.4846\u001b[0m       0.7925        0.4996  0.1369\n",
      "      6  0.0000        \u001b[32m0.4840\u001b[0m       0.7925        0.4984  0.1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        \u001b[32m0.4821\u001b[0m       0.7925        0.5019  0.1477\n",
      "      8  0.0000        \u001b[32m0.4811\u001b[0m       0.7925        0.5007  0.1445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0000        \u001b[32m0.4792\u001b[0m       0.7925        0.4993  0.1477\n",
      "     10  0.0000        0.4804       0.7925        0.4974  0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  0.0000        \u001b[32m0.4764\u001b[0m       0.7925        0.4965  0.1382\n",
      "     12  0.0000        0.4786       0.7925        \u001b[31m0.4953\u001b[0m  0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13  0.0000        \u001b[32m0.4745\u001b[0m       0.7925        \u001b[31m0.4908\u001b[0m  0.1415\n",
      "     14  0.0000        \u001b[32m0.4638\u001b[0m       0.7925        \u001b[31m0.4832\u001b[0m  0.1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15  0.0000        \u001b[32m0.4453\u001b[0m       0.7925        \u001b[31m0.4826\u001b[0m  0.1630\n",
      "     16  0.0000        \u001b[32m0.4379\u001b[0m       0.7925        \u001b[31m0.4681\u001b[0m  0.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17  \u001b[36m0.3871\u001b[0m        \u001b[32m0.4310\u001b[0m       0.7869        \u001b[31m0.4628\u001b[0m  0.1627\n",
      "     18  0.3468        \u001b[32m0.4293\u001b[0m       0.7888        0.4634  0.1670\n",
      "     19  \u001b[36m0.4062\u001b[0m        \u001b[32m0.4186\u001b[0m       0.7869        \u001b[31m0.4583\u001b[0m  0.1702\n",
      "     20  0.3895        \u001b[32m0.4159\u001b[0m       0.7832        \u001b[31m0.4555\u001b[0m  0.1311\n",
      "     21  0.4061        \u001b[32m0.4136\u001b[0m       0.7813        \u001b[31m0.4513\u001b[0m  0.1244\n",
      "     22  0.4000        \u001b[32m0.4133\u001b[0m       0.7925        0.4549  0.1241\n",
      "     23  0.3977        \u001b[32m0.4084\u001b[0m       \u001b[35m0.8019\u001b[0m        \u001b[31m0.4425\u001b[0m  0.1294\n",
      "     24  0.3978        \u001b[32m0.4059\u001b[0m       0.7963        \u001b[31m0.4418\u001b[0m  0.1281\n",
      "     25  \u001b[36m0.4271\u001b[0m        \u001b[32m0.4026\u001b[0m       0.7944        0.4446  0.1274\n",
      "     26  \u001b[36m0.4316\u001b[0m        0.4036       0.7981        \u001b[31m0.4405\u001b[0m  0.1243\n",
      "     27  \u001b[36m0.4516\u001b[0m        \u001b[32m0.4003\u001b[0m       \u001b[35m0.8093\u001b[0m        \u001b[31m0.4378\u001b[0m  0.1246\n",
      "     28  0.4293        \u001b[32m0.3981\u001b[0m       0.7963        0.4429  0.1364\n",
      "     29  0.4045        \u001b[32m0.3966\u001b[0m       0.8019        \u001b[31m0.4301\u001b[0m  0.1336\n",
      "     30  0.3931        \u001b[32m0.3964\u001b[0m       0.8037        0.4401  0.1354\n",
      "     31  0.3886        \u001b[32m0.3916\u001b[0m       0.8000        0.4310  0.1328\n",
      "     32  0.4199        \u001b[32m0.3915\u001b[0m       0.8037        0.4425  0.1345\n",
      "     33  0.4309        \u001b[32m0.3862\u001b[0m       0.8075        0.4382  0.1339\n",
      "     34  0.3977        \u001b[32m0.3821\u001b[0m       0.8019        0.4407  0.1283\n",
      "     35  0.4000        \u001b[32m0.3786\u001b[0m       0.8037        \u001b[31m0.4244\u001b[0m  0.1267\n",
      "     36  0.4294        0.3793       \u001b[35m0.8112\u001b[0m        0.4266  0.1243\n",
      "     37  0.4432        \u001b[32m0.3743\u001b[0m       0.8075        0.4253  0.1236\n",
      "     38  0.4444        0.3764       \u001b[35m0.8131\u001b[0m        \u001b[31m0.4242\u001b[0m  0.1332\n",
      "     39  \u001b[36m0.4541\u001b[0m        \u001b[32m0.3710\u001b[0m       0.8112        0.4292  0.1289\n",
      "     40  \u001b[36m0.4556\u001b[0m        0.3715       \u001b[35m0.8168\u001b[0m        0.4299  0.1427\n",
      "     41  0.4550        \u001b[32m0.3697\u001b[0m       0.8075        0.4345  0.1434\n",
      "     42  \u001b[36m0.4670\u001b[0m        \u001b[32m0.3679\u001b[0m       0.8037        0.4279  0.1324\n",
      "     43  \u001b[36m0.5025\u001b[0m        \u001b[32m0.3659\u001b[0m       0.8150        \u001b[31m0.4048\u001b[0m  0.1324\n",
      "     44  0.4457        0.3695       0.8093        0.4333  0.1293\n",
      "     45  0.3690        0.3830       0.8019        0.4214  0.1356\n",
      "     46  0.4000        \u001b[32m0.3650\u001b[0m       0.8093        0.4241  0.1290\n",
      "     47  0.4333        \u001b[32m0.3619\u001b[0m       0.8093        0.4514  0.1297\n",
      "     48  0.4229        0.3649       0.8112        0.4384  0.1364\n",
      "     49  0.4737        0.3645       0.8131        0.4394  0.1312\n",
      "     50  0.4270        \u001b[32m0.3595\u001b[0m       0.8093        0.4204  0.1337\n",
      "     51  0.3571        \u001b[32m0.3558\u001b[0m       0.7981        0.4430  0.1309\n",
      "     52  0.3977        \u001b[32m0.3544\u001b[0m       0.8075        0.4582  0.1257\n",
      "     53  0.3221        0.3695       0.8112        0.4515  0.1391\n",
      "     54  0.4712        0.3669       0.8112        0.4236  0.1309\n",
      "     55  0.3602        0.3633       0.8075        0.4568  0.1425\n",
      "     56  0.4407        0.3551       0.8150        0.4521  0.1337\n",
      "     57  0.3929        0.3634       0.8093        0.4456  0.1417\n",
      "     58  0.3804        0.3631       0.8112        0.4344  0.1340\n",
      "     59  0.3780        0.3619       0.8093        0.4377  0.1308\n",
      "     60  0.4167        0.3615       0.8168        0.4728  0.1276\n",
      "     61  0.3580        0.3555       0.8056        0.4800  0.1389\n",
      "     62  0.4343        0.3602       0.8150        0.4643  0.1352\n",
      "     63  0.3625        0.3592       0.8093        0.4849  0.1287\n",
      "     64  0.3690        0.3650       0.8019        0.4938  0.1249\n",
      "     65  0.4186        0.3575       0.8131        0.4553  0.1329\n",
      "     66  0.3820        0.3645       0.7944        0.4303  0.1428\n",
      "     67  0.3933        0.3635       0.7981        0.4173  0.1355\n",
      "     68  0.4309        0.3644       0.8075        0.4203  0.1327\n",
      "     69  0.4828        0.3703       0.8037        0.4372  0.1341\n",
      "     70  0.4421        0.3678       0.8019        0.4084  0.1242\n",
      "     71  0.4592        0.3593       0.8019        \u001b[31m0.4032\u001b[0m  0.1246\n",
      "     72  0.4194        0.3603       0.7981        0.4121  0.1242\n",
      "     73  0.4800        0.3551       0.8056        0.4312  0.1248\n",
      "     74  0.4831        0.3569       0.8000        0.4278  0.1285\n",
      "     75  0.4706        0.3570       0.7981        0.4099  0.1566\n",
      "     76  0.4695        0.3554       0.7888        0.4197  0.1643\n",
      "     77  0.4660        0.3598       0.7944        0.4302  0.1604\n",
      "     78  0.4739        0.3604       0.7925        0.4350  0.1530\n",
      "     79  0.4638        \u001b[32m0.3434\u001b[0m       0.7925        0.4212  0.1523\n",
      "     80  0.4793        0.3510       0.7888        0.4194  0.1343\n",
      "     81  0.4683        0.3460       0.7963        0.4207  0.1721\n",
      "     82  0.4645        0.3500       0.7888        0.4465  0.1598\n",
      "     83  0.5022        0.3494       0.7925        0.4312  0.1424\n",
      "     84  0.5000        0.3522       0.7944        0.4286  0.1712\n",
      "     85  0.4906        \u001b[32m0.3396\u001b[0m       0.7981        0.4260  0.1629\n",
      "     86  \u001b[36m0.5138\u001b[0m        \u001b[32m0.3320\u001b[0m       0.8019        0.4223  0.1650\n",
      "     87  0.4615        0.3427       0.8037        0.4606  0.1607\n",
      "     88  0.4907        0.3368       0.7944        0.4516  0.1626\n",
      "     89  0.5118        0.3354       0.8075        0.4282  0.1610\n",
      "     90  0.4479        0.3416       0.8019        0.4445  0.1670\n",
      "     91  0.5116        0.3354       0.8037        0.4355  0.1734\n",
      "     92  \u001b[36m0.5167\u001b[0m        \u001b[32m0.3249\u001b[0m       0.8112        0.4442  0.1636\n",
      "     93  0.5110        0.3395       0.7925        0.4332  0.1661\n",
      "     94  0.4824        0.3398       0.8075        0.4266  0.1739\n",
      "     95  0.4286        0.3338       0.7907        0.4456  0.1375\n",
      "     96  0.4776        0.3374       0.8037        0.4235  0.1298\n",
      "     97  0.4729        0.3383       0.8000        0.4254  0.1238\n",
      "     98  0.4545        0.3428       0.7981        0.4412  0.1344\n",
      "     99  \u001b[36m0.5182\u001b[0m        0.3305       0.8019        0.4453  0.1276\n",
      "    100  0.4670        0.3277       0.8037        0.4476  0.1369\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0000\u001b[0m        \u001b[32m0.5558\u001b[0m       \u001b[35m0.7794\u001b[0m        \u001b[31m0.5040\u001b[0m  0.1211\n",
      "      2  0.0000        \u001b[32m0.5072\u001b[0m       0.7794        0.5047  0.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3  \u001b[36m0.0168\u001b[0m        \u001b[32m0.5053\u001b[0m       \u001b[35m0.7813\u001b[0m        0.5055  0.1399\n",
      "      4  0.0000        0.5059       0.7794        0.5143  0.1367\n",
      "      5  0.0000        \u001b[32m0.5050\u001b[0m       0.7794        0.5131  0.1772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6  0.0000        \u001b[32m0.5019\u001b[0m       0.7794        0.5072  0.1703\n",
      "      7  0.0000        \u001b[32m0.4995\u001b[0m       0.7794        0.5053  0.1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8  0.0000        \u001b[32m0.4986\u001b[0m       0.7794        0.5054  0.1593\n",
      "      9  \u001b[36m0.0333\u001b[0m        \u001b[32m0.4977\u001b[0m       \u001b[35m0.7832\u001b[0m        0.5055  0.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10  \u001b[36m0.1085\u001b[0m        \u001b[32m0.4945\u001b[0m       \u001b[35m0.7850\u001b[0m        \u001b[31m0.5033\u001b[0m  0.1216\n",
      "     11  0.0800        \u001b[32m0.4916\u001b[0m       0.7850        \u001b[31m0.5011\u001b[0m  0.1259\n",
      "     12  0.0640        \u001b[32m0.4888\u001b[0m       0.7813        0.5017  0.1457\n",
      "     13  0.0640        \u001b[32m0.4865\u001b[0m       0.7813        \u001b[31m0.4998\u001b[0m  0.1453\n",
      "     14  \u001b[36m0.1240\u001b[0m        \u001b[32m0.4800\u001b[0m       \u001b[35m0.7888\u001b[0m        \u001b[31m0.4783\u001b[0m  0.1467\n",
      "     15  \u001b[36m0.2329\u001b[0m        \u001b[32m0.4702\u001b[0m       \u001b[35m0.7907\u001b[0m        \u001b[31m0.4652\u001b[0m  0.1370\n",
      "     16  \u001b[36m0.2667\u001b[0m        \u001b[32m0.4680\u001b[0m       \u001b[35m0.7944\u001b[0m        \u001b[31m0.4651\u001b[0m  0.1348\n",
      "     17  \u001b[36m0.3270\u001b[0m        \u001b[32m0.4630\u001b[0m       \u001b[35m0.8000\u001b[0m        \u001b[31m0.4555\u001b[0m  0.1239\n",
      "     18  \u001b[36m0.3793\u001b[0m        \u001b[32m0.4601\u001b[0m       0.7981        0.4649  0.1197\n",
      "     19  0.3007        \u001b[32m0.4482\u001b[0m       0.8000        \u001b[31m0.4350\u001b[0m  0.1204\n",
      "     20  0.3436        \u001b[32m0.4409\u001b[0m       0.8000        \u001b[31m0.4299\u001b[0m  0.1196\n",
      "     21  \u001b[36m0.4316\u001b[0m        0.4440       0.7981        0.4480  0.1192\n",
      "     22  \u001b[36m0.4469\u001b[0m        \u001b[32m0.4398\u001b[0m       \u001b[35m0.8150\u001b[0m        0.4393  0.1198\n",
      "     23  0.3977        \u001b[32m0.4300\u001b[0m       0.8075        \u001b[31m0.4223\u001b[0m  0.1225\n",
      "     24  \u001b[36m0.4870\u001b[0m        0.4323       0.8150        \u001b[31m0.4134\u001b[0m  0.1232\n",
      "     25  0.4762        \u001b[32m0.4254\u001b[0m       0.8150        \u001b[31m0.4090\u001b[0m  0.1196\n",
      "     26  0.4505        \u001b[32m0.4212\u001b[0m       0.8131        0.4091  0.1203\n",
      "     27  \u001b[36m0.5052\u001b[0m        \u001b[32m0.4152\u001b[0m       \u001b[35m0.8206\u001b[0m        \u001b[31m0.4050\u001b[0m  0.1264\n",
      "     28  0.4873        0.4166       0.8112        0.4108  0.1227\n",
      "     29  0.5000        \u001b[32m0.4131\u001b[0m       0.8168        0.4084  0.1343\n",
      "     30  0.5049        \u001b[32m0.4122\u001b[0m       0.8093        0.4121  0.1226\n",
      "     31  0.4565        \u001b[32m0.4105\u001b[0m       0.8131        \u001b[31m0.4008\u001b[0m  0.1233\n",
      "     32  \u001b[36m0.5196\u001b[0m        \u001b[32m0.4094\u001b[0m       0.8168        0.4103  0.1268\n",
      "     33  0.5096        0.4101       0.8093        0.4144  0.1231\n",
      "     34  0.4925        \u001b[32m0.4085\u001b[0m       0.8112        0.4090  0.1202\n",
      "     35  0.5073        \u001b[32m0.4068\u001b[0m       0.8112        0.4167  0.1223\n",
      "     36  0.4762        \u001b[32m0.4058\u001b[0m       0.8150        0.4011  0.1650\n",
      "     37  0.4845        \u001b[32m0.4003\u001b[0m       0.8131        0.4134  0.1844\n",
      "     38  \u001b[36m0.5622\u001b[0m        0.4037       \u001b[35m0.8224\u001b[0m        0.4288  0.1707\n",
      "     39  0.4848        0.4074       0.8093        0.4166  0.1791\n",
      "     40  \u001b[36m0.5992\u001b[0m        \u001b[32m0.4001\u001b[0m       0.8150        0.4273  0.1514\n",
      "     41  0.5098        0.4004       0.8131        0.4078  0.1223\n",
      "     42  0.5536        \u001b[32m0.3977\u001b[0m       0.8131        0.4204  0.1546\n",
      "     43  0.5495        \u001b[32m0.3976\u001b[0m       0.8131        0.4252  0.1697\n",
      "     44  0.5641        0.4016       0.8093        0.4283  0.1419\n",
      "     45  0.5776        0.4005       0.8168        0.4100  0.1412\n",
      "     46  0.5200        0.4092       0.8206        0.4071  0.1363\n",
      "     47  0.4813        0.4019       0.8187        \u001b[31m0.3957\u001b[0m  0.1398\n",
      "     48  0.5650        0.3983       0.8187        0.4122  0.1345\n",
      "     49  0.5913        0.4016       \u001b[35m0.8243\u001b[0m        0.4236  0.1241\n",
      "     50  0.5625        0.4010       0.8168        0.4127  0.1303\n",
      "     51  0.5571        0.3989       0.8187        0.4095  0.1221\n",
      "     52  0.5662        \u001b[32m0.3937\u001b[0m       0.8224        0.4038  0.1221\n",
      "     53  0.5377        0.3938       0.8168        0.4219  0.1414\n",
      "     54  0.5217        0.3970       0.8150        0.4195  0.1836\n",
      "     55  0.5421        \u001b[32m0.3910\u001b[0m       0.8168        0.4171  0.1651\n",
      "     56  0.5514        \u001b[32m0.3879\u001b[0m       0.8206        0.4057  0.1684\n",
      "     57  0.5514        \u001b[32m0.3856\u001b[0m       0.8206        0.4011  0.1210\n",
      "     58  0.5556        0.3920       0.8206        0.4011  0.1231\n",
      "     59  0.4921        0.3942       0.8187        0.4007  0.1306\n",
      "     60  0.4813        0.3985       0.8187        0.4054  0.1221\n",
      "     61  0.5327        0.3898       0.8131        0.4027  0.1576\n",
      "     62  0.5507        0.3898       \u001b[35m0.8262\u001b[0m        \u001b[31m0.3855\u001b[0m  0.1832\n",
      "     63  0.5514        0.3922       0.8206        0.4031  0.1644\n",
      "     64  0.5320        0.3921       0.8224        0.4049  0.1409\n",
      "     65  0.5052        0.3910       0.8206        0.4063  0.1305\n",
      "     66  0.4725        0.3883       0.8206        0.4021  0.1281\n",
      "     67  0.4407        0.3974       0.8150        0.3943  0.1216\n",
      "     68  0.5561        \u001b[32m0.3849\u001b[0m       \u001b[35m0.8299\u001b[0m        0.3964  0.1760\n",
      "     69  0.5526        0.3864       0.8093        0.4229  0.1973\n",
      "     70  0.5505        \u001b[32m0.3820\u001b[0m       0.8168        0.4042  0.1861\n",
      "     71  0.5352        0.3869       0.8150        0.4194  0.1495\n",
      "     72  0.5340        0.3856       \u001b[35m0.8336\u001b[0m        0.3994  0.1413\n",
      "     73  0.5495        0.3836       0.8131        0.3998  0.1389\n",
      "     74  0.5143        0.3829       0.8093        0.4218  0.1309\n",
      "     75  0.5347        0.3863       0.8243        0.3860  0.1731\n",
      "     76  0.5561        \u001b[32m0.3811\u001b[0m       0.8150        0.4189  0.1752\n",
      "     77  0.5078        0.3848       0.8224        0.3879  0.1801\n",
      "     78  0.5500        0.3903       0.8318        0.3883  0.1891\n",
      "     79  0.5106        0.3899       0.8280        0.3988  0.1714\n",
      "     80  0.5550        \u001b[32m0.3797\u001b[0m       0.8262        0.4024  0.1326\n",
      "     81  0.4889        0.3900       0.8280        0.3865  0.1286\n",
      "     82  0.5226        \u001b[32m0.3793\u001b[0m       0.8224        0.3921  0.1386\n",
      "     83  0.5274        0.3806       0.8224        0.4104  0.1278\n",
      "     84  0.4740        0.3926       0.8299        0.3979  0.1243\n",
      "     85  0.5306        0.3835       0.8280        0.4073  0.1289\n",
      "     86  0.5446        0.3812       0.8280        0.3980  0.1216\n",
      "     87  0.5794        0.3793       0.8318        0.3983  0.1260\n",
      "     88  0.5312        0.3882       0.8318        0.3917  0.1275\n",
      "     89  0.5714        \u001b[32m0.3782\u001b[0m       0.8206        0.4275  0.1277\n",
      "     90  0.5302        0.3785       0.8112        0.4063  0.1322\n",
      "     91  0.5798        \u001b[32m0.3754\u001b[0m       0.8131        0.4124  0.1339\n",
      "     92  0.5079        0.3873       0.8262        0.3865  0.1301\n",
      "     93  0.5500        \u001b[32m0.3741\u001b[0m       0.8318        0.4000  0.1255\n",
      "     94  0.5333        \u001b[32m0.3722\u001b[0m       0.8299        0.3930  0.1264\n",
      "     95  0.5785        0.3786       0.8093        0.4204  0.1426\n",
      "     96  0.5530        0.3737       0.8187        0.4065  0.1418\n",
      "     97  0.5893        \u001b[32m0.3655\u001b[0m       0.8280        0.4098  0.1261\n",
      "     98  0.5561        0.3757       0.8299        0.3968  0.1271\n",
      "     99  0.5248        0.3726       0.8206        0.3984  0.1305\n",
      "    100  0.5204        0.3732       0.8243        0.4135  0.1278\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0000\u001b[0m        \u001b[32m0.5313\u001b[0m       \u001b[35m0.7888\u001b[0m        \u001b[31m0.5070\u001b[0m  0.1271\n",
      "      2  0.0000        \u001b[32m0.5027\u001b[0m       0.7888        0.5196  0.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3  0.0000        \u001b[32m0.4927\u001b[0m       0.7888        0.5150  0.1322\n",
      "      4  0.0000        \u001b[32m0.4908\u001b[0m       0.7888        0.5181  0.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0.0000        \u001b[32m0.4882\u001b[0m       0.7888        0.5119  0.1277\n",
      "      6  0.0000        \u001b[32m0.4843\u001b[0m       0.7888        0.5075  0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        \u001b[32m0.4820\u001b[0m       0.7888        \u001b[31m0.5038\u001b[0m  0.1278\n",
      "      8  0.0000        \u001b[32m0.4799\u001b[0m       0.7888        \u001b[31m0.5014\u001b[0m  0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0000        \u001b[32m0.4744\u001b[0m       0.7888        \u001b[31m0.4953\u001b[0m  0.1442\n",
      "     10  0.0000        0.4746       0.7888        \u001b[31m0.4906\u001b[0m  0.1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  0.0000        \u001b[32m0.4720\u001b[0m       0.7888        \u001b[31m0.4845\u001b[0m  0.1443\n",
      "     12  0.0000        \u001b[32m0.4675\u001b[0m       0.7888        0.4860  0.1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13  0.0000        0.4723       0.7888        0.4883  0.1321\n",
      "     14  0.0000        \u001b[32m0.4506\u001b[0m       0.7888        \u001b[31m0.4718\u001b[0m  0.1231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15  0.0000        \u001b[32m0.4482\u001b[0m       0.7888        0.4760  0.1346\n",
      "     16  \u001b[36m0.4293\u001b[0m        \u001b[32m0.4467\u001b[0m       \u001b[35m0.7963\u001b[0m        0.4745  0.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17  \u001b[36m0.4433\u001b[0m        \u001b[32m0.4401\u001b[0m       0.7888        \u001b[31m0.4685\u001b[0m  0.1325\n",
      "     18  \u001b[36m0.4513\u001b[0m        0.4419       \u001b[35m0.8000\u001b[0m        \u001b[31m0.4648\u001b[0m  0.1321\n",
      "     19  \u001b[36m0.4683\u001b[0m        \u001b[32m0.4370\u001b[0m       0.7963        \u001b[31m0.4574\u001b[0m  0.1448\n",
      "     20  0.4510        \u001b[32m0.4367\u001b[0m       0.7907        0.4669  0.1300\n",
      "     21  0.4064        \u001b[32m0.4339\u001b[0m       0.7925        0.4587  0.1287\n",
      "     22  \u001b[36m0.4739\u001b[0m        \u001b[32m0.4332\u001b[0m       0.7925        \u001b[31m0.4560\u001b[0m  0.1194\n",
      "     23  0.4677        \u001b[32m0.4293\u001b[0m       0.8000        \u001b[31m0.4527\u001b[0m  0.1317\n",
      "     24  \u001b[36m0.4909\u001b[0m        \u001b[32m0.4270\u001b[0m       0.7907        0.4623  0.1279\n",
      "     25  0.4683        \u001b[32m0.4237\u001b[0m       0.7963        0.4537  0.1224\n",
      "     26  0.4909        \u001b[32m0.4225\u001b[0m       0.7907        0.4561  0.1556\n",
      "     27  0.4673        \u001b[32m0.4212\u001b[0m       0.7869        0.4597  0.1752\n",
      "     28  0.4787        \u001b[32m0.4163\u001b[0m       \u001b[35m0.8168\u001b[0m        \u001b[31m0.4325\u001b[0m  0.1734\n",
      "     29  \u001b[36m0.4932\u001b[0m        0.4207       0.7925        0.4522  0.1749\n",
      "     30  \u001b[36m0.5023\u001b[0m        \u001b[32m0.4111\u001b[0m       0.7963        0.4372  0.1622\n",
      "     31  \u001b[36m0.5094\u001b[0m        0.4200       0.8056        0.4348  0.1684\n",
      "     32  0.5045        \u001b[32m0.4096\u001b[0m       0.7944        0.4466  0.1697\n",
      "     33  0.4623        0.4106       0.8000        0.4336  0.1670\n",
      "     34  0.4878        0.4103       0.8037        0.4346  0.1618\n",
      "     35  0.4902        \u001b[32m0.4083\u001b[0m       0.8056        \u001b[31m0.4311\u001b[0m  0.1828\n",
      "     36  0.4681        0.4139       0.8131        0.4351  0.1742\n",
      "     37  0.5075        0.4106       0.8150        0.4355  0.1850\n",
      "     38  0.4752        \u001b[32m0.4056\u001b[0m       0.8019        0.4465  0.1846\n",
      "     39  \u001b[36m0.5189\u001b[0m        0.4089       0.8093        0.4324  0.1678\n",
      "     40  0.4848        \u001b[32m0.4015\u001b[0m       0.8093        \u001b[31m0.4224\u001b[0m  0.1608\n",
      "     41  0.4663        \u001b[32m0.3998\u001b[0m       0.8075        0.4252  0.1446\n",
      "     42  0.5143        \u001b[32m0.3990\u001b[0m       0.8093        0.4281  0.1258\n",
      "     43  0.4975        \u001b[32m0.3985\u001b[0m       0.8112        0.4282  0.1333\n",
      "     44  0.4975        0.3986       0.8112        0.4284  0.1282\n",
      "     45  0.5140        \u001b[32m0.3978\u001b[0m       0.8056        0.4286  0.1343\n",
      "     46  0.4876        \u001b[32m0.3958\u001b[0m       0.8075        0.4303  0.1381\n",
      "     47  0.4873        \u001b[32m0.3904\u001b[0m       0.8112        0.4252  0.1244\n",
      "     48  0.4737        \u001b[32m0.3880\u001b[0m       0.8131        \u001b[31m0.4185\u001b[0m  0.1367\n",
      "     49  \u001b[36m0.5278\u001b[0m        0.3909       0.8093        0.4279  0.1391\n",
      "     50  0.5025        0.3938       0.8150        0.4193  0.1269\n",
      "     51  \u001b[36m0.5333\u001b[0m        0.3882       0.8168        0.4191  0.1301\n",
      "     52  0.4420        0.3888       0.8112        \u001b[31m0.4142\u001b[0m  0.1274\n",
      "     53  0.4737        \u001b[32m0.3867\u001b[0m       0.8131        \u001b[31m0.4119\u001b[0m  0.1255\n",
      "     54  0.4724        0.3957       0.8037        0.4218  0.1256\n",
      "     55  0.5152        \u001b[32m0.3844\u001b[0m       \u001b[35m0.8206\u001b[0m        0.4141  0.1260\n",
      "     56  0.4747        \u001b[32m0.3829\u001b[0m       0.8056        0.4160  0.1245\n",
      "     57  \u001b[36m0.5463\u001b[0m        0.3842       0.8168        0.4184  0.1383\n",
      "     58  0.5000        0.4063       0.8019        0.4248  0.1291\n",
      "     59  0.5075        0.3991       0.8150        0.4131  0.1202\n",
      "     60  0.5025        0.3880       0.8112        0.4223  0.1295\n",
      "     61  0.5243        \u001b[32m0.3824\u001b[0m       0.8168        0.4223  0.1438\n",
      "     62  0.5050        0.3883       0.8131        0.4146  0.1214\n",
      "     63  0.4868        \u001b[32m0.3807\u001b[0m       0.8187        \u001b[31m0.4061\u001b[0m  0.1203\n",
      "     64  \u001b[36m0.5488\u001b[0m        0.3844       0.8187        0.4182  0.1198\n",
      "     65  0.4923        0.3862       0.8150        0.4130  0.1202\n",
      "     66  0.5000        \u001b[32m0.3774\u001b[0m       0.8206        0.4196  0.1196\n",
      "     67  0.5026        0.3783       0.8187        0.4156  0.1203\n",
      "     68  0.4731        \u001b[32m0.3771\u001b[0m       0.8168        0.4145  0.1227\n",
      "     69  0.5181        \u001b[32m0.3726\u001b[0m       \u001b[35m0.8262\u001b[0m        0.4111  0.1198\n",
      "     70  0.4699        0.3773       0.8187        0.4278  0.1385\n",
      "     71  0.4870        0.3787       0.8150        0.4160  0.1262\n",
      "     72  0.5152        0.3758       0.8206        0.4076  0.1202\n",
      "     73  0.5308        0.3791       0.8150        0.4124  0.1254\n",
      "     74  0.4889        0.3790       \u001b[35m0.8280\u001b[0m        \u001b[31m0.4050\u001b[0m  0.1268\n",
      "     75  0.4839        0.3755       0.8206        0.4104  0.1257\n",
      "     76  0.4809        \u001b[32m0.3717\u001b[0m       0.8224        0.4152  0.1254\n",
      "     77  0.4545        0.3731       0.8206        \u001b[31m0.4048\u001b[0m  0.1468\n",
      "     78  0.5000        0.3751       0.8168        0.4214  0.1252\n",
      "     79  0.4719        0.3759       0.8243        0.4058  0.1250\n",
      "     80  0.4432        0.3755       0.8168        \u001b[31m0.4017\u001b[0m  0.1266\n",
      "     81  0.4891        \u001b[32m0.3711\u001b[0m       0.8243        0.4205  0.1300\n",
      "     82  0.5263        \u001b[32m0.3695\u001b[0m       0.8150        0.4202  0.1243\n",
      "     83  0.4783        \u001b[32m0.3672\u001b[0m       0.8206        0.4085  0.1250\n",
      "     84  0.4674        0.3708       0.8168        0.4046  0.1267\n",
      "     85  0.4894        0.3716       0.8206        0.4062  0.1249\n",
      "     86  0.5178        0.3813       0.8224        0.4275  0.1253\n",
      "     87  0.5128        \u001b[32m0.3648\u001b[0m       0.8224        \u001b[31m0.3955\u001b[0m  0.1288\n",
      "     88  0.4746        0.3664       0.8262        0.3970  0.1281\n",
      "     89  0.4835        0.3702       0.8243        0.4107  0.1349\n",
      "     90  0.5051        0.3684       0.8168        0.4206  0.1420\n",
      "     91  0.5411        0.3686       0.8224        0.4169  0.1227\n",
      "     92  0.4731        \u001b[32m0.3627\u001b[0m       0.8168        0.4161  0.1249\n",
      "     93  0.4633        0.3641       0.8224        0.4007  0.1261\n",
      "     94  0.5152        0.3639       0.8206        0.4065  0.1249\n",
      "     95  0.4633        \u001b[32m0.3619\u001b[0m       0.8224        0.4123  0.1258\n",
      "     96  0.5027        0.3636       0.8262        0.4095  0.1211\n",
      "     97  0.4444        \u001b[32m0.3616\u001b[0m       0.8224        0.4065  0.1245\n",
      "     98  0.4889        0.3674       0.8280        0.4174  0.1280\n",
      "     99  0.5027        0.3637       \u001b[35m0.8299\u001b[0m        0.4095  0.1239\n",
      "    100  0.5155        \u001b[32m0.3612\u001b[0m       0.8243        0.4143  0.1204\n",
      "  epoch      f1    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------  ------------  -----------  ------------  ------\n",
      "      1  \u001b[36m0.0678\u001b[0m        \u001b[32m0.5526\u001b[0m       \u001b[35m0.7944\u001b[0m        \u001b[31m0.4980\u001b[0m  0.1260\n",
      "      2  0.0000        \u001b[32m0.4969\u001b[0m       0.7925        0.5004  0.1606\n",
      "      3  0.0000        \u001b[32m0.4843\u001b[0m       0.7925        0.4997  0.1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4  0.0513        \u001b[32m0.4830\u001b[0m       0.7925        0.4986  0.1302\n",
      "      5  0.0000        \u001b[32m0.4830\u001b[0m       0.7925        0.4990  0.1271\n",
      "      6  0.0000        \u001b[32m0.4806\u001b[0m       0.7925        \u001b[31m0.4965\u001b[0m  0.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7  0.0000        \u001b[32m0.4785\u001b[0m       0.7925        \u001b[31m0.4958\u001b[0m  0.1334\n",
      "      8  0.0000        \u001b[32m0.4751\u001b[0m       0.7925        \u001b[31m0.4933\u001b[0m  0.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9  0.0000        \u001b[32m0.4705\u001b[0m       0.7925        \u001b[31m0.4899\u001b[0m  0.1325\n",
      "     10  0.0000        \u001b[32m0.4676\u001b[0m       0.7925        \u001b[31m0.4876\u001b[0m  0.1283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11  \u001b[36m0.3253\u001b[0m        \u001b[32m0.4625\u001b[0m       0.7907        0.4879  0.1281\n",
      "     12  0.2429        \u001b[32m0.4538\u001b[0m       \u001b[35m0.8019\u001b[0m        \u001b[31m0.4771\u001b[0m  0.1317\n",
      "     13  \u001b[36m0.3394\u001b[0m        \u001b[32m0.4445\u001b[0m       0.7963        \u001b[31m0.4740\u001b[0m  0.1452\n",
      "     14  0.2968        \u001b[32m0.4401\u001b[0m       0.7963        \u001b[31m0.4578\u001b[0m  0.1329\n",
      "     15  \u001b[36m0.3820\u001b[0m        \u001b[32m0.4286\u001b[0m       0.7944        \u001b[31m0.4510\u001b[0m  0.1391\n",
      "     16  \u001b[36m0.4301\u001b[0m        \u001b[32m0.4212\u001b[0m       0.8019        \u001b[31m0.4466\u001b[0m  0.1211\n",
      "     17  0.3830        \u001b[32m0.4185\u001b[0m       0.7832        0.4557  0.1245\n",
      "     18  0.3625        \u001b[32m0.4138\u001b[0m       \u001b[35m0.8093\u001b[0m        \u001b[31m0.4346\u001b[0m  0.1353\n",
      "     19  \u001b[36m0.4358\u001b[0m        0.4143       \u001b[35m0.8112\u001b[0m        \u001b[31m0.4265\u001b[0m  0.1360\n",
      "     20  0.3729        \u001b[32m0.4077\u001b[0m       0.7925        0.4302  0.1393\n",
      "     21  0.3804        0.4095       0.8112        \u001b[31m0.4193\u001b[0m  0.1302\n",
      "     22  0.3837        \u001b[32m0.4063\u001b[0m       0.8019        0.4205  0.1381\n",
      "     23  \u001b[36m0.4677\u001b[0m        \u001b[32m0.4030\u001b[0m       0.8000        \u001b[31m0.4164\u001b[0m  0.1394\n",
      "     24  0.3908        \u001b[32m0.3972\u001b[0m       0.8019        0.4186  0.1261\n",
      "     25  0.4114        0.4005       0.8075        0.4182  0.1400\n",
      "     26  0.4157        \u001b[32m0.3936\u001b[0m       0.8056        \u001b[31m0.4095\u001b[0m  0.1254\n",
      "     27  0.4382        \u001b[32m0.3924\u001b[0m       \u001b[35m0.8131\u001b[0m        \u001b[31m0.4085\u001b[0m  0.1199\n",
      "     28  0.4023        \u001b[32m0.3924\u001b[0m       0.8056        0.4129  0.1200\n",
      "     29  0.4333        \u001b[32m0.3871\u001b[0m       0.8093        \u001b[31m0.4066\u001b[0m  0.1317\n",
      "     30  0.4590        0.3919       \u001b[35m0.8150\u001b[0m        \u001b[31m0.4061\u001b[0m  0.1314\n",
      "     31  \u001b[36m0.4837\u001b[0m        \u001b[32m0.3833\u001b[0m       0.7925        0.4220  0.1287\n",
      "     32  0.4481        \u001b[32m0.3827\u001b[0m       0.8112        \u001b[31m0.3989\u001b[0m  0.1400\n",
      "     33  0.4481        0.3849       0.8112        0.4075  0.1425\n",
      "     34  0.4481        \u001b[32m0.3765\u001b[0m       0.8112        \u001b[31m0.3949\u001b[0m  0.1400\n",
      "     35  0.4817        0.3834       0.8150        0.4017  0.1389\n",
      "     36  0.4138        0.3836       0.8093        0.4014  0.1301\n",
      "     37  0.4592        0.3791       0.8019        0.4016  0.1346\n",
      "     38  0.4181        \u001b[32m0.3763\u001b[0m       0.8075        \u001b[31m0.3916\u001b[0m  0.1328\n",
      "     39  0.4362        0.3777       0.8019        0.3978  0.1413\n",
      "     40  0.4398        \u001b[32m0.3740\u001b[0m       0.8000        0.3981  0.1279\n",
      "     41  0.4420        0.3765       0.8112        0.3967  0.1275\n",
      "     42  0.4318        0.3752       0.8131        0.3966  0.1280\n",
      "     43  0.4674        \u001b[32m0.3725\u001b[0m       \u001b[35m0.8168\u001b[0m        0.3961  0.1290\n",
      "     44  0.4024        0.3758       0.8112        0.3923  0.1297\n",
      "     45  0.4385        \u001b[32m0.3698\u001b[0m       0.8037        0.3939  0.1399\n",
      "     46  0.4565        \u001b[32m0.3652\u001b[0m       0.8131        0.3919  0.1291\n",
      "     47  0.4199        \u001b[32m0.3650\u001b[0m       0.8037        0.3927  0.1309\n",
      "     48  0.4787        \u001b[32m0.3638\u001b[0m       0.8168        0.3938  0.1248\n",
      "     49  0.4481        \u001b[32m0.3612\u001b[0m       0.8112        \u001b[31m0.3890\u001b[0m  0.1243\n",
      "     50  0.4372        0.3638       0.8075        0.3910  0.1275\n",
      "     51  0.4526        0.3617       0.8056        0.3914  0.1359\n",
      "     52  0.4368        \u001b[32m0.3589\u001b[0m       0.8168        0.3902  0.1272\n",
      "     53  0.3827        0.3597       0.8131        0.3946  0.1238\n",
      "     54  0.4229        0.3594       0.8112        0.3937  0.1303\n",
      "     55  \u001b[36m0.5000\u001b[0m        0.3656       0.8131        0.3944  0.1245\n",
      "     56  0.4385        0.3677       0.8037        0.4023  0.1411\n",
      "     57  0.4294        \u001b[32m0.3555\u001b[0m       0.8112        0.3908  0.1284\n",
      "     58  0.4444        0.3597       0.8037        \u001b[31m0.3887\u001b[0m  0.1276\n",
      "     59  0.3758        0.3624       0.8075        0.3976  0.1278\n",
      "     60  0.4199        0.3802       0.8037        0.3983  0.1275\n",
      "     61  0.4385        0.3689       0.8037        0.4062  0.1273\n",
      "     62  0.4396        \u001b[32m0.3552\u001b[0m       0.8093        0.4005  0.1274\n",
      "     63  0.4348        \u001b[32m0.3502\u001b[0m       0.8056        0.4002  0.1325\n",
      "     64  0.4070        0.3542       0.8093        0.4115  0.1274\n",
      "     65  0.4444        0.3514       0.8131        0.4112  0.1446\n",
      "     66  0.4615        \u001b[32m0.3493\u001b[0m       0.8168        0.4064  0.1458\n",
      "     67  0.4024        0.3550       0.8112        0.4038  0.1302\n",
      "     68  0.4199        0.3526       0.8037        0.4130  0.1262\n",
      "     69  0.4023        0.3498       0.8056        0.4019  0.1324\n",
      "     70  0.4469        0.3510       0.8150        0.4015  0.1448\n",
      "     71  0.3953        0.3499       0.8056        0.4092  0.1406\n",
      "     72  0.4396        0.3592       0.8093        0.4128  0.1318\n",
      "     73  0.3636        0.3754       0.8037        0.4236  0.1319\n",
      "     74  0.4309        0.3568       0.8075        0.4146  0.1366\n",
      "     75  0.4731        \u001b[32m0.3479\u001b[0m       0.8168        0.4199  0.1325\n",
      "     76  0.4492        0.3650       0.8075        0.4228  0.1396\n",
      "     77  0.4072        0.3581       0.8150        0.4255  0.1438\n",
      "     78  0.4072        0.3483       0.8150        0.4175  0.1332\n",
      "     79  0.4656        \u001b[32m0.3470\u001b[0m       0.8112        0.4104  0.1465\n",
      "     80  0.4358        0.3541       0.8112        0.4403  0.1407\n",
      "     81  0.4157        0.3590       0.8056        0.4372  0.1390\n",
      "     82  0.4505        0.3495       0.8131        0.4127  0.1298\n",
      "     83  0.3931        0.3536       0.8037        0.4330  0.1303\n",
      "     84  0.3625        0.3506       0.8093        0.4369  0.1328\n",
      "     85  0.4372        \u001b[32m0.3466\u001b[0m       0.8075        0.4476  0.1272\n",
      "     86  0.4091        0.3477       0.8056        0.4444  0.1271\n",
      "     87  0.3952        0.3529       0.8112        0.4373  0.1289\n",
      "     88  0.3810        \u001b[32m0.3466\u001b[0m       0.8056        0.4310  0.1232\n",
      "     89  0.3704        0.3474       0.8093        0.5009  0.1303\n",
      "     90  0.4550        0.3544       0.8075        0.4634  0.1702\n",
      "     91  0.4176        0.3631       0.8019        0.4216  0.1830\n",
      "     92  0.3771        0.3522       0.7963        0.5204  0.1490\n",
      "     93  0.3647        0.3646       0.7981        0.4990  0.1898\n",
      "     94  0.4222        0.3553       0.8056        0.4369  0.1416\n",
      "     95  0.4046        \u001b[32m0.3456\u001b[0m       0.8075        0.4638  0.1573\n",
      "     96  0.3978        0.3459       0.7963        0.4601  0.1720\n",
      "     97  0.4046        0.3519       0.8075        0.5068  0.1508\n",
      "     98  0.4262        0.3601       0.8037        0.4723  0.1396\n",
      "     99  0.4253        0.3461       0.8131        0.4452  0.1436\n",
      "    100  0.3882        \u001b[32m0.3428\u001b[0m       0.8056        0.4920  0.1461\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-c6d9ed0c2902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#rs = GridSearchCV(net, parameters, n_jobs=1, refit=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#                 scoring='f1', cv=3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Predict labels of test data using the trained classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m plot_confusion_matrix(pred_test, y_val, prefix_information='RF',\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0mmodule_triggers_optimizer_reinit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'module'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspecial_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mmodule_triggers_optimizer_reinit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/skorch/net.py\u001b[0m in \u001b[0;36minitialize_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-34e6990bee23>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_channels, n_features, mid_layer_channels, C_k_p_s_1, M_k_s_1, C_k_p_s_2, M_k_s_2, p, add_noise_to_input)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_out_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmid_layer_channels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcurrent_input_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_out_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/lib/python3.6/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0mfan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_correct_fan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "## net = None\n",
    "rs = None\n",
    "accuracy_train_epoch_scoring = EpochScoring(scoring='f1', lower_is_better=False, on_train=False)\n",
    "device = torch.device('cuda:0')\n",
    "n_channels = x_train.shape[1]\n",
    "n_features = x_train.shape[2]\n",
    "n_epochs = 100\n",
    "kernel_size = 2\n",
    "padding_size = 1\n",
    "net = NeuralNetClassifier(module=LeNet5, criterion=nn.CrossEntropyLoss,\n",
    "                          module__n_channels= n_channels,\n",
    "                          module__n_features=n_features,\n",
    "                          module__C_k_p_s_1=[kernel_size,padding_size,1],\n",
    "                          module__M_k_s_1=[2, 2],\n",
    "                          module__M_k_s_2=[2, 2],\n",
    "                          module__C_k_p_s_2=[kernel_size,padding_size,1],\n",
    "                          #module__p = [0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "                          module__mid_layer_channels=33,\n",
    "                          optimizer=optim.Adam, \n",
    "                          optimizer__lr = 0.008,\n",
    "                          #optimizer__weight_decay=0.01,\n",
    "                          max_epochs=n_epochs, \n",
    "                          batch_size=50,\n",
    "                          iterator_train__shuffle=False,\n",
    "                          device=device,\n",
    "                          warm_start=True,#train_split=None,\n",
    "                          callbacks=[accuracy_epoch_scoring],\n",
    "                         )\n",
    "model_name = LeNet5.__name__\n",
    "rs = RandomizedSearchCV(net, parameters, refit=True, \n",
    "                        n_iter=10, n_jobs=1,\n",
    "                       cv=3, scoring='f1')\n",
    "#rs = GridSearchCV(net, parameters, n_jobs=1, refit=True, \n",
    "#                 scoring='f1', cv=3)\n",
    "rs.fit(x_train, y_train)\n",
    "pred_test = rs.predict(x_val)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_val, prefix_information='RF',\n",
    "                          dataset_name='', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'module__C_k_p_s_1': [3, 1, 1], 'module__C_k_p_s_2': [2, 2, 1]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LSTM_0. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model_dir_path = 'models'\n",
    "model_filename = \"{:s}/{}_LSTM_model_acc-{:2.3f}_{:s}_FINAL.model\".format(\n",
    "    model_dir_path, 'yahoo_data', accuracy_of_net, strftime(\"%Y_%m_%d_%H_%M_%S\", localtime())\n",
    ")\n",
    "pickle.dump(model, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
