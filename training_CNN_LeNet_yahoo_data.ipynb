{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PipelineResources import * # This is where we have all of the resources that will be used in the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = pd.read_pickle('upm_yahoo.pckl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training, validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Test: Use a CNN Model to predict whether or not the next day will close above 1.5 %. \n",
    "The goal behind this exercise is to establish a baseline model and performance. In addition, it is also work out the way the data will be stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample size is: 4755\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = nasdaq.index.size\n",
    "print(\" Sample size is: {}\".format(number_of_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
       "       'open_change', 'open_change_pct', 'next_day_open_change',\n",
       "       'next_day_open_change_pct', 'open_change_wrt_close',\n",
       "       'open_change_wrt_close_pct', 'open_change_wrt_high',\n",
       "       'open_change_wrt_low', 'open_change_wrt_volume',\n",
       "       'next_day_open_change_wrt_close', 'next_day_open_change_wrt_close_pct',\n",
       "       'next_day_open_change_wrt_high', 'next_day_open_change_wrt_low',\n",
       "       'next_day_open_change_wrt_volume', 'close_change_pct', 'close_change',\n",
       "       'high_change_pct', 'high_change', 'low_change_pct', 'low_change',\n",
       "       'volume_change_pct', 'volume_change', 'high_low_range',\n",
       "       'high_low_range_with_ref_open', 'high_low_range_with_ref_open_pct',\n",
       "       'high_low_range_with_ref_close', 'high_low_range_with_ref_close_pct',\n",
       "       'gt_1', 'gt_1.5', 'gt_2.5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasdaq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of days per samples: 1\n",
      "(4751,)\n",
      "[0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "(4751, 13)\n",
      "(3563, 13)\n"
     ]
    }
   ],
   "source": [
    "### random_state = 1\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = get_input_sets(nasdaq, chosen_features, \n",
    "                                                                chosen_label, x_test=False,\n",
    "                                                               number_of_days_per_sample=1)\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075\n",
      "967\n",
      "(221,)\n",
      "(221, 13)\n",
      "3240\n",
      "2916\n",
      "(647,)\n",
      "(647, 13)\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = decrease_class_rows(x_val, y_val, \n",
    "                                   class_number=0, \n",
    "                                   percentage_cut=0.90)\n",
    "x_train, y_train = decrease_class_rows(x_train, y_train, \n",
    "                                       class_number=0, \n",
    "                                       percentage_cut=0.90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup multi channels and FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647, 2, 13)\n",
      "(221, 2, 13)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, x_test = modify_dataset_channels(x_train, x_val, \n",
    "                                                 x_test=False, \n",
    "                                                 compute_fft=True, \n",
    "                                                 multi_channel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, n_channels, n_features, mid_layer_channels=16,\n",
    "                 C_k_p_s_1=[2, 0, 1], M_k_s_1=[2, 2], C_k_p_s_2=[2, 0, 1],\n",
    "                 M_k_s_2=[2, 2], p=[0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                 add_noise_to_input=False):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.add_noise_to_input = add_noise_to_input\n",
    "        self.name = 'LetNet5'\n",
    "        self.conv1d_1 = nn.Conv1d(n_channels, mid_layer_channels,\n",
    "                                  kernel_size=C_k_p_s_1[0], padding=C_k_p_s_1[1],\n",
    "                                  stride=C_k_p_s_1[2])\n",
    "        # self.batch_1 = nn.BatchNorm1d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool_1 = nn.MaxPool1d(kernel_size=M_k_s_1[0],\n",
    "                                       stride=M_k_s_1[1])\n",
    "        current_input_size = \\\n",
    "        (1 + (n_features - C_k_p_s_1[0] + 2 * C_k_p_s_1[1]) / C_k_p_s_1[2]) / M_k_s_1[0]\n",
    "        current_input_size = int(current_input_size)\n",
    "        self.drop_out_1 = nn.Dropout(p=p[0])\n",
    "        # bp()\n",
    "        self.conv1d_2 = nn.Conv1d(mid_layer_channels,\n",
    "                                  2 * mid_layer_channels, \n",
    "                                  kernel_size=C_k_p_s_2[0],\n",
    "                                  padding=C_k_p_s_2[1],\n",
    "                                  stride=C_k_p_s_2[2])\n",
    "        current_input_size = \\\n",
    "        (1 + (current_input_size - C_k_p_s_2[0] + 2 * C_k_p_s_2[1]) / C_k_p_s_2[2]) / M_k_s_1[0]\n",
    "        current_input_size = int(current_input_size)\n",
    "        self.drop_out_2 = nn.Dropout(p=p[1])\n",
    "        self.max_pool_2 = nn.MaxPool1d(kernel_size=M_k_s_2[0],\n",
    "                                       stride=M_k_s_2[1])\n",
    "        \n",
    "        self.fc1 = nn.Linear(2 * mid_layer_channels * current_input_size, 120)\n",
    "        self.drop_out_3 = nn.Dropout(p=p[2])\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.drop_out_4 = nn.Dropout(p=p[3])\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.drop_out_5 = nn.Dropout(p=p[4])\n",
    "        # self.soft_max = nn.Softmax(dim=1)\n",
    "        self.fc4 = nn.Linear(10, 2)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # bp()\n",
    "        x = x.float()\n",
    "        #if self.add_noise_to_input:\n",
    "        #    x = add_noise(x)\n",
    "        #    x = x.float()\n",
    "        x = self.max_pool_1(self.relu(self.drop_out_1(self.conv1d_1(x))))\n",
    "        # bp()\n",
    "        x = self.max_pool_2(self.relu(self.drop_out_2(self.conv1d_2(x))))\n",
    "        x = x.view(x.shape[0], x.shape[1] * x.shape[2])\n",
    "        x = self.relu(self.drop_out_3(self.fc1(x)))\n",
    "        x = self.relu(self.drop_out_4(self.fc2(x)))\n",
    "        x = self.relu(self.drop_out_5(self.fc3(x)))\n",
    "        # x = self.sigmoid(self.fc4(x))\n",
    "        # bp()\n",
    "        # x = self.soft_max(self.fc4(x))\n",
    "        # x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        #fc4_output = self.fc4(x)\n",
    "        #print(fc4_output)\n",
    "        #x = F.softmax(fc4_output, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgLeNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_features, mid_layer_channels=16,\n",
    "                 C_k_p_s_1=[2, 0, 1], M_k_s_1=[2, 2], C_k_p_s_2=[2, 0, 1],\n",
    "                 M_k_s_2=[2, 2], p=[0.0, 0.0, 0.0, 0.0, 0.0]):\n",
    "        super(AvgLeNet, self).__init__()\n",
    "        self.name = 'AvgLeNet'\n",
    "        self.conv1d_1 = nn.Conv1d(n_channels,\n",
    "                                  mid_layer_channels,\n",
    "                                  kernel_size=C_k_p_s_1[0],\n",
    "                                  padding=C_k_p_s_1[1],\n",
    "                                  stride=C_k_p_s_1[2])\n",
    "        # self.batch_1 = nn.BatchNorm1d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool_1 = nn.MaxPool1d(kernel_size=M_k_s_1[0],\n",
    "                                       stride=M_k_s_1[1])\n",
    "        current_input_size = \\\n",
    "        (1 + (n_features - C_k_p_s_1[0] + 2 * C_k_p_s_1[1]) / C_k_p_s_1[2]) / M_k_s_1[0]\n",
    "        current_input_size = int(current_input_size)\n",
    "        self.drop_out_1 = nn.Dropout(p=p[0])\n",
    "        # bp()\n",
    "        self.conv1d_2 = nn.Conv1d(mid_layer_channels,\n",
    "                                  2 * mid_layer_channels, kernel_size=C_k_p_s_2[0],\n",
    "                                  padding=C_k_p_s_2[1],\n",
    "                                  stride=C_k_p_s_2[2])\n",
    "        current_input_size = \\\n",
    "        (1 + (current_input_size - C_k_p_s_2[0] + 2 * C_k_p_s_2[1]) / C_k_p_s_2[2]) / M_k_s_1[0]\n",
    "        current_input_size = int(current_input_size)\n",
    "        self.drop_out_2 = nn.Dropout(p=p[1])\n",
    "        self.max_pool_2 = nn.MaxPool1d(kernel_size=M_k_s_2[0],\n",
    "                                       stride=M_k_s_2[1])\n",
    "        \n",
    "        self.fc1 = nn.Linear(2 * mid_layer_channels * current_input_size, 120)\n",
    "        self.drop_out_3 = nn.Dropout(p=p[2])\n",
    "        self.avg_pool_1 = nn.AvgPool1d(10)\n",
    "        \n",
    "        self.fc2 = nn.Linear(12, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # bp()\n",
    "        x = x.float()\n",
    "        x = self.max_pool_1(self.relu(self.drop_out_1(self.conv1d_1(x))))\n",
    "        # bp()\n",
    "        x = self.max_pool_2(self.relu(self.drop_out_2(self.conv1d_2(x))))\n",
    "        x = x.view(x.shape[0], x.shape[1] * x.shape[2])\n",
    "        #bp()\n",
    "        x = self.avg_pool_1(self.relu(self.drop_out_3(self.fc1(x.reshape(x.shape[0],\n",
    "                                                                         1,x.shape[1])))))\n",
    "        \n",
    "        x = self.fc2(x.reshape(x.shape[0],x.shape[2]))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input data for pytorch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input tensor: torch.Size([647, 2, 13])\n",
      "loss: 0.6963527798652649\n",
      "The shapes seem to be ok.\n"
     ]
    }
   ],
   "source": [
    "model_name = AvgLeNet.__name__\n",
    "device = torch.device('cuda:0')\n",
    "n_channels = x_train.shape[1]\n",
    "n_features = x_train.shape[2]\n",
    "net = AvgLeNet(n_channels, n_features)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    #bp()\n",
    "    input_data = torch.tensor(x_train).float()\n",
    "    labels = torch.tensor(y_train).long()\n",
    "    input_data = input_data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    print('Shape of the input tensor:', input_data.shape)\n",
    "    y = net(input_data)\n",
    "    loss = criterion(y, labels)\n",
    "    print('loss: {}'.format(loss))\n",
    "    assert y.shape == torch.Size([y_train.shape[0], 2]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "print('The shapes seem to be ok.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6658\u001b[0m    \u001b[32m0.6667\u001b[0m        \u001b[35m0.7012\u001b[0m       \u001b[31m0.5000\u001b[0m        \u001b[94m0.6958\u001b[0m  0.0246\n",
      "      2      0.6624    0.6667        \u001b[35m0.6938\u001b[0m       0.5000        \u001b[94m0.6933\u001b[0m  0.0230\n",
      "      3      0.3832    0.0000        0.6950       0.5000        0.6938  0.0247\n",
      "      4      0.1415    0.0000        \u001b[35m0.6928\u001b[0m       0.5000        0.6947  0.0272\n",
      "      5      0.0000    0.0000        0.6979       0.5000        0.6934  0.0287\n",
      "      6      0.0000    0.0000        \u001b[35m0.6921\u001b[0m       0.5000        \u001b[94m0.6925\u001b[0m  0.0281\n",
      "      7      0.0000    0.0000        0.6924       0.5000        \u001b[94m0.6922\u001b[0m  0.0281\n",
      "      8      0.0000    0.0000        0.6930       0.5000        0.6932  0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9      0.3605    0.6667        0.6937       0.5000        0.6932  0.0288\n",
      "     10      0.6105    0.6667        0.6932       0.5000        0.6932  0.0311\n",
      "     11      0.6388    0.6667        0.6934       0.5000        0.6932  0.0274\n",
      "     12      0.6436    0.6667        0.6931       0.5000        0.6932  0.0248\n",
      "     13      0.6576    0.6667        0.6928       0.5000        0.6933  0.0253\n",
      "     14      0.6658    0.6667        0.6930       0.5000        0.6933  0.0242\n",
      "     15      0.6632    0.6667        0.6935       0.5000        0.6934  0.0220\n",
      "     16      0.6641    0.6667        0.6937       0.5000        0.6932  0.0222\n",
      "     17      0.6604    0.6667        0.6929       0.5000        0.6931  0.0208\n",
      "     18      0.6490    \u001b[32m0.6667\u001b[0m        0.6927       \u001b[31m0.5385\u001b[0m        0.6928  0.0251\n",
      "     19      0.5567    0.1370        0.6935       0.5154        0.6923  0.0237\n",
      "     20      0.4770    0.5333        0.6931       \u001b[31m0.5692\u001b[0m        \u001b[94m0.6917\u001b[0m  0.0271\n",
      "     21      0.6024    0.4314        \u001b[35m0.6917\u001b[0m       0.5538        \u001b[94m0.6902\u001b[0m  0.0250\n",
      "     22      0.4825    0.3656        0.6923       0.5462        0.6906  0.0260\n",
      "     23      0.5957    0.6667        0.6940       0.5000        0.6933  0.0217\n",
      "     24      \u001b[36m0.6684\u001b[0m    0.6667        0.6933       0.5000        0.6935  0.0278\n",
      "     25      0.6667    0.6667        0.6933       0.5000        0.6926  0.0247\n",
      "     26      0.6499    0.6667        0.6928       0.5000        0.6913  0.0260\n",
      "     27      0.6629    0.6000        \u001b[35m0.6910\u001b[0m       0.5385        \u001b[94m0.6899\u001b[0m  0.0273\n",
      "     28      0.6242    0.4571        \u001b[35m0.6879\u001b[0m       0.5615        \u001b[94m0.6887\u001b[0m  0.0253\n",
      "     29      0.5389    0.5197        \u001b[35m0.6856\u001b[0m       0.5308        \u001b[94m0.6864\u001b[0m  0.0275\n",
      "     30      0.6531    \u001b[32m0.6702\u001b[0m        0.6866       0.5231        0.6922  0.0265\n",
      "     31      0.6667    0.6629        0.6930       0.5385        0.6869  0.0293\n",
      "     32      0.6544    0.4386        \u001b[35m0.6819\u001b[0m       0.5077        0.6941  0.0373\n",
      "     33      0.5543    0.6369        0.7102       0.5615        0.6866  0.0218\n",
      "     34      0.6657    0.6282        0.6857       0.5538        0.6886  0.0271\n",
      "     35      0.6244    0.5424        0.6892       \u001b[31m0.5846\u001b[0m        0.6866  0.0274\n",
      "     36      0.6007    0.4717        0.6820       0.5692        \u001b[94m0.6849\u001b[0m  0.0222\n",
      "     37      0.5714    0.4673        \u001b[35m0.6798\u001b[0m       0.5615        \u001b[94m0.6848\u001b[0m  0.0246\n",
      "     38      0.5891    0.5797        0.6821       0.5538        \u001b[94m0.6839\u001b[0m  0.0237\n",
      "     39      0.6451    0.6093        \u001b[35m0.6729\u001b[0m       0.5462        \u001b[94m0.6778\u001b[0m  0.0240\n",
      "     40      0.6459    0.5410        0.6806       0.5692        0.6780  0.0250\n",
      "     41      0.6336    0.5899        \u001b[35m0.6683\u001b[0m       0.5615        \u001b[94m0.6749\u001b[0m  0.0263\n",
      "     42      0.6352    0.5455        \u001b[35m0.6620\u001b[0m       0.5769        0.6768  0.0284\n",
      "     43      0.5880    0.5736        0.6749       0.5769        \u001b[94m0.6723\u001b[0m  0.0311\n",
      "     44      0.6239    0.5299        \u001b[35m0.6504\u001b[0m       0.5769        \u001b[94m0.6676\u001b[0m  0.0320\n",
      "     45      0.6442    0.3696        0.6720       0.5538        0.6842  0.0334\n",
      "     46      0.6082    0.4870        0.6709       0.5462        0.6812  0.0314\n",
      "     47      0.6362    0.5736        0.6660       0.5769        0.6763  0.0323\n",
      "     48      \u001b[36m0.6729\u001b[0m    0.6207        0.6713       0.5769        0.6786  0.0284\n",
      "     49      0.6339    0.5714        0.6836       0.5846        0.6745  0.0275\n",
      "     50      0.6623    0.5410        0.6576       0.5692        0.6774  0.0308\n",
      "     51      0.5403    0.3182        0.6657       0.5385        0.6842  0.0316\n",
      "     52      0.5691    0.4660        0.6603       0.5769        0.6779  0.0306\n",
      "     53      0.6397    0.5882        \u001b[35m0.6426\u001b[0m       \u001b[31m0.6231\u001b[0m        0.6725  0.0252\n",
      "     54      0.6371    0.2683        \u001b[35m0.6167\u001b[0m       0.5385        0.7002  0.0261\n",
      "     55      0.5950    0.6240        0.6395       \u001b[31m0.6385\u001b[0m        \u001b[94m0.6452\u001b[0m  0.0237\n",
      "     56      0.6542    0.4086        0.6383       0.5769        0.6621  0.0232\n",
      "     57      0.6526    0.6667        0.6311       \u001b[31m0.6615\u001b[0m        \u001b[94m0.6401\u001b[0m  0.0247\n",
      "     58      0.6667    0.3636        0.6364       0.5692        0.6704  0.0238\n",
      "     59      0.5151    0.2308        0.6604       0.5385        0.6783  0.0251\n",
      "     60      0.5833    0.6525        0.6597       0.6231        0.6734  0.0277\n",
      "     61      0.6411    0.3505        0.6644       0.5154        0.6818  0.0262\n",
      "     62      0.5209    0.4242        0.6629       0.5615        0.6728  0.0278\n",
      "     63      0.5646    0.6519        0.6488       0.6385        0.6441  0.0234\n",
      "     64      0.6296    \u001b[32m0.6918\u001b[0m        0.6380       0.6231        \u001b[94m0.6386\u001b[0m  0.0232\n",
      "     65      0.6308    0.5714        \u001b[35m0.6157\u001b[0m       0.6308        0.6504  0.0215\n",
      "     66      0.5367    0.5586        0.6383       0.6231        0.6479  0.0246\n",
      "     67      0.5747    0.6261        0.6412       \u001b[31m0.6692\u001b[0m        \u001b[94m0.6327\u001b[0m  0.0283\n",
      "     68      0.5672    0.4130        0.6314       0.5846        0.6566  0.0243\n",
      "     69      0.6161    0.6525        0.6263       0.6231        \u001b[94m0.6305\u001b[0m  0.0254\n",
      "     70      \u001b[36m0.6877\u001b[0m    0.4660        0.6262       0.5769        0.6613  0.0248\n",
      "     71      0.5600    0.4860        \u001b[35m0.6131\u001b[0m       0.5769        0.6560  0.0275\n",
      "     72      0.5964    0.6230        0.6176       0.6462        0.6375  0.0282\n",
      "     73      0.5746    0.4902        0.6250       0.6000        0.6535  0.0295\n",
      "     74      0.5349    0.5664        0.6391       0.6231        0.6434  0.0252\n",
      "     75      0.5892    \u001b[32m0.6935\u001b[0m        0.6304       \u001b[31m0.7077\u001b[0m        0.6314  0.0282\n",
      "     76      0.5659    0.3294        0.6243       0.5615        0.6725  0.0272\n",
      "     77      0.5630    0.6917        0.6225       0.6846        \u001b[94m0.6232\u001b[0m  0.0299\n",
      "     78      0.6512    0.6168        0.6193       0.6846        0.6270  0.0320\n",
      "     79      0.5228    0.4742        0.6362       0.6077        0.6378  0.0305\n",
      "     80      0.6555    0.6901        \u001b[35m0.5948\u001b[0m       0.6615        0.6381  0.0282\n",
      "     81      \u001b[36m0.7025\u001b[0m    0.6182        0.6034       0.6769        0.6287  0.0296\n",
      "     82      0.6575    0.5741        \u001b[35m0.5892\u001b[0m       0.6462        0.6431  0.0319\n",
      "     83      0.6638    0.5946        0.6144       0.6538        0.6376  0.0323\n",
      "     84      0.6014    0.4086        0.6145       0.5769        0.6677  0.0318\n",
      "     85      0.6128    0.6486        0.6344       0.6000        0.6599  0.0328\n",
      "     86      0.6939    0.6018        0.6163       0.6538        0.6496  0.0320\n",
      "     87      0.6123    0.6050        0.6182       0.6385        0.6401  0.0290\n",
      "     88      0.6679    0.6619        0.6129       0.6385        0.6420  0.0315\n",
      "     89      0.6038    0.4902        0.6206       0.6000        0.6541  0.0290\n",
      "     90      0.5935    0.6034        0.6107       0.6462        0.6298  0.0254\n",
      "     91      0.6717    \u001b[32m0.6944\u001b[0m        0.6124       0.6615        \u001b[94m0.6230\u001b[0m  0.0288\n",
      "     92      0.6831    0.6549        0.6146       0.7000        0.6294  0.0309\n",
      "     93      0.6396    0.6557        0.6143       0.6769        0.6330  0.0313\n",
      "     94      0.6680    0.6333        0.5895       0.6615        \u001b[94m0.6202\u001b[0m  0.0308\n",
      "     95      0.6599    0.6333        0.6103       0.6615        \u001b[94m0.6165\u001b[0m  0.0310\n",
      "     96      0.6787    0.6400        \u001b[35m0.5857\u001b[0m       0.6538        \u001b[94m0.6098\u001b[0m  0.0288\n",
      "     97      0.6802    0.6441        0.5870       0.6769        \u001b[94m0.6032\u001b[0m  0.0257\n",
      "     98      0.6199    0.6095        0.6131       0.6846        0.6162  0.0297\n",
      "     99      0.6710    0.6182        \u001b[35m0.5847\u001b[0m       0.6769        0.6109  0.0311\n",
      "    100      0.6472    0.6214        0.5950       0.7000        0.6239  0.0287\n",
      "    101      0.6467    \u001b[32m0.6993\u001b[0m        0.6104       0.6692        \u001b[94m0.6019\u001b[0m  0.0287\n",
      "    102      0.7023    0.6613        0.6092       0.6769        \u001b[94m0.5991\u001b[0m  0.0280\n",
      "    103      0.6623    \u001b[32m0.7092\u001b[0m        \u001b[35m0.5846\u001b[0m       0.6846        0.6010  0.0259\n",
      "    104      \u001b[36m0.7086\u001b[0m    0.6833        0.5916       0.7077        \u001b[94m0.5870\u001b[0m  0.0244\n",
      "    105      0.6891    0.6923        \u001b[35m0.5618\u001b[0m       0.6923        0.5897  0.0263\n",
      "    106      0.7056    0.6783        \u001b[35m0.5614\u001b[0m       \u001b[31m0.7154\u001b[0m        \u001b[94m0.5736\u001b[0m  0.0282\n",
      "    107      0.6876    0.6929        \u001b[35m0.5405\u001b[0m       0.7000        0.5812  0.0294\n",
      "    108      0.7012    0.6441        0.5734       0.6769        0.5962  0.0301\n",
      "    109      0.6359    0.5981        0.5889       0.6692        0.6190  0.0289\n",
      "    110      0.6842    0.6846        0.5894       0.6385        0.6083  0.0274\n",
      "    111      0.6810    0.6364        0.5834       0.6923        0.6115  0.0304\n",
      "    112      0.6867    0.6250        0.5762       0.6769        0.5977  0.0261\n",
      "    113      \u001b[36m0.7398\u001b[0m    0.6875        0.5482       0.6923        0.5854  0.0269\n",
      "    114      0.6909    0.6486        0.5831       0.7000        0.6022  0.0245\n",
      "    115      0.6820    0.6239        0.5848       0.6846        0.6112  0.0305\n",
      "    116      0.6809    0.6769        0.5964       0.6769        0.6022  0.0307\n",
      "    117      0.7121    0.6774        0.5937       0.6923        0.5987  0.0301\n",
      "    118      0.6985    0.6435        0.5784       0.6846        0.5793  0.0241\n",
      "    119      0.6751    0.6833        0.5923       0.7077        \u001b[94m0.5730\u001b[0m  0.0295\n",
      "    120      0.7291    0.6126        0.5560       0.6692        0.6053  0.0286\n",
      "    121      0.6576    0.6167        0.5923       0.6462        0.6200  0.0281\n",
      "    122      0.7052    0.6667        0.5852       0.6462        0.6033  0.0285\n",
      "    123      0.7066    \u001b[32m0.7231\u001b[0m        0.5792       \u001b[31m0.7231\u001b[0m        0.5865  0.0274\n",
      "    124      0.7127    0.6504        0.5796       0.6692        0.5880  0.0266\n",
      "    125      0.6528    0.5455        0.5776       0.6538        0.6321  0.0224\n",
      "    126      0.6443    0.6950        0.5867       0.6692        0.5990  0.0238\n",
      "    127      0.7176    0.6612        0.5842       0.6846        0.5895  0.0278\n",
      "    128      0.6739    0.7154        0.5490       \u001b[31m0.7308\u001b[0m        0.5811  0.0257\n",
      "    129      0.6983    0.7143        0.5662       0.7231        0.5988  0.0237\n",
      "    130      0.6949    0.7049        0.5545       0.7231        0.5988  0.0237\n",
      "    131      0.7119    0.7068        0.5574       0.7000        0.5917  0.0278\n",
      "    132      0.7173    0.7164        0.5765       0.7077        0.5935  0.0230\n",
      "    133      0.7200    0.7143        0.5608       0.7231        0.5931  0.0234\n",
      "    134      0.7011    0.7040        0.5666       0.7154        0.5938  0.0230\n",
      "    135      0.7012    0.7040        0.5614       0.7154        0.5747  0.0212\n",
      "    136      0.7326    0.6496        \u001b[35m0.5350\u001b[0m       0.6846        0.5863  0.0215\n",
      "    137      0.7355    \u001b[32m0.7419\u001b[0m        0.5544       \u001b[31m0.7538\u001b[0m        \u001b[94m0.5617\u001b[0m  0.0218\n",
      "    138      0.7122    0.7009        0.5585       0.7308        \u001b[94m0.5595\u001b[0m  0.0255\n",
      "    139      0.6985    0.6897        0.5508       0.7231        0.5606  0.0306\n",
      "    140      0.7179    0.5882        \u001b[35m0.5205\u001b[0m       0.6769        0.5862  0.0263\n",
      "    141      0.6837    0.6552        0.5474       0.6923        0.5847  0.0287\n",
      "    142      0.6888    0.6168        0.6252       0.6846        0.6020  0.0266\n",
      "    143      0.6323    0.6038        0.6066       0.6769        0.6017  0.0239\n",
      "    144      0.7115    0.7040        0.5680       0.7154        0.5900  0.0291\n",
      "    145      0.6883    0.6491        0.5656       0.6923        0.5891  0.0291\n",
      "    146      0.6742    0.6783        0.5515       0.7154        0.5741  0.0278\n",
      "    147      0.6989    0.6891        0.5563       0.7154        0.5671  0.0280\n",
      "    148      0.7143    0.6897        0.5475       0.7231        0.5657  0.0257\n",
      "    149      0.7192    0.6306        0.5444       0.6846        0.5682  0.0268\n",
      "    150      0.6726    0.6435        0.5550       0.6846        0.5697  0.0241\n",
      "    151      0.6880    0.5872        0.5803       0.6538        0.6075  0.0270\n",
      "    152      0.6623    0.5741        0.5832       0.6462        0.6217  0.0289\n",
      "    153      0.6958    0.6667        0.5655       0.6923        0.5994  0.0286\n",
      "    154      0.6917    0.6452        0.5698       0.6615        0.6041  0.0270\n",
      "    155      0.7152    0.6935        0.5487       0.7077        0.5829  0.0289\n",
      "    156      0.7206    0.6724        0.5522       0.7077        0.5744  0.0281\n",
      "    157      0.7128    0.6949        0.5533       0.7231        0.5837  0.0296\n",
      "    158      0.7046    0.7194        0.5595       0.7000        0.5756  0.0282\n",
      "    159      0.7117    0.7206        0.5685       0.7077        0.5689  0.0320\n",
      "    160      0.6711    0.6789        0.5718       0.7308        0.5847  0.0319\n",
      "    161      0.6546    0.7077        0.5939       0.7077        0.5748  0.0284\n",
      "    162      0.7079    0.6720        0.5848       0.6846        0.5803  0.0213\n",
      "    163      0.6469    0.5263        0.5787       0.6538        0.6190  0.0228\n",
      "    164      0.6135    0.6607        0.5887       0.7077        0.5935  0.0230\n",
      "    165      0.7078    0.7260        0.5601       0.6923        0.5865  0.0231\n",
      "    166      0.7243    0.6542        0.5789       0.7154        0.5693  0.0234\n",
      "    167      0.6348    0.6139        0.5741       0.7000        0.5817  0.0253\n",
      "    168      0.6908    0.7231        0.5417       0.7231        0.5616  0.0275\n",
      "    169      0.7002    0.5657        0.5681       0.6692        0.5925  0.0293\n",
      "    170      0.6900    0.6714        0.5598       0.6462        0.6037  0.0302\n",
      "    171      0.6780    0.6838        0.5861       0.7154        0.6004  0.0294\n",
      "    172      0.6424    0.5825        0.5636       0.6692        0.6060  0.0290\n",
      "    173      0.6214    0.6552        0.5794       0.6923        0.6006  0.0301\n",
      "    174      0.7000    0.6723        0.5798       0.7000        0.6003  0.0270\n",
      "    175      0.6316    0.6355        0.5818       0.7000        0.6067  0.0236\n",
      "    176      0.6594    0.7077        0.5756       0.7077        0.5800  0.0270\n",
      "    177      0.7324    0.6992        0.5699       0.7154        0.5676  0.0258\n",
      "    178      0.7066    0.6372        0.5605       0.6846        0.5822  0.0259\n",
      "    179      0.7029    0.7206        0.5401       0.7077        0.5767  0.0281\n",
      "    180      0.7033    0.7154        0.5723       0.7308        0.5796  0.0251\n",
      "    181      0.7105    0.7176        0.5761       0.7154        0.5719  0.0244\n",
      "    182      0.7214    \u001b[32m0.7519\u001b[0m        0.5472       0.7462        0.5662  0.0311\n",
      "    183      0.7294    0.7176        0.5543       0.7154        0.5734  0.0306\n",
      "    184      0.7246    0.7194        0.5388       0.7000        0.5860  0.0289\n",
      "    185      0.7033    0.7324        0.5693       0.7077        0.5724  0.0279\n",
      "    186      0.7248    0.7218        0.5352       0.7154        0.5771  0.0304\n",
      "    187      0.6983    0.7463        0.5590       0.7385        0.5625  0.0305\n",
      "    188      0.7223    0.7360        0.5669       0.7462        \u001b[94m0.5585\u001b[0m  0.0294\n",
      "    189      0.6447    0.6612        0.5718       0.6846        0.5884  0.0278\n",
      "    190      0.6948    0.7143        0.5680       0.7231        0.5806  0.0255\n",
      "    191      0.6726    0.6306        0.5670       0.6846        0.5907  0.0297\n",
      "    192      0.6681    0.7101        0.6087       0.6923        0.5986  0.0292\n",
      "    193      0.6969    0.6486        0.5819       0.7000        0.5999  0.0288\n",
      "    194      0.6725    0.7344        0.5722       0.7385        0.5775  0.0304\n",
      "    195      0.7183    0.7429        0.5575       0.7231        0.5695  0.0287\n",
      "    196      \u001b[36m0.7470\u001b[0m    0.7385        0.5292       0.7385        \u001b[94m0.5553\u001b[0m  0.0270\n",
      "    197      0.7195    0.7190        0.5532       0.6692        0.6044  0.0306\n",
      "    198      0.7190    0.6783        0.5901       0.7154        0.6072  0.0292\n",
      "    199      0.6590    0.6897        0.5867       0.7231        0.6054  0.0292\n",
      "    200      0.6815    0.7143        0.5966       0.6923        0.5898  0.0316\n",
      "Accuracy of Net: 0.75\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.74      0.75       324\n",
      "          1       0.75      0.76      0.75       323\n",
      "\n",
      "avg / total       0.75      0.75      0.75       647\n",
      "\n",
      "Accuracy of Net: 0.70\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.63      0.67       108\n",
      "          1       0.68      0.76      0.72       113\n",
      "\n",
      "avg / total       0.70      0.70      0.70       221\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = None\n",
    "noise_training = False\n",
    "\n",
    "n_channels = x_train.shape[1]\n",
    "n_features = x_train.shape[2]\n",
    "device = torch.device('cuda:0')\n",
    "accuracy_epoch_scoring_val = EpochScoring(scoring='f1',name='f1_val',\n",
    "                                          lower_is_better=False, on_train=False)\n",
    "accuracy_epoch_scoring_train = EpochScoring(scoring='f1',name='f1_train',\n",
    "                                            lower_is_better=False, on_train=True)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='valid_acc',\n",
    "                                         patience=5,\n",
    "                                         lower_is_better=False)\n",
    "n_epochs = 200\n",
    "kernel_size = n_features\n",
    "padding_size = int(n_features/2)\n",
    "model = NeuralNetClassifier(module=LeNet5, criterion=nn.CrossEntropyLoss,\n",
    "                          module__n_channels= n_channels,\n",
    "                          module__n_features=n_features,\n",
    "                          module__C_k_p_s_1=[kernel_size,padding_size,2],\n",
    "                          module__M_k_s_1=[2, 2],\n",
    "                          module__M_k_s_2=[2, 2],\n",
    "                          module__C_k_p_s_2=[kernel_size,padding_size,2],\n",
    "                          module__p = [0.30357368,\n",
    "                                       0.29148488, \n",
    "                                       0.00700351, \n",
    "                                       0.37788387, \n",
    "                                       0.19788962],\n",
    "                          module__mid_layer_channels=39,\n",
    "                          optimizer=optim.Adam, \n",
    "                          optimizer__lr=0.01,\n",
    "                          #optimizer__weight_decay=0.01,\n",
    "                          max_epochs=n_epochs, \n",
    "                          batch_size=100,\n",
    "                          iterator_train__shuffle=True,\n",
    "                          device=device,\n",
    "                          warm_start=True,#train_split=None,\n",
    "                          callbacks=[accuracy_epoch_scoring_val, \n",
    "                                     accuracy_epoch_scoring_train],\n",
    "                         )\n",
    "if noise_training:\n",
    "    noise_rounds = 5\n",
    "    for _ in range(noise_rounds):\n",
    "\n",
    "        x_noise = add_noise(x_train)\n",
    "        model.partial_fit(x_noise, y_train)\n",
    "else:\n",
    "    model.fit(x_train, y_train)\n",
    "pred_test = model.predict(x_train)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_train, prefix_information=model_name,\n",
    "                          dataset_name='train', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "\n",
    "pred_test = model.predict(x_val)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_val, prefix_information='LeNet',\n",
    "                          dataset_name='', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LeNet5. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "#model = pickle.load(open('models/yahoo_dataLenet-0.842_2019_05_16_01_44_12_FINAL.model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Net: 0.82\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.88      0.87       340\n",
      "          1       0.76      0.72      0.74       182\n",
      "\n",
      "avg / total       0.82      0.82      0.82       522\n",
      "\n",
      "Accuracy of Net: 0.84\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.88       113\n",
      "          1       0.79      0.77      0.78        64\n",
      "\n",
      "avg / total       0.84      0.84      0.84       177\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test = model.predict(x_train)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_train, prefix_information=model_name,\n",
    "                          dataset_name='train', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "plt.savefig(fname='latex/figures/' + 'Lenet_Training_results' + '.pdf', format='pdf', dpi=300)\n",
    "\n",
    "pred_test = model.predict(x_val)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_val, prefix_information='RF',\n",
    "                          dataset_name='', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "\n",
    "plt.savefig(fname='latex/figures/' + 'Lenet_Test_results' + '.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'module__mid_layer_channels': array([49, 60, 29, 46, 13, 26, 48, 39, 33, 63])}\n"
     ]
    }
   ],
   "source": [
    "M = 10\n",
    "optimizer__lr= np.random.uniform(1e-2, 1e-4, M)\n",
    "weight_decay = np.random.uniform(1e-2,0.3 , M)\n",
    "optimizer__weight_decay = np.random.uniform(1e-2,0.3 , M)\n",
    "max_epochs = np.random.randint(2, 100, M)\n",
    "mid_layer_channels = np.array(np.random.uniform(5, 64, M), dtype=int)\n",
    "#batch_size = [4, 10, 20, 30]\n",
    "optimizers = (optim.SGD, optim.Adam)\n",
    "#C_k_p_s_1 = ([5, 0, 1],[4, 0, 1], [3, 0, 1], [2, 0, 1], [1, 0, 1])\n",
    "C_k_p_s_1 = tuple([[np.random.randint(2, 5, size=1)[0],\n",
    "                    np.random.randint(0, 4, size=1)[0], \n",
    "                    np.random.randint(1, 2, size=1)[0]]  for _ in range(M)])\n",
    "C_k_p_s_2 = tuple([[np.random.randint(2, 5, size=1)[0],\n",
    "                    np.random.randint(0, 4, size=1)[0], \n",
    "                    np.random.randint(1, 2, size=1)[0]]  for _ in range(M)])\n",
    "p = [np.random.uniform(0.0, 0.5, size=5) for _ in range(M)]\n",
    "p.append([0.1,0.1, 0.1, 0.1, 0.1])\n",
    "p.append([0.0,0.0, 0.0, 0.0, 0.0])\n",
    "p = tuple(p)\n",
    "#C_k_p_s_1 = [5, 0, 1], M_k_s_1 = [2, 2], C_k_p_s_2 = [5, 0, 1], M_k_s_2 = [2, 2] \n",
    "# mid_layer_channels=16 p=[0.1,0.1, 0.1, 0.1, 0.1]\n",
    "parameters = {#'optimizer__lr': optimizer__lr, \n",
    "    #'optimizer': optimizers, \n",
    "    #'optimizer__weight_decay': optimizer__weight_decay,\n",
    "    #'module__C_k_p_s_1': C_k_p_s_1, \n",
    "    #'module__C_k_p_s_2': C_k_p_s_2,\n",
    "    'module__mid_layer_channels': mid_layer_channels, \n",
    "    #'module__p': p, \n",
    "    #'max_epochs': max_epochs\n",
    "}\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.5954\u001b[0m    \u001b[32m0.0000\u001b[0m        \u001b[35m0.7018\u001b[0m       \u001b[31m0.5455\u001b[0m        \u001b[94m0.6902\u001b[0m  0.0210\n",
      "      2      0.3797    \u001b[32m0.4952\u001b[0m        \u001b[35m0.6810\u001b[0m       \u001b[31m0.5620\u001b[0m        \u001b[94m0.6692\u001b[0m  0.0270\n",
      "      3      \u001b[36m0.5982\u001b[0m    \u001b[32m0.5234\u001b[0m        \u001b[35m0.6466\u001b[0m       \u001b[31m0.5785\u001b[0m        0.6842  0.0205\n",
      "      4      \u001b[36m0.6198\u001b[0m    0.5094        \u001b[35m0.6418\u001b[0m       0.5702        \u001b[94m0.6687\u001b[0m  0.0275\n",
      "      5      0.6158    0.4694        0.6439       0.5702        0.6772  0.0248\n",
      "      6      0.6040    0.5000        \u001b[35m0.6398\u001b[0m       0.5537        0.6734  0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7      0.6157    0.5000        \u001b[35m0.6192\u001b[0m       0.5702        0.6764  0.0277\n",
      "      8      0.5946    0.4694        0.6365       0.5702        0.6767  0.0279\n",
      "      9      0.5897    \u001b[32m0.5321\u001b[0m        0.6418       0.5785        \u001b[94m0.6659\u001b[0m  0.0269\n",
      "     10      0.6115    0.4646        0.6223       0.5620        0.6790  0.0272\n",
      "     11      0.5779    0.4583        0.6458       0.5702        0.6676  0.0267\n",
      "     12      0.5836    0.4270        0.6246       0.5785        0.6717  0.0279\n",
      "     13      0.5939    0.5000        0.6256       \u001b[31m0.5868\u001b[0m        0.6825  0.0265\n",
      "     14      0.5954    0.4348        0.6366       0.5702        0.6704  0.0268\n",
      "     15      0.5798    0.4600        0.6310       0.5537        0.6675  0.0268\n",
      "     16      \u001b[36m0.6313\u001b[0m    0.4444        0.6302       0.5455        0.6853  0.0331\n",
      "     17      0.6238    0.4956        0.6219       0.5289        0.6718  0.0213\n",
      "     18      0.6187    0.4000        \u001b[35m0.6149\u001b[0m       \u001b[31m0.6033\u001b[0m        0.6732  0.0258\n",
      "     19      0.5598    0.4717        0.6256       0.5372        \u001b[94m0.6640\u001b[0m  0.0257\n",
      "     20      0.6241    0.4536        0.6190       0.5620        0.6711  0.0216\n",
      "     21      0.5808    \u001b[32m0.5370\u001b[0m        0.6292       0.5868        \u001b[94m0.6538\u001b[0m  0.0191\n",
      "     22      0.5961    0.5000        0.6180       0.5868        0.6677  0.0285\n",
      "     23      0.6302    0.4762        0.6305       0.5455        0.6599  0.0184\n",
      "     24      0.5860    0.4600        \u001b[35m0.6139\u001b[0m       0.5537        0.6564  0.0236\n",
      "     25      \u001b[36m0.6534\u001b[0m    0.4752        0.6171       0.5620        0.6589  0.0197\n",
      "     26      0.6225    0.4632        0.6232       0.5785        \u001b[94m0.6468\u001b[0m  0.0260\n",
      "     27      0.6104    0.5049        \u001b[35m0.6084\u001b[0m       0.5785        \u001b[94m0.6453\u001b[0m  0.0252\n",
      "     28      0.6494    \u001b[32m0.5472\u001b[0m        0.6107       0.6033        0.6559  0.0203\n",
      "     29      \u001b[36m0.6573\u001b[0m    \u001b[32m0.5926\u001b[0m        0.6107       \u001b[31m0.6364\u001b[0m        \u001b[94m0.6266\u001b[0m  0.0188\n",
      "     30      \u001b[36m0.6635\u001b[0m    0.4773        \u001b[35m0.5767\u001b[0m       0.6198        0.6441  0.0231\n",
      "     31      \u001b[36m0.6693\u001b[0m    0.5913        0.6474       0.6116        0.6327  0.0255\n",
      "     32      0.6026    0.4835        0.5909       0.6116        0.6385  0.0219\n",
      "     33      \u001b[36m0.6752\u001b[0m    0.5586        0.5883       0.5950        0.6332  0.0289\n",
      "     34      0.6651    \u001b[32m0.6154\u001b[0m        0.5793       0.6281        \u001b[94m0.6065\u001b[0m  0.0291\n",
      "     35      \u001b[36m0.6849\u001b[0m    0.5000        \u001b[35m0.5727\u001b[0m       0.6364        0.6311  0.0193\n",
      "     36      0.6844    0.5275        0.5873       \u001b[31m0.6446\u001b[0m        0.6303  0.0284\n",
      "     37      0.6617    \u001b[32m0.6207\u001b[0m        \u001b[35m0.5592\u001b[0m       0.6364        \u001b[94m0.6050\u001b[0m  0.0190\n",
      "     38      \u001b[36m0.7265\u001b[0m    \u001b[32m0.6606\u001b[0m        \u001b[35m0.5334\u001b[0m       \u001b[31m0.6942\u001b[0m        0.6160  0.0316\n",
      "     39      0.7031    0.5591        0.5837       0.6612        0.6179  0.0199\n",
      "     40      0.6667    0.5833        0.5888       0.6694        0.6114  0.0224\n",
      "     41      0.6767    0.6286        0.5691       0.6777        \u001b[94m0.5986\u001b[0m  0.0275\n",
      "     42      0.7088    0.5773        0.5584       0.6612        0.6397  0.0219\n",
      "     43      0.7167    0.6486        0.5574       0.6777        \u001b[94m0.5926\u001b[0m  0.0214\n",
      "     44      \u001b[36m0.7338\u001b[0m    0.6237        0.5369       \u001b[31m0.7107\u001b[0m        \u001b[94m0.5915\u001b[0m  0.0238\n",
      "     45      0.6847    0.6471        0.5728       0.7025        \u001b[94m0.5810\u001b[0m  0.0257\n",
      "     46      0.7120    0.6545        \u001b[35m0.5235\u001b[0m       0.6860        0.6002  0.0258\n",
      "     47      0.7190    0.6549        0.5515       0.6777        0.5962  0.0301\n",
      "     48      0.7137    \u001b[32m0.6822\u001b[0m        0.5505       0.6612        0.5989  0.0279\n",
      "     49      0.7288    0.6042        0.5331       0.6860        0.5895  0.0206\n",
      "     50      \u001b[36m0.7467\u001b[0m    0.6600        0.5373       \u001b[31m0.7190\u001b[0m        0.6033  0.0235\n",
      "     51      0.6967    \u001b[32m0.6852\u001b[0m        0.5682       0.7190        \u001b[94m0.5632\u001b[0m  0.0292\n",
      "     52      0.7103    0.6087        0.5264       0.7025        0.5724  0.0200\n",
      "     53      0.7136    0.6735        0.5668       \u001b[31m0.7355\u001b[0m        \u001b[94m0.5511\u001b[0m  0.0204\n",
      "     54      0.7153    0.6471        \u001b[35m0.5129\u001b[0m       0.7025        0.5666  0.0237\n",
      "     55      \u001b[36m0.7539\u001b[0m    0.6170        0.5282       0.7025        0.6217  0.0246\n",
      "     56      0.6868    0.6535        0.5377       0.7107        0.5861  0.0235\n",
      "     57      0.6902    0.6604        0.5299       0.7025        0.5731  0.0248\n",
      "     58      0.7146    0.6408        0.5315       0.6942        0.6118  0.0216\n",
      "     59      0.7171    0.6667        \u001b[35m0.5025\u001b[0m       0.7025        0.5865  0.0209\n",
      "     60      0.7467    0.6531        \u001b[35m0.4930\u001b[0m       0.7190        0.6004  0.0254\n",
      "     61      0.7239    0.5714        0.5049       0.6777        0.6153  0.0221\n",
      "     62      0.7371    \u001b[32m0.6903\u001b[0m        0.5316       0.7107        0.5738  0.0236\n",
      "     63      0.7371    \u001b[32m0.6909\u001b[0m        0.5016       0.7190        0.5956  0.0187\n",
      "     64      0.7385    \u001b[32m0.6939\u001b[0m        0.5144       \u001b[31m0.7521\u001b[0m        0.6219  0.0244\n",
      "     65      0.7285    \u001b[32m0.7027\u001b[0m        0.5302       0.7273        0.5599  0.0243\n",
      "     66      0.7364    0.6250        0.5234       0.7025        0.6094  0.0251\n",
      "     67      0.6921    0.6087        0.5394       0.7025        0.5979  0.0212\n",
      "     68      0.7079    \u001b[32m0.7091\u001b[0m        0.5255       0.7355        0.5720  0.0214\n",
      "     69      \u001b[36m0.7543\u001b[0m    0.6796        0.5030       0.7273        0.6116  0.0199\n",
      "     70      0.7380    0.6796        0.5014       0.7273        0.5954  0.0231\n",
      "     71      0.7506    0.6667        0.5059       0.7190        0.5851  0.0233\n",
      "     72      0.7392    0.7059        0.5033       0.7521        0.5675  0.0195\n",
      "     73      0.7400    0.6602        \u001b[35m0.4814\u001b[0m       0.7107        0.5766  0.0195\n",
      "     74      0.7458    0.6327        0.4874       0.7025        0.5876  0.0238\n",
      "     75      0.7335    0.5287        0.5045       0.6612        0.6219  0.0226\n",
      "     76      0.7200    0.6792        0.5291       0.7190        0.5803  0.0194\n",
      "     77      0.7033    0.5979        0.5067       0.6777        0.5959  0.0209\n",
      "     78      0.7418    0.6304        0.5194       0.7190        0.5841  0.0252\n",
      "     79      0.7095    0.6667        0.5064       0.7107        0.5805  0.0236\n",
      "     80      0.7511    0.5957        0.5058       0.6860        0.6023  0.0235\n",
      "     81      0.7416    0.6667        \u001b[35m0.4690\u001b[0m       0.7190        0.6046  0.0193\n",
      "     82      \u001b[36m0.7594\u001b[0m    0.6923        0.5002       0.7355        0.6167  0.0224\n",
      "     83      0.7438    0.7048        0.5040       0.7438        0.5853  0.0325\n",
      "     84      0.7385    0.7027        0.5239       0.7273        0.5580  0.0209\n",
      "     85      0.7281    0.6471        0.5092       0.7025        0.5770  0.0210\n",
      "     86      0.7389    0.5934        0.4984       0.6942        0.5936  0.0257\n",
      "     87      0.7157    0.6733        0.4913       0.7273        0.5738  0.0202\n",
      "     88      0.7421    0.5778        0.4848       0.6860        0.6389  0.0224\n",
      "     89      0.6806    0.6964        0.5430       0.7190        0.5809  0.0250\n",
      "     90      0.7473    0.5169        0.5028       0.6446        0.6320  0.0273\n",
      "     91      0.6954    0.5652        0.5250       0.6694        0.5902  0.0186\n",
      "     92      0.7438    0.6598        0.4884       0.7273        0.6091  0.0254\n",
      "     93      0.7418    0.6800        0.4786       0.7355        0.5974  0.0200\n",
      "     94      0.7472    0.6022        0.4698       0.6942        0.6869  0.0242\n",
      "     95      0.7136    0.6400        0.4942       0.7025        0.5729  0.0247\n",
      "     96      0.7517    0.5957        0.4975       0.6860        0.5837  0.0219\n",
      "     97      0.7083    0.5843        0.4753       0.6942        0.6045  0.0259\n",
      "     98      0.7494    0.6465        0.4842       0.7107        0.6203  0.0242\n",
      "     99      0.7237    0.5684        \u001b[35m0.4686\u001b[0m       0.6612        0.6711  0.0263\n",
      "    100      0.7489    0.6316        0.4903       0.7107        0.6434  0.0261\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6257\u001b[0m    \u001b[32m0.3056\u001b[0m        \u001b[35m0.7130\u001b[0m       \u001b[31m0.5868\u001b[0m        \u001b[94m0.6737\u001b[0m  0.0251\n",
      "      2      0.5628    \u001b[32m0.6667\u001b[0m        \u001b[35m0.6962\u001b[0m       \u001b[31m0.6364\u001b[0m        \u001b[94m0.6650\u001b[0m  0.0324\n",
      "      3      0.6106    0.5417        \u001b[35m0.6596\u001b[0m       0.6364        \u001b[94m0.6479\u001b[0m  0.0211\n",
      "      4      0.5837    \u001b[32m0.6716\u001b[0m        0.6709       0.6364        0.6485  0.0225\n",
      "      5      \u001b[36m0.6517\u001b[0m    0.5437        \u001b[35m0.6478\u001b[0m       0.6116        \u001b[94m0.6469\u001b[0m  0.0251\n",
      "      6      0.6010    0.5766        \u001b[35m0.6468\u001b[0m       0.6116        \u001b[94m0.6412\u001b[0m  0.0237\n",
      "      7      0.6105    0.5818        0.6533       0.6198        0.6443  0.0221\n",
      "      8      0.5893    0.6612        0.6568       \u001b[31m0.6612\u001b[0m        \u001b[94m0.6407\u001b[0m  0.0323\n",
      "      9      0.6261    0.6555        0.6529       0.6612        \u001b[94m0.6378\u001b[0m  0.0213\n",
      "     10      0.5816    0.5437        0.6621       0.6116        0.6464  0.0249\n",
      "     11      0.6178    0.6333        0.6576       0.6364        0.6464  0.0254\n",
      "     12      0.5791    0.4944        0.6602       0.6281        0.6602  0.0270\n",
      "     13      0.5082    0.5524        0.6658       0.6116        0.6577  0.0252\n",
      "     14      0.6338    0.6504        0.6556       0.6446        0.6435  0.0185\n",
      "     15      0.6228    0.5385        \u001b[35m0.6422\u001b[0m       0.6033        0.6436  0.0187\n",
      "     16      0.5928    0.6560        0.6625       0.6446        0.6451  0.0181\n",
      "     17      0.6309    0.5370        0.6549       0.5868        0.6598  0.0219\n",
      "     18      0.5749    0.5714        0.6467       0.6033        0.6463  0.0234\n",
      "     19      0.6093    0.5766        0.6496       0.6116        0.6381  0.0241\n",
      "     20      0.6051    0.5660        0.6467       0.6198        0.6394  0.0224\n",
      "     21      0.5802    0.6441        0.6466       0.6529        \u001b[94m0.6353\u001b[0m  0.0184\n",
      "     22      0.6509    0.5946        \u001b[35m0.6416\u001b[0m       0.6281        \u001b[94m0.6294\u001b[0m  0.0197\n",
      "     23      0.6311    0.5361        \u001b[35m0.6314\u001b[0m       0.6281        0.6388  0.0243\n",
      "     24      0.5538    0.5577        0.6557       0.6198        0.6433  0.0222\n",
      "     25      0.6380    0.5437        0.6404       0.6116        0.6461  0.0261\n",
      "     26      0.5642    0.5161        0.6480       0.6281        0.6387  0.0263\n",
      "     27      0.5414    0.5849        0.6563       0.6364        0.6422  0.0189\n",
      "     28      0.6109    0.5567        0.6486       0.6446        0.6312  0.0217\n",
      "     29      0.5763    0.5743        0.6501       0.6446        \u001b[94m0.6291\u001b[0m  0.0240\n",
      "     30      0.6083    0.5741        \u001b[35m0.6310\u001b[0m       0.6198        0.6342  0.0193\n",
      "     31      0.6267    0.5773        \u001b[35m0.6228\u001b[0m       0.6612        \u001b[94m0.6243\u001b[0m  0.0311\n",
      "     32      0.6154    0.5607        0.6461       0.6116        0.6268  0.0248\n",
      "     33      0.5990    0.5893        0.6233       0.6198        \u001b[94m0.6234\u001b[0m  0.0246\n",
      "     34      0.6445    0.6491        0.6532       \u001b[31m0.6694\u001b[0m        \u001b[94m0.6053\u001b[0m  0.0253\n",
      "     35      0.6024    \u001b[32m0.6842\u001b[0m        0.6575       \u001b[31m0.7025\u001b[0m        0.6290  0.0229\n",
      "     36      0.6304    0.6667        0.6313       0.7025        0.6180  0.0198\n",
      "     37      0.6514    0.6508        0.6324       0.6364        0.6147  0.0258\n",
      "     38      \u001b[36m0.6879\u001b[0m    0.6239        0.6299       0.6612        \u001b[94m0.6053\u001b[0m  0.0247\n",
      "     39      0.6424    0.5556        \u001b[35m0.6098\u001b[0m       0.6694        0.6108  0.0218\n",
      "     40      0.6329    0.6408        0.6350       0.6942        \u001b[94m0.5922\u001b[0m  0.0272\n",
      "     41      0.4831    0.5227        0.6401       0.6529        0.6251  0.0271\n",
      "     42      0.6110    \u001b[32m0.6935\u001b[0m        0.6235       0.6860        0.6038  0.0218\n",
      "     43      0.6722    0.6891        \u001b[35m0.6087\u001b[0m       0.6942        \u001b[94m0.5840\u001b[0m  0.0227\n",
      "     44      0.6769    0.6789        0.6343       \u001b[31m0.7107\u001b[0m        0.6002  0.0229\n",
      "     45      0.6573    0.6392        \u001b[35m0.5988\u001b[0m       0.7107        0.5925  0.0250\n",
      "     46      0.6653    0.6549        0.6090       0.6777        \u001b[94m0.5815\u001b[0m  0.0251\n",
      "     47      0.6637    0.6825        0.6220       0.6694        0.5942  0.0188\n",
      "     48      0.6592    0.6800        0.6159       \u001b[31m0.7355\u001b[0m        0.5903  0.0253\n",
      "     49      0.6402    0.6471        0.6053       0.7025        \u001b[94m0.5813\u001b[0m  0.0244\n",
      "     50      0.6517    \u001b[32m0.6964\u001b[0m        0.6035       0.7190        \u001b[94m0.5760\u001b[0m  0.0189\n",
      "     51      0.6299    0.6923        \u001b[35m0.5902\u001b[0m       0.7355        \u001b[94m0.5680\u001b[0m  0.0225\n",
      "     52      0.6636    \u001b[32m0.7059\u001b[0m        \u001b[35m0.5886\u001b[0m       \u001b[31m0.7521\u001b[0m        \u001b[94m0.5573\u001b[0m  0.0226\n",
      "     53      0.6740    \u001b[32m0.7179\u001b[0m        0.5929       0.7273        \u001b[94m0.5471\u001b[0m  0.0195\n",
      "     54      0.6715    0.6916        0.5970       0.7273        0.5611  0.0251\n",
      "     55      \u001b[36m0.7140\u001b[0m    0.7009        \u001b[35m0.5721\u001b[0m       0.7107        0.5509  0.0275\n",
      "     56      0.6963    0.6667        0.5800       0.6612        0.5784  0.0220\n",
      "     57      0.6860    0.7071        \u001b[35m0.5527\u001b[0m       \u001b[31m0.7603\u001b[0m        \u001b[94m0.5266\u001b[0m  0.0269\n",
      "     58      0.6613    0.6923        0.6365       0.7355        0.5595  0.0224\n",
      "     59      0.5876    0.4878        0.5971       0.6529        0.6106  0.0223\n",
      "     60      0.5714    0.6842        0.6055       0.7025        0.5710  0.0240\n",
      "     61      0.6772    0.6964        0.5835       0.7190        0.5593  0.0241\n",
      "     62      0.6606    0.7080        \u001b[35m0.5500\u001b[0m       0.7273        0.5492  0.0210\n",
      "     63      0.7113    0.6903        0.5797       0.7107        0.5509  0.0259\n",
      "     64      0.6420    0.6800        0.5776       0.7355        0.5525  0.0321\n",
      "     65      0.6883    0.7097        0.5795       0.7025        0.5586  0.0325\n",
      "     66      0.6727    0.7103        0.5712       0.7438        0.5507  0.0324\n",
      "     67      0.6942    0.7119        0.5967       0.7190        0.5681  0.0333\n",
      "     68      \u001b[36m0.7159\u001b[0m    0.7048        0.5501       0.7438        0.5321  0.0334\n",
      "     69      0.7071    0.7103        0.5954       0.7438        0.5551  0.0339\n",
      "     70      0.6993    0.7037        0.5649       0.7355        0.5496  0.0330\n",
      "     71      0.6815    0.7097        0.6030       0.7025        0.5444  0.0316\n",
      "     72      0.7159    0.6964        0.5596       0.7190        0.5571  0.0316\n",
      "     73      0.7035    0.7087        0.5964       0.6942        0.5658  0.0275\n",
      "     74      0.7084    0.7018        0.5512       0.7190        0.5324  0.0302\n",
      "     75      0.7035    \u001b[32m0.7627\u001b[0m        \u001b[35m0.5404\u001b[0m       \u001b[31m0.7686\u001b[0m        \u001b[94m0.5212\u001b[0m  0.0241\n",
      "     76      0.7077    0.7603        0.5408       0.7603        \u001b[94m0.5167\u001b[0m  0.0238\n",
      "     77      \u001b[36m0.7193\u001b[0m    0.7455        \u001b[35m0.5330\u001b[0m       0.7686        0.5170  0.0239\n",
      "     78      0.7113    0.7273        \u001b[35m0.5293\u001b[0m       0.7273        0.5307  0.0323\n",
      "     79      \u001b[36m0.7437\u001b[0m    0.7048        0.5362       0.7438        0.5348  0.0285\n",
      "     80      0.6923    0.7377        0.5397       0.7355        0.5317  0.0202\n",
      "     81      0.7099    0.7627        0.5493       0.7686        0.5184  0.0240\n",
      "     82      0.7357    0.7414        0.5410       0.7521        0.5259  0.0246\n",
      "     83      0.7168    0.7257        0.5378       0.7438        0.5232  0.0289\n",
      "     84      0.7269    0.7368        0.5353       0.7521        0.5190  0.0244\n",
      "     85      \u001b[36m0.7573\u001b[0m    0.7227        \u001b[35m0.5092\u001b[0m       0.7273        0.5352  0.0231\n",
      "     86      0.7412    0.7368        0.5355       0.7521        0.5285  0.0240\n",
      "     87      0.7146    0.7241        0.5395       0.7355        0.5363  0.0242\n",
      "     88      0.7377    0.7541        0.5334       0.7521        0.5258  0.0195\n",
      "     89      0.7301    0.7333        0.5388       0.7355        0.5244  0.0232\n",
      "     90      0.7269    0.7143        0.5310       0.7355        0.5307  0.0246\n",
      "     91      0.7392    0.7206        0.5418       0.6860        0.5665  0.0210\n",
      "     92      0.7320    0.6476        0.5364       0.6942        0.5589  0.0258\n",
      "     93      0.7188    0.7353        0.5742       0.7025        0.5600  0.0256\n",
      "     94      0.7479    0.7027        0.5290       0.7273        0.5275  0.0254\n",
      "     95      0.7289    0.7521        0.5199       0.7603        0.5243  0.0251\n",
      "     96      0.7533    0.7018        \u001b[35m0.4965\u001b[0m       0.7190        0.5340  0.0204\n",
      "     97      0.7383    0.7244        0.5430       0.7107        0.5446  0.0267\n",
      "     98      0.7297    0.7257        0.5257       0.7438        0.5305  0.0235\n",
      "     99      0.7450    0.7132        0.5152       0.6942        0.5504  0.0272\n",
      "    100      0.7467    0.7027        0.5165       0.7273        0.5292  0.0212\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6228\u001b[0m    \u001b[32m0.6000\u001b[0m        \u001b[35m0.6970\u001b[0m       \u001b[31m0.6364\u001b[0m        \u001b[94m0.6689\u001b[0m  0.0224\n",
      "      2      0.5234    0.4471        \u001b[35m0.6683\u001b[0m       0.6116        \u001b[94m0.6667\u001b[0m  0.0189\n",
      "      3      0.2807    0.2535        0.6884       0.5620        0.6704  0.0181\n",
      "      4      0.4840    0.5660        0.6712       0.6198        \u001b[94m0.6635\u001b[0m  0.0236\n",
      "      5      0.4294    0.2778        0.6756       0.5702        0.6678  0.0242\n",
      "      6      0.3541    0.3951        \u001b[35m0.6674\u001b[0m       0.5950        \u001b[94m0.6594\u001b[0m  0.0253\n",
      "      7      0.4330    0.5474        0.6677       \u001b[31m0.6446\u001b[0m        \u001b[94m0.6560\u001b[0m  0.0269\n",
      "      8      0.4606    0.3855        \u001b[35m0.6572\u001b[0m       0.5785        \u001b[94m0.6541\u001b[0m  0.0219\n",
      "      9      0.4393    0.5319        0.6691       0.6364        \u001b[94m0.6518\u001b[0m  0.0253\n",
      "     10      0.5013    0.5686        \u001b[35m0.6534\u001b[0m       0.6364        0.6530  0.0193\n",
      "     11      0.4615    0.3704        0.6604       0.5785        0.6543  0.0279\n",
      "     12      0.4012    0.3704        0.6625       0.5785        0.6541  0.0188\n",
      "     13      0.4573    0.5306        0.6681       0.6198        \u001b[94m0.6514\u001b[0m  0.0248\n",
      "     14      0.4226    0.3467        0.6667       0.5950        0.6563  0.0228\n",
      "     15      0.4246    0.5217        0.6565       0.6364        \u001b[94m0.6495\u001b[0m  0.0232\n",
      "     16      0.4868    0.5545        0.6561       0.6281        0.6518  0.0191\n",
      "     17      0.5238    0.5545        \u001b[35m0.6472\u001b[0m       0.6281        0.6500  0.0272\n",
      "     18      0.5309    \u001b[32m0.6050\u001b[0m        \u001b[35m0.6459\u001b[0m       0.6116        \u001b[94m0.6478\u001b[0m  0.0266\n",
      "     19      0.5542    0.5510        0.6589       0.6364        0.6495  0.0213\n",
      "     20      0.5459    0.5577        0.6506       0.6198        \u001b[94m0.6430\u001b[0m  0.0219\n",
      "     21      0.5134    0.5591        \u001b[35m0.6383\u001b[0m       \u001b[31m0.6612\u001b[0m        0.6450  0.0193\n",
      "     22      0.5231    \u001b[32m0.6226\u001b[0m        0.6404       \u001b[31m0.6694\u001b[0m        \u001b[94m0.6419\u001b[0m  0.0235\n",
      "     23      0.5749    \u001b[32m0.6250\u001b[0m        \u001b[35m0.6379\u001b[0m       0.6529        \u001b[94m0.6335\u001b[0m  0.0277\n",
      "     24      0.6089    \u001b[32m0.6512\u001b[0m        \u001b[35m0.6352\u001b[0m       0.6281        0.6338  0.0248\n",
      "     25      0.6093    0.4651        0.6385       0.6198        0.6462  0.0304\n",
      "     26      0.5488    \u001b[32m0.6897\u001b[0m        0.6581       0.6281        0.6375  0.0241\n",
      "     27      \u001b[36m0.6512\u001b[0m    0.6139        \u001b[35m0.6181\u001b[0m       \u001b[31m0.6777\u001b[0m        \u001b[94m0.6182\u001b[0m  0.0191\n",
      "     28      0.6253    0.6829        0.6314       0.6777        \u001b[94m0.6022\u001b[0m  0.0200\n",
      "     29      0.5659    0.6875        0.6268       0.5868        0.6467  0.0224\n",
      "     30      \u001b[36m0.7074\u001b[0m    0.5714        0.6220       0.6777        0.6285  0.0236\n",
      "     31      0.4888    0.6667        0.6374       \u001b[31m0.6860\u001b[0m        0.6132  0.0242\n",
      "     32      0.6407    0.6549        0.6308       0.6777        0.6237  0.0225\n",
      "     33      0.5676    0.5773        0.6319       0.6612        0.6198  0.0236\n",
      "     34      0.6404    0.6667        0.6212       0.6694        0.6083  0.0213\n",
      "     35      0.5810    \u001b[32m0.7328\u001b[0m        0.6426       \u001b[31m0.7107\u001b[0m        0.6115  0.0192\n",
      "     36      0.6462    0.6783        \u001b[35m0.6117\u001b[0m       0.6942        \u001b[94m0.5976\u001b[0m  0.0235\n",
      "     37      0.6258    \u001b[32m0.7402\u001b[0m        \u001b[35m0.6068\u001b[0m       \u001b[31m0.7273\u001b[0m        \u001b[94m0.5866\u001b[0m  0.0195\n",
      "     38      0.6259    0.7077        \u001b[35m0.6024\u001b[0m       0.6860        \u001b[94m0.5805\u001b[0m  0.0229\n",
      "     39      \u001b[36m0.7277\u001b[0m    0.7387        \u001b[35m0.5743\u001b[0m       \u001b[31m0.7603\u001b[0m        \u001b[94m0.5684\u001b[0m  0.0230\n",
      "     40      0.6623    0.7200        0.5757       0.7107        0.5738  0.0195\n",
      "     41      0.6587    0.7299        0.5759       0.6942        0.5694  0.0234\n",
      "     42      0.7073    0.7258        0.5817       0.7190        \u001b[94m0.5675\u001b[0m  0.0267\n",
      "     43      0.6456    0.6903        0.5844       0.7107        \u001b[94m0.5554\u001b[0m  0.0216\n",
      "     44      0.6868    0.7227        0.5784       0.7273        0.5576  0.0239\n",
      "     45      0.7075    0.7130        \u001b[35m0.5511\u001b[0m       0.7273        0.5613  0.0230\n",
      "     46      0.6620    0.6957        0.5761       0.7107        0.5878  0.0189\n",
      "     47      0.7206    0.7154        0.5693       0.7107        0.5669  0.0249\n",
      "     48      0.6115    0.6275        0.6158       0.6860        0.6027  0.0278\n",
      "     49      0.6382    0.7042        0.6061       0.6529        0.6013  0.0223\n",
      "     50      \u001b[36m0.7328\u001b[0m    0.7119        0.5553       0.7190        0.5650  0.0262\n",
      "     51      0.6935    0.7273        \u001b[35m0.5421\u001b[0m       0.7025        0.5886  0.0201\n",
      "     52      0.6852    \u001b[32m0.7460\u001b[0m        0.5792       0.7355        0.5703  0.0257\n",
      "     53      0.7025    0.6957        0.5603       0.7107        0.5702  0.0217\n",
      "     54      0.6761    0.7069        0.5806       0.7190        0.5678  0.0195\n",
      "     55      0.7200    0.6903        0.5548       0.7107        0.5645  0.0237\n",
      "     56      0.7325    0.6727        0.5446       0.7025        0.5690  0.0227\n",
      "     57      \u001b[36m0.7364\u001b[0m    0.6891        0.5430       0.6942        0.5825  0.0254\n",
      "     58      0.6906    0.7143        \u001b[35m0.5380\u001b[0m       0.7025        0.5858  0.0239\n",
      "     59      \u001b[36m0.7495\u001b[0m    0.6727        0.5423       0.7025        \u001b[94m0.5523\u001b[0m  0.0250\n",
      "     60      0.7143    0.7077        0.5553       0.6860        0.5675  0.0261\n",
      "     61      0.7355    0.6949        \u001b[35m0.5179\u001b[0m       0.7025        0.5674  0.0256\n",
      "     62      \u001b[36m0.7533\u001b[0m    0.6604        0.5224       0.7025        0.5688  0.0268\n",
      "     63      0.6817    0.7027        0.5714       0.7273        0.5813  0.0220\n",
      "     64      0.6359    0.7130        0.5860       0.7273        0.5580  0.0328\n",
      "     65      0.7092    0.7164        0.5687       0.6860        0.5798  0.0222\n",
      "     66      0.7432    0.6786        0.5305       0.7025        0.5586  0.0276\n",
      "     67      0.7098    0.7080        0.5398       0.7273        \u001b[94m0.5506\u001b[0m  0.0190\n",
      "     68      0.6885    0.7031        0.5534       0.6860        0.5778  0.0235\n",
      "     69      0.7429    0.6727        0.5516       0.7025        0.5580  0.0235\n",
      "     70      0.7235    0.7143        0.5263       0.7025        0.5892  0.0197\n",
      "     71      0.7143    0.6972        0.5600       0.7273        0.5549  0.0189\n",
      "     72      0.7424    0.7154        0.5427       0.7107        0.5620  0.0248\n",
      "     73      0.7235    0.6957        \u001b[35m0.5143\u001b[0m       0.7107        0.5581  0.0254\n",
      "     74      0.7204    0.7049        0.5294       0.7025        0.5887  0.0265\n",
      "     75      0.7373    0.6364        0.5275       0.6694        0.5688  0.0217\n",
      "     76      0.7228    0.6829        0.5471       0.6777        0.5663  0.0218\n",
      "     77      0.7420    0.6833        0.5149       0.6860        0.5617  0.0211\n",
      "     78      0.7505    0.6667        0.5153       0.6777        0.5722  0.0326\n",
      "     79      0.7260    0.6549        \u001b[35m0.5121\u001b[0m       0.6777        0.5729  0.0281\n",
      "     80      \u001b[36m0.7534\u001b[0m    0.7119        \u001b[35m0.4933\u001b[0m       0.7190        0.6021  0.0309\n",
      "     81      \u001b[36m0.7551\u001b[0m    0.7000        0.5150       0.7025        0.5794  0.0308\n",
      "     82      0.7439    0.7059        0.4973       0.7107        0.5967  0.0287\n",
      "     83      0.7354    0.7213        0.5219       0.7190        0.5737  0.0343\n",
      "     84      0.7407    0.7213        0.5076       0.7190        0.5575  0.0337\n",
      "     85      0.7252    0.7227        0.5085       0.7273        0.5694  0.0312\n",
      "     86      0.7387    0.6724        0.5006       0.6860        0.5947  0.0374\n",
      "     87      0.7123    0.6481        0.5194       0.6860        0.5600  0.0352\n",
      "     88      0.7467    0.7087        0.5252       0.6942        0.5888  0.0328\n",
      "     89      0.7443    0.6897        0.5120       0.7025        0.5527  0.0339\n",
      "     90      0.7495    0.7049        0.5023       0.7025        0.5747  0.0281\n",
      "     91      0.7511    0.6667        0.5090       0.6777        0.5612  0.0314\n",
      "     92      0.7452    0.6491        0.5187       0.6694        0.5742  0.0251\n",
      "     93      0.7234    0.6724        0.5215       0.6860        0.5947  0.0294\n",
      "     94      \u001b[36m0.7557\u001b[0m    0.6838        0.5168       0.6942        0.5687  0.0216\n",
      "     95      \u001b[36m0.7615\u001b[0m    0.6838        \u001b[35m0.4862\u001b[0m       0.6942        0.5775  0.0231\n",
      "     96      0.7494    0.6783        0.5218       0.6942        0.5780  0.0235\n",
      "     97      0.7495    0.6549        0.5167       0.6777        0.5756  0.0195\n",
      "     98      0.7459    0.6942        0.4936       0.6942        0.6030  0.0264\n",
      "     99      0.7603    0.6667        0.5100       0.6694        0.5759  0.0260\n",
      "    100      0.7361    0.6723        0.5003       0.6777        0.5607  0.0269\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.4375\u001b[0m    \u001b[32m0.0357\u001b[0m        \u001b[35m0.6924\u001b[0m       \u001b[31m0.5537\u001b[0m        \u001b[94m0.6836\u001b[0m  0.0214\n",
      "      2      0.1116    \u001b[32m0.0702\u001b[0m        \u001b[35m0.6833\u001b[0m       \u001b[31m0.5620\u001b[0m        \u001b[94m0.6818\u001b[0m  0.0219\n",
      "      3      0.3880    \u001b[32m0.4304\u001b[0m        \u001b[35m0.6822\u001b[0m       \u001b[31m0.6281\u001b[0m        \u001b[94m0.6644\u001b[0m  0.0253\n",
      "      4      0.3854    0.3784        \u001b[35m0.6594\u001b[0m       0.6198        0.6676  0.0247\n",
      "      5      \u001b[36m0.4759\u001b[0m    \u001b[32m0.4524\u001b[0m        0.6707       0.6198        \u001b[94m0.6632\u001b[0m  0.0286\n",
      "      6      0.4295    0.3784        \u001b[35m0.6481\u001b[0m       0.6198        0.6668  0.0353\n",
      "      7      0.4644    0.4235        0.6605       0.5950        0.6632  0.0214\n",
      "      8      \u001b[36m0.4912\u001b[0m    0.4270        \u001b[35m0.6339\u001b[0m       0.5785        0.6639  0.0303\n",
      "      9      \u001b[36m0.5549\u001b[0m    0.4390        \u001b[35m0.6333\u001b[0m       0.6198        0.6816  0.0186\n",
      "     10      0.4783    0.4235        0.6440       0.5950        0.6697  0.0273\n",
      "     11      \u001b[36m0.5579\u001b[0m    0.4186        0.6489       0.5868        \u001b[94m0.6582\u001b[0m  0.0187\n",
      "     12      0.4494    0.3380        0.6441       0.6116        0.6678  0.0266\n",
      "     13      0.3813    0.4286        0.6452       0.6033        0.6597  0.0216\n",
      "     14      0.5289    0.4235        0.6372       0.5950        0.6655  0.0306\n",
      "     15      0.5254    0.4337        \u001b[35m0.6309\u001b[0m       0.6116        0.6616  0.0211\n",
      "     16      0.5233    0.4146        0.6328       0.6033        0.6616  0.0250\n",
      "     17      0.5333    0.4146        0.6425       0.6033        0.6612  0.0221\n",
      "     18      0.4458    0.3896        0.6409       0.6116        0.6705  0.0365\n",
      "     19      0.4899    0.4444        0.6420       0.5868        0.6610  0.0242\n",
      "     20      0.5292    0.4270        0.6365       0.5785        \u001b[94m0.6580\u001b[0m  0.0235\n",
      "     21      \u001b[36m0.5623\u001b[0m    0.4318        \u001b[35m0.6257\u001b[0m       0.5868        \u001b[94m0.6526\u001b[0m  0.0246\n",
      "     22      0.5445    0.4337        0.6348       0.6116        0.6580  0.0234\n",
      "     23      0.5408    0.4390        \u001b[35m0.6240\u001b[0m       0.6198        0.6543  0.0188\n",
      "     24      0.5000    \u001b[32m0.4615\u001b[0m        0.6313       0.5950        0.6527  0.0232\n",
      "     25      \u001b[36m0.5642\u001b[0m    \u001b[32m0.4651\u001b[0m        0.6242       0.6198        0.6614  0.0266\n",
      "     26      \u001b[36m0.5762\u001b[0m    0.4651        \u001b[35m0.6057\u001b[0m       0.6198        0.6590  0.0277\n",
      "     27      \u001b[36m0.5918\u001b[0m    \u001b[32m0.4842\u001b[0m        0.6393       0.5950        \u001b[94m0.6470\u001b[0m  0.0340\n",
      "     28      0.5604    0.4750        0.6330       \u001b[31m0.6529\u001b[0m        0.6553  0.0206\n",
      "     29      0.5615    \u001b[32m0.5143\u001b[0m        0.6420       0.5785        \u001b[94m0.6395\u001b[0m  0.0235\n",
      "     30      \u001b[36m0.5934\u001b[0m    0.4598        \u001b[35m0.6044\u001b[0m       0.6116        0.6457  0.0249\n",
      "     31      \u001b[36m0.6096\u001b[0m    \u001b[32m0.5192\u001b[0m        0.6147       0.5868        \u001b[94m0.6386\u001b[0m  0.0202\n",
      "     32      \u001b[36m0.6300\u001b[0m    \u001b[32m0.5421\u001b[0m        0.6064       0.5950        \u001b[94m0.6283\u001b[0m  0.0198\n",
      "     33      \u001b[36m0.6392\u001b[0m    0.4946        \u001b[35m0.5943\u001b[0m       0.6116        0.6309  0.0230\n",
      "     34      0.6195    0.4598        0.6036       0.6116        0.6333  0.0242\n",
      "     35      \u001b[36m0.6410\u001b[0m    0.4783        0.6351       0.6033        \u001b[94m0.6175\u001b[0m  0.0265\n",
      "     36      0.5922    \u001b[32m0.5600\u001b[0m        0.6092       0.6364        0.6283  0.0224\n",
      "     37      \u001b[36m0.6504\u001b[0m    0.5111        \u001b[35m0.5921\u001b[0m       0.6364        0.6361  0.0221\n",
      "     38      0.6359    \u001b[32m0.6139\u001b[0m        \u001b[35m0.5878\u001b[0m       \u001b[31m0.6777\u001b[0m        \u001b[94m0.6173\u001b[0m  0.0204\n",
      "     39      0.6420    \u001b[32m0.6604\u001b[0m        0.6083       \u001b[31m0.7025\u001b[0m        \u001b[94m0.6063\u001b[0m  0.0264\n",
      "     40      \u001b[36m0.6919\u001b[0m    0.6186        0.5914       0.6942        \u001b[94m0.6024\u001b[0m  0.0270\n",
      "     41      0.6744    0.5833        0.5909       0.6694        0.6099  0.0222\n",
      "     42      0.6731    0.6471        \u001b[35m0.5809\u001b[0m       0.7025        0.6036  0.0206\n",
      "     43      \u001b[36m0.7089\u001b[0m    0.5618        0.5970       0.6777        0.6221  0.0279\n",
      "     44      0.6652    0.6545        0.6041       0.6860        0.6203  0.0266\n",
      "     45      0.6798    \u001b[32m0.6789\u001b[0m        \u001b[35m0.5803\u001b[0m       \u001b[31m0.7107\u001b[0m        \u001b[94m0.5919\u001b[0m  0.0218\n",
      "     46      \u001b[36m0.7293\u001b[0m    0.5122        \u001b[35m0.5544\u001b[0m       0.6694        0.6586  0.0264\n",
      "     47      0.6878    \u001b[32m0.6964\u001b[0m        0.5708       \u001b[31m0.7190\u001b[0m        \u001b[94m0.5804\u001b[0m  0.0249\n",
      "     48      0.7103    0.5412        0.5626       0.6777        0.6330  0.0267\n",
      "     49      0.6927    0.5435        0.5579       0.6529        0.6176  0.0225\n",
      "     50      0.7208    0.6735        \u001b[35m0.5507\u001b[0m       \u001b[31m0.7355\u001b[0m        0.5903  0.0200\n",
      "     51      0.6889    0.6139        0.5548       0.6777        0.5991  0.0253\n",
      "     52      0.6741    0.6111        0.6013       0.6529        0.6014  0.0244\n",
      "     53      0.6773    0.6408        0.5655       0.6942        0.6072  0.0197\n",
      "     54      0.6998    0.6325        \u001b[35m0.5496\u001b[0m       0.6446        0.5881  0.0254\n",
      "     55      0.6817    0.6087        0.5596       0.7025        0.6328  0.0235\n",
      "     56      0.6754    0.6777        0.5783       0.6777        0.5894  0.0197\n",
      "     57      0.6912    0.5435        \u001b[35m0.5297\u001b[0m       0.6529        0.6293  0.0279\n",
      "     58      0.6975    0.5979        0.5654       0.6777        0.5880  0.0241\n",
      "     59      0.6530    0.5618        0.5688       0.6777        0.6041  0.0224\n",
      "     60      0.7042    0.6263        0.5576       0.6942        0.6028  0.0237\n",
      "     61      0.7014    0.6792        0.5393       0.7190        \u001b[94m0.5788\u001b[0m  0.0239\n",
      "     62      0.7226    0.6916        \u001b[35m0.5066\u001b[0m       0.7273        0.5887  0.0234\n",
      "     63      \u001b[36m0.7313\u001b[0m    0.5556        0.5342       0.6694        0.5936  0.0232\n",
      "     64      \u001b[36m0.7324\u001b[0m    0.6042        0.5515       0.6860        \u001b[94m0.5787\u001b[0m  0.0200\n",
      "     65      0.6969    0.5412        0.5378       0.6777        0.6149  0.0264\n",
      "     66      0.6846    0.6847        0.5416       0.7107        0.5851  0.0297\n",
      "     67      0.7294    0.6600        0.5444       0.7190        0.5831  0.0195\n",
      "     68      0.7200    0.6916        0.5244       0.7273        0.5829  0.0209\n",
      "     69      0.7235    0.4878        0.5496       0.6529        0.6202  0.0252\n",
      "     70      0.6436    0.6852        0.5586       0.7190        \u001b[94m0.5504\u001b[0m  0.0246\n",
      "     71      0.7038    0.5581        0.5535       0.6860        0.5931  0.0232\n",
      "     72      0.6613    0.6400        0.5185       0.7025        0.5600  0.0188\n",
      "     73      \u001b[36m0.7335\u001b[0m    0.6731        \u001b[35m0.5059\u001b[0m       0.7190        0.5896  0.0254\n",
      "     74      \u001b[36m0.7426\u001b[0m    0.6400        0.5235       0.7025        0.5817  0.0241\n",
      "     75      0.7260    0.6667        0.5186       0.7190        0.5701  0.0222\n",
      "     76      0.7323    0.6796        0.5192       0.7273        0.5515  0.0217\n",
      "     77      0.7376    0.5682        0.5305       0.6860        0.5900  0.0243\n",
      "     78      0.6988    \u001b[32m0.7321\u001b[0m        0.5406       \u001b[31m0.7521\u001b[0m        0.5538  0.0212\n",
      "     79      0.7229    0.6600        0.5263       0.7190        0.5889  0.0260\n",
      "     80      0.7045    0.6897        0.5427       0.7025        0.5712  0.0232\n",
      "     81      0.7289    0.6170        0.5168       0.7025        0.6135  0.0251\n",
      "     82      0.7132    0.6923        0.5271       0.7355        0.5620  0.0187\n",
      "     83      0.7332    0.6796        \u001b[35m0.4867\u001b[0m       0.7273        0.5688  0.0233\n",
      "     84      0.7237    0.6863        0.5005       0.7355        0.5875  0.0225\n",
      "     85      0.7231    0.6667        0.5166       0.7190        0.5699  0.0183\n",
      "     86      0.7277    0.6863        0.4972       0.7355        0.5741  0.0182\n",
      "     87      0.7348    0.7193        0.5160       0.7355        0.5539  0.0226\n",
      "     88      0.7188    0.6250        0.5089       0.7025        0.5821  0.0234\n",
      "     89      0.7301    0.6186        0.5237       0.6942        0.5655  0.0184\n",
      "     90      0.6821    0.6731        0.5131       0.7190        0.5587  0.0223\n",
      "     91      \u001b[36m0.7699\u001b[0m    0.6600        0.4945       0.7190        0.5881  0.0226\n",
      "     92      0.7350    0.6923        0.4991       0.7355        0.5539  0.0182\n",
      "     93      0.7483    0.6237        0.4929       0.7107        0.5790  0.0226\n",
      "     94      0.7114    0.7273        0.4997       0.7521        \u001b[94m0.5402\u001b[0m  0.0184\n",
      "     95      \u001b[36m0.7755\u001b[0m    0.6735        \u001b[35m0.4580\u001b[0m       0.7355        0.5850  0.0180\n",
      "     96      0.7259    0.6923        0.5238       0.7355        0.5585  0.0223\n",
      "     97      0.7464    0.7048        0.4897       0.7438        0.5603  0.0224\n",
      "     98      0.7005    0.5833        0.4909       0.6694        0.5798  0.0189\n",
      "     99      0.7311    0.6600        0.5087       0.7190        0.5908  0.0184\n",
      "    100      0.7238    0.6857        0.4995       0.7273        0.5893  0.0236\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6349\u001b[0m    \u001b[32m0.6480\u001b[0m        \u001b[35m0.7157\u001b[0m       \u001b[31m0.4793\u001b[0m        \u001b[94m0.6997\u001b[0m  0.0231\n",
      "      2      \u001b[36m0.6510\u001b[0m    0.5524        \u001b[35m0.6914\u001b[0m       \u001b[31m0.6116\u001b[0m        \u001b[94m0.6720\u001b[0m  0.0212\n",
      "      3      0.5071    0.5474        \u001b[35m0.6805\u001b[0m       \u001b[31m0.6446\u001b[0m        \u001b[94m0.6586\u001b[0m  0.0263\n",
      "      4      0.5908    \u001b[32m0.6667\u001b[0m        \u001b[35m0.6659\u001b[0m       \u001b[31m0.6529\u001b[0m        \u001b[94m0.6432\u001b[0m  0.0272\n",
      "      5      0.6134    0.6446        \u001b[35m0.6622\u001b[0m       0.6446        \u001b[94m0.6422\u001b[0m  0.0235\n",
      "      6      0.5947    0.6446        0.6650       0.6446        0.6526  0.0274\n",
      "      7      0.6253    0.5437        \u001b[35m0.6615\u001b[0m       0.6116        0.6484  0.0253\n",
      "      8      0.5714    0.5490        \u001b[35m0.6578\u001b[0m       0.6198        0.6576  0.0218\n",
      "      9      0.5909    0.6615        0.6626       0.6364        0.6551  0.0334\n",
      "     10      0.6047    0.5253        0.6588       0.6116        0.6470  0.0219\n",
      "     11      0.5566    0.5370        0.6685       0.5868        0.6507  0.0269\n",
      "     12      0.6115    0.5983        0.6584       0.6116        0.6541  0.0246\n",
      "     13      0.6019    0.5347        \u001b[35m0.6459\u001b[0m       0.6116        0.6500  0.0217\n",
      "     14      0.5986    0.6333        0.6611       0.6364        0.6459  0.0261\n",
      "     15      0.6073    0.5294        0.6498       0.6033        0.6476  0.0222\n",
      "     16      0.5783    0.5370        0.6524       0.5868        0.6521  0.0253\n",
      "     17      0.5862    0.5000        0.6487       0.5868        0.6457  0.0278\n",
      "     18      0.5871    0.5243        \u001b[35m0.6414\u001b[0m       0.5950        0.6473  0.0219\n",
      "     19      0.6048    0.5505        0.6572       0.5950        0.6473  0.0269\n",
      "     20      0.5671    0.4946        \u001b[35m0.6295\u001b[0m       0.6116        0.6459  0.0254\n",
      "     21      0.5825    0.5310        0.6747       0.5620        0.6604  0.0288\n",
      "     22      0.6014    0.5505        0.6534       0.5950        0.6562  0.0252\n",
      "     23      0.5882    0.5149        0.6531       0.5950        0.6436  0.0207\n",
      "     24      0.5663    0.5437        0.6446       0.6116        \u001b[94m0.6418\u001b[0m  0.0214\n",
      "     25      0.6078    0.5818        0.6405       0.6198        \u001b[94m0.6398\u001b[0m  0.0258\n",
      "     26      0.6154    0.5686        0.6490       0.6364        \u001b[94m0.6327\u001b[0m  0.0219\n",
      "     27      0.5770    0.6316        0.6483       0.6529        \u001b[94m0.6318\u001b[0m  0.0249\n",
      "     28      0.6391    0.6667        0.6506       0.6446        0.6433  0.0227\n",
      "     29      0.6348    0.5631        0.6380       0.6281        0.6340  0.0241\n",
      "     30      0.6238    0.5766        0.6518       0.6116        0.6456  0.0195\n",
      "     31      0.5659    0.5741        0.6388       0.6198        0.6396  0.0201\n",
      "     32      0.6215    0.6071        0.6351       0.6364        \u001b[94m0.6268\u001b[0m  0.0289\n",
      "     33      0.5990    0.5743        0.6401       0.6446        0.6269  0.0232\n",
      "     34      0.6143    0.6018        0.6329       0.6281        \u001b[94m0.6227\u001b[0m  0.0235\n",
      "     35      0.5315    0.5567        0.6483       0.6446        0.6371  0.0193\n",
      "     36      0.5506    \u001b[32m0.6880\u001b[0m        0.6401       \u001b[31m0.6777\u001b[0m        0.6311  0.0230\n",
      "     37      0.6256    0.6078        0.6331       0.6694        \u001b[94m0.6104\u001b[0m  0.0244\n",
      "     38      0.6161    0.6387        0.6497       0.6446        0.6316  0.0185\n",
      "     39      0.6499    0.6061        \u001b[35m0.6155\u001b[0m       0.6777        0.6263  0.0242\n",
      "     40      0.6318    0.6612        0.6294       0.6612        0.6228  0.0261\n",
      "     41      0.6158    0.5745        0.6204       0.6694        0.6250  0.0218\n",
      "     42      0.6395    \u001b[32m0.7018\u001b[0m        0.6394       \u001b[31m0.7190\u001b[0m        \u001b[94m0.5982\u001b[0m  0.0195\n",
      "     43      0.5967    \u001b[32m0.7241\u001b[0m        0.6393       \u001b[31m0.7355\u001b[0m        \u001b[94m0.5948\u001b[0m  0.0188\n",
      "     44      0.6098    0.6286        \u001b[35m0.5955\u001b[0m       0.6777        \u001b[94m0.5916\u001b[0m  0.0188\n",
      "     45      0.6383    0.6800        0.6420       0.7355        0.5990  0.0190\n",
      "     46      0.4868    0.6804        0.6276       \u001b[31m0.7438\u001b[0m        0.5953  0.0257\n",
      "     47      \u001b[36m0.6590\u001b[0m    0.6598        0.6022       0.7273        \u001b[94m0.5698\u001b[0m  0.0232\n",
      "     48      0.5825    0.7040        0.6287       0.6942        0.5993  0.0191\n",
      "     49      \u001b[36m0.6851\u001b[0m    0.6538        0.6046       0.7025        0.5933  0.0253\n",
      "     50      0.6414    0.6486        \u001b[35m0.5944\u001b[0m       0.6777        0.5898  0.0217\n",
      "     51      0.6713    0.6723        \u001b[35m0.5912\u001b[0m       0.6777        0.5948  0.0264\n",
      "     52      0.6759    0.6667        0.6036       0.7107        0.5747  0.0216\n",
      "     53      0.6696    0.6857        \u001b[35m0.5840\u001b[0m       0.7273        \u001b[94m0.5457\u001b[0m  0.0245\n",
      "     54      0.6619    0.7119        0.6218       0.7190        0.5844  0.0273\n",
      "     55      0.6682    0.6304        0.5943       0.7190        0.5605  0.0216\n",
      "     56      0.5867    0.6723        0.5936       0.6777        0.5918  0.0322\n",
      "     57      0.6773    0.6667        0.5857       0.7190        0.5704  0.0245\n",
      "     58      0.6709    0.6903        0.5961       0.7107        0.5489  0.0206\n",
      "     59      0.6835    \u001b[32m0.7258\u001b[0m        0.5882       0.7190        0.5527  0.0233\n",
      "     60      \u001b[36m0.6996\u001b[0m    0.7027        \u001b[35m0.5729\u001b[0m       0.7273        \u001b[94m0.5430\u001b[0m  0.0344\n",
      "     61      \u001b[36m0.7045\u001b[0m    \u001b[32m0.7360\u001b[0m        \u001b[35m0.5659\u001b[0m       0.7273        0.5536  0.0335\n",
      "     62      \u001b[36m0.7300\u001b[0m    0.7333        \u001b[35m0.5551\u001b[0m       0.7355        0.5456  0.0331\n",
      "     63      0.6945    0.7360        0.5869       0.7273        0.5494  0.0392\n",
      "     64      0.7072    0.7000        0.5937       0.7025        0.5652  0.0406\n",
      "     65      0.6854    0.6726        0.5627       0.6942        0.5530  0.0396\n",
      "     66      0.7022    0.7027        \u001b[35m0.5526\u001b[0m       0.7273        \u001b[94m0.5403\u001b[0m  0.0407\n",
      "     67      0.7083    0.6903        0.5550       0.7107        \u001b[94m0.5393\u001b[0m  0.0365\n",
      "     68      0.7032    0.7107        0.5531       0.7107        0.5453  0.0364\n",
      "     69      0.7244    0.7193        \u001b[35m0.5385\u001b[0m       0.7355        \u001b[94m0.5289\u001b[0m  0.0377\n",
      "     70      0.6764    \u001b[32m0.7603\u001b[0m        0.5570       \u001b[31m0.7603\u001b[0m        \u001b[94m0.5218\u001b[0m  0.0371\n",
      "     71      0.7288    0.6909        0.5571       0.7190        0.5369  0.0416\n",
      "     72      0.6859    0.7200        0.5851       0.7107        0.5420  0.0339\n",
      "     73      \u001b[36m0.7420\u001b[0m    0.7368        0.5420       0.7521        \u001b[94m0.5160\u001b[0m  0.0362\n",
      "     74      0.6748    \u001b[32m0.7634\u001b[0m        0.5613       0.7438        0.5546  0.0357\n",
      "     75      0.7237    0.7304        0.5783       0.7438        0.5519  0.0344\n",
      "     76      0.6768    0.7027        0.5485       0.7273        0.5329  0.0314\n",
      "     77      0.7361    0.6981        0.5418       0.7355        0.5315  0.0345\n",
      "     78      0.6556    0.7069        0.5757       0.7190        0.5567  0.0343\n",
      "     79      0.6533    0.6667        0.5608       0.6942        0.5430  0.0355\n",
      "     80      0.6900    0.6964        0.5394       0.7190        0.5335  0.0330\n",
      "     81      0.7105    0.7317        0.5724       0.7273        0.5477  0.0345\n",
      "     82      0.6965    0.6964        0.5457       0.7190        0.5360  0.0354\n",
      "     83      0.7056    0.7302        0.5526       0.7190        0.5520  0.0325\n",
      "     84      \u001b[36m0.7570\u001b[0m    0.7107        \u001b[35m0.5111\u001b[0m       0.7107        0.5414  0.0340\n",
      "     85      0.7297    0.7091        0.5363       0.7355        0.5380  0.0310\n",
      "     86      0.7075    0.7360        0.5610       0.7273        0.5437  0.0281\n",
      "     87      0.7021    0.7207        0.5236       0.7438        0.5308  0.0300\n",
      "     88      0.7032    0.7193        0.5325       0.7355        0.5288  0.0316\n",
      "     89      0.7234    0.7317        0.5196       0.7273        0.5372  0.0326\n",
      "     90      0.7542    0.7207        0.5156       0.7438        0.5222  0.0340\n",
      "     91      0.6914    0.7419        0.5990       0.7355        0.5501  0.0274\n",
      "     92      \u001b[36m0.7623\u001b[0m    0.7130        0.5526       0.7273        0.5490  0.0320\n",
      "     93      0.6902    0.7069        0.5487       0.7190        0.5381  0.0327\n",
      "     94      0.7472    0.7179        0.5149       0.7273        0.5385  0.0331\n",
      "     95      0.7309    \u001b[32m0.7667\u001b[0m        0.5292       \u001b[31m0.7686\u001b[0m        0.5238  0.0348\n",
      "     96      0.7300    0.7333        0.5561       0.7355        0.5338  0.0302\n",
      "     97      0.7383    0.7344        0.5268       0.7190        0.5593  0.0220\n",
      "     98      0.7401    0.7414        0.5199       0.7521        0.5293  0.0226\n",
      "     99      0.7252    0.6957        0.5143       0.7107        0.5347  0.0191\n",
      "    100      0.7085    0.7317        0.5478       0.7273        0.5424  0.0240\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.3989\u001b[0m    \u001b[32m0.0968\u001b[0m        \u001b[35m0.6938\u001b[0m       \u001b[31m0.5372\u001b[0m        \u001b[94m0.6885\u001b[0m  0.0226\n",
      "      2      0.2500    \u001b[32m0.5263\u001b[0m        \u001b[35m0.6806\u001b[0m       \u001b[31m0.6281\u001b[0m        \u001b[94m0.6570\u001b[0m  0.0252\n",
      "      3      \u001b[36m0.4770\u001b[0m    0.4096        \u001b[35m0.6722\u001b[0m       0.5950        0.6582  0.0250\n",
      "      4      0.4239    0.4471        \u001b[35m0.6616\u001b[0m       0.6116        \u001b[94m0.6565\u001b[0m  0.0212\n",
      "      5      0.4464    0.4471        0.6618       0.6116        \u001b[94m0.6556\u001b[0m  0.0252\n",
      "      6      0.4431    0.4773        0.6626       0.6198        \u001b[94m0.6533\u001b[0m  0.0221\n",
      "      7      0.4638    \u001b[32m0.5361\u001b[0m        \u001b[35m0.6590\u001b[0m       0.6281        \u001b[94m0.6524\u001b[0m  0.0317\n",
      "      8      0.4463    0.4598        \u001b[35m0.6573\u001b[0m       0.6116        0.6526  0.0317\n",
      "      9      0.4535    0.4651        0.6622       0.6198        0.6524  0.0367\n",
      "     10      0.4345    0.4524        0.6643       0.6198        0.6525  0.0336\n",
      "     11      0.4320    0.4146        0.6715       0.6033        0.6527  0.0328\n",
      "     12      0.4025    0.5000        0.6659       \u001b[31m0.6364\u001b[0m        \u001b[94m0.6500\u001b[0m  0.0215\n",
      "     13      \u001b[36m0.5266\u001b[0m    \u001b[32m0.6379\u001b[0m        0.6587       \u001b[31m0.6529\u001b[0m        \u001b[94m0.6497\u001b[0m  0.0238\n",
      "     14      0.5028    0.4146        0.6581       0.6033        0.6530  0.0257\n",
      "     15      0.4819    0.6250        \u001b[35m0.6556\u001b[0m       0.6529        0.6516  0.0208\n",
      "     16      0.4246    0.2571        0.6754       0.5702        0.6723  0.0236\n",
      "     17      0.4134    0.6250        0.6660       0.6529        0.6549  0.0197\n",
      "     18      0.4973    0.3846        0.6658       0.6033        0.6565  0.0250\n",
      "     19      0.4642    0.5800        \u001b[35m0.6516\u001b[0m       0.6529        0.6512  0.0214\n",
      "     20      0.5097    0.4598        0.6570       0.6116        0.6500  0.0241\n",
      "     21      0.4348    0.4651        0.6570       0.6198        \u001b[94m0.6485\u001b[0m  0.0269\n",
      "     22      0.4961    0.5319        \u001b[35m0.6503\u001b[0m       0.6364        \u001b[94m0.6450\u001b[0m  0.0192\n",
      "     23      0.4611    0.6226        0.6519       \u001b[31m0.6694\u001b[0m        \u001b[94m0.6388\u001b[0m  0.0237\n",
      "     24      \u001b[36m0.5871\u001b[0m    0.4524        \u001b[35m0.6460\u001b[0m       0.6198        0.6389  0.0190\n",
      "     25      0.5279    \u001b[32m0.6557\u001b[0m        \u001b[35m0.6432\u001b[0m       0.6529        \u001b[94m0.6343\u001b[0m  0.0186\n",
      "     26      0.5095    0.5800        0.6440       0.6529        \u001b[94m0.6268\u001b[0m  0.0225\n",
      "     27      \u001b[36m0.6029\u001b[0m    0.6111        \u001b[35m0.6224\u001b[0m       0.6529        0.6271  0.0188\n",
      "     28      0.5646    0.6055        0.6360       0.6446        \u001b[94m0.6245\u001b[0m  0.0232\n",
      "     29      0.5578    \u001b[32m0.6774\u001b[0m        0.6417       0.6694        \u001b[94m0.6208\u001b[0m  0.0231\n",
      "     30      \u001b[36m0.6221\u001b[0m    0.6552        \u001b[35m0.6154\u001b[0m       0.6694        0.6209  0.0189\n",
      "     31      0.5975    0.6612        \u001b[35m0.6145\u001b[0m       0.6612        0.6209  0.0228\n",
      "     32      0.6127    \u001b[32m0.7068\u001b[0m        0.6158       \u001b[31m0.6777\u001b[0m        \u001b[94m0.5999\u001b[0m  0.0230\n",
      "     33      \u001b[36m0.6521\u001b[0m    0.5393        \u001b[35m0.5965\u001b[0m       0.6612        0.6224  0.0315\n",
      "     34      0.6140    0.6038        0.6336       0.6529        0.6053  0.0215\n",
      "     35      0.4309    0.3377        0.6461       0.5785        0.6510  0.0274\n",
      "     36      0.5553    0.7007        0.6369       0.6612        0.6456  0.0225\n",
      "     37      0.5909    0.4198        0.6105       0.6116        0.6227  0.0279\n",
      "     38      0.5635    0.7007        0.6065       0.6612        0.6301  0.0338\n",
      "     39      0.6059    0.6491        0.6060       0.6694        0.6051  0.0338\n",
      "     40      0.6473    0.6777        0.6068       0.6777        0.6028  0.0338\n",
      "     41      0.5882    0.6606        0.6021       \u001b[31m0.6942\u001b[0m        0.6014  0.0339\n",
      "     42      \u001b[36m0.6549\u001b[0m    0.6719        \u001b[35m0.5829\u001b[0m       0.6529        0.6106  0.0339\n",
      "     43      0.6475    0.6610        \u001b[35m0.5807\u001b[0m       0.6694        0.6050  0.0321\n",
      "     44      0.6450    0.6777        0.5892       0.6777        0.6009  0.0274\n",
      "     45      \u001b[36m0.6683\u001b[0m    0.6780        \u001b[35m0.5787\u001b[0m       0.6860        \u001b[94m0.5902\u001b[0m  0.0212\n",
      "     46      \u001b[36m0.7195\u001b[0m    0.6774        \u001b[35m0.5429\u001b[0m       0.6694        0.5969  0.0313\n",
      "     47      0.6860    0.6842        0.5630       \u001b[31m0.7025\u001b[0m        \u001b[94m0.5816\u001b[0m  0.0215\n",
      "     48      0.6181    0.6724        0.5764       0.6860        0.5824  0.0216\n",
      "     49      0.6571    0.6667        0.5941       0.6694        0.5840  0.0211\n",
      "     50      0.7116    0.6880        0.5551       0.6777        0.5874  0.0268\n",
      "     51      0.6824    0.7031        0.5740       0.6860        0.6111  0.0256\n",
      "     52      0.6733    0.6780        0.5578       0.6860        \u001b[94m0.5798\u001b[0m  0.0224\n",
      "     53      \u001b[36m0.7253\u001b[0m    \u001b[32m0.7069\u001b[0m        \u001b[35m0.5193\u001b[0m       \u001b[31m0.7190\u001b[0m        \u001b[94m0.5749\u001b[0m  0.0247\n",
      "     54      0.6959    \u001b[32m0.7087\u001b[0m        0.5551       0.6942        0.5812  0.0237\n",
      "     55      0.6847    0.6720        0.5561       0.6612        0.5764  0.0252\n",
      "     56      0.6713    0.6829        0.5710       0.6777        0.5895  0.0282\n",
      "     57      0.6837    0.6720        0.5570       0.6612        0.6099  0.0229\n",
      "     58      0.6745    0.6984        0.5648       0.6860        0.5945  0.0222\n",
      "     59      0.7000    0.6909        0.5480       0.7190        \u001b[94m0.5672\u001b[0m  0.0188\n",
      "     60      0.6414    \u001b[32m0.7402\u001b[0m        0.5607       \u001b[31m0.7273\u001b[0m        0.5892  0.0234\n",
      "     61      0.7186    0.7193        0.5502       \u001b[31m0.7355\u001b[0m        \u001b[94m0.5634\u001b[0m  0.0232\n",
      "     62      0.7084    0.7227        0.5367       0.7273        0.5849  0.0196\n",
      "     63      \u001b[36m0.7320\u001b[0m    0.6838        0.5373       0.6942        0.5780  0.0178\n",
      "     64      0.6995    0.7287        0.5340       0.7107        0.5910  0.0241\n",
      "     65      0.7078    0.7244        0.5516       0.7107        0.5802  0.0310\n",
      "     66      0.7078    0.6481        0.5461       0.6860        \u001b[94m0.5535\u001b[0m  0.0210\n",
      "     67      0.6717    \u001b[32m0.7481\u001b[0m        0.5452       0.7273        0.5999  0.0216\n",
      "     68      0.7103    0.7080        0.5320       0.7273        \u001b[94m0.5463\u001b[0m  0.0252\n",
      "     69      0.6958    0.7027        0.5421       0.7273        0.5475  0.0255\n",
      "     70      0.6944    0.6842        0.5409       0.7025        0.5590  0.0247\n",
      "     71      0.6682    0.7009        0.5617       0.7107        0.5521  0.0271\n",
      "     72      0.7051    0.7273        0.5348       0.7273        0.5470  0.0263\n",
      "     73      0.7091    0.7286        0.5368       0.6860        0.6180  0.0219\n",
      "     74      0.7264    0.6606        0.5378       0.6942        0.5512  0.0182\n",
      "     75      0.7281    0.7183        0.5588       0.6694        0.5837  0.0229\n",
      "     76      0.7256    0.6609        \u001b[35m0.5181\u001b[0m       0.6777        0.5520  0.0206\n",
      "     77      0.7277    0.7059        0.5274       0.7107        0.5655  0.0222\n",
      "     78      0.6266    0.7179        0.5310       0.7273        0.5681  0.0256\n",
      "     79      0.6938    0.7059        0.5446       0.7107        0.5704  0.0196\n",
      "     80      0.6845    0.6992        0.5399       0.6942        0.5883  0.0202\n",
      "     81      0.7061    0.7193        0.5452       0.7355        0.5748  0.0232\n",
      "     82      0.7166    0.6977        0.5229       0.6777        0.6156  0.0251\n",
      "     83      \u001b[36m0.7473\u001b[0m    0.6972        \u001b[35m0.5080\u001b[0m       0.7273        0.5655  0.0247\n",
      "     84      0.7070    0.7154        0.5116       0.7107        0.5839  0.0209\n",
      "     85      \u001b[36m0.7599\u001b[0m    0.6964        0.5120       0.7190        0.5599  0.0213\n",
      "     86      0.7218    \u001b[32m0.7500\u001b[0m        0.5189       0.7355        0.5827  0.0186\n",
      "     87      0.7209    0.5962        \u001b[35m0.5062\u001b[0m       0.6529        0.5586  0.0232\n",
      "     88      0.7017    0.6875        0.5109       0.6694        0.5919  0.0313\n",
      "     89      0.7298    0.7143        0.5080       0.7025        0.5721  0.0296\n",
      "     90      0.7505    0.6942        \u001b[35m0.4902\u001b[0m       0.6942        0.5566  0.0181\n",
      "     91      0.7212    \u001b[32m0.7742\u001b[0m        0.5347       \u001b[31m0.7686\u001b[0m        0.5467  0.0334\n",
      "     92      0.7110    0.6415        0.5278       0.6860        \u001b[94m0.5378\u001b[0m  0.0295\n",
      "     93      0.6748    0.7328        0.5548       0.7107        0.5594  0.0323\n",
      "     94      0.7191    0.6838        0.5156       0.6942        \u001b[94m0.5374\u001b[0m  0.0219\n",
      "     95      0.7449    0.6935        0.4992       0.6860        0.5551  0.0187\n",
      "     96      0.7073    0.6667        0.5138       0.6942        \u001b[94m0.5270\u001b[0m  0.0283\n",
      "     97      0.7403    0.7273        0.5388       0.7273        0.5430  0.0183\n",
      "     98      0.6751    0.6372        0.5425       0.6612        0.5444  0.0284\n",
      "     99      \u001b[36m0.7685\u001b[0m    0.7273        0.5042       0.7025        0.5992  0.0225\n",
      "    100      0.7500    0.7000        0.4984       0.7025        0.5646  0.0232\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.3095\u001b[0m    \u001b[32m0.3333\u001b[0m        \u001b[35m0.6983\u001b[0m       \u001b[31m0.6033\u001b[0m        \u001b[94m0.6782\u001b[0m  0.0225\n",
      "      2      \u001b[36m0.4885\u001b[0m    \u001b[32m0.4500\u001b[0m        \u001b[35m0.6713\u001b[0m       \u001b[31m0.6364\u001b[0m        \u001b[94m0.6648\u001b[0m  0.0216\n",
      "      3      0.3891    0.2899        \u001b[35m0.6631\u001b[0m       0.5950        0.6687  0.0209\n",
      "      4      0.4066    0.4304        0.6709       0.6281        \u001b[94m0.6621\u001b[0m  0.0277\n",
      "      5      0.4052    0.3784        \u001b[35m0.6544\u001b[0m       0.6198        0.6663  0.0278\n",
      "      6      0.4732    0.4000        \u001b[35m0.6481\u001b[0m       0.6033        0.6669  0.0222\n",
      "      7      \u001b[36m0.4985\u001b[0m    0.4091        \u001b[35m0.6243\u001b[0m       0.5702        0.6726  0.0264\n",
      "      8      \u001b[36m0.5029\u001b[0m    0.4000        0.6422       0.6281        0.6677  0.0279\n",
      "      9      0.4169    0.3947        0.6484       0.6198        0.6686  0.0273\n",
      "     10      0.4387    0.4000        0.6319       0.5537        \u001b[94m0.6621\u001b[0m  0.0233\n",
      "     11      \u001b[36m0.5623\u001b[0m    0.4337        0.6546       0.6116        0.6689  0.0244\n",
      "     12      0.4465    0.4337        0.6366       0.6116        0.6635  0.0232\n",
      "     13      0.4986    0.4186        0.6404       0.5868        \u001b[94m0.6563\u001b[0m  0.0225\n",
      "     14      0.4138    0.4000        0.6361       0.6281        0.6937  0.0306\n",
      "     15      0.4648    \u001b[32m0.4600\u001b[0m        0.6493       0.5537        \u001b[94m0.6533\u001b[0m  0.0208\n",
      "     16      \u001b[36m0.6187\u001b[0m    0.4301        0.6318       0.5620        0.6627  0.0324\n",
      "     17      0.4716    0.3947        0.6363       0.6198        0.6822  0.0266\n",
      "     18      0.4582    0.4270        0.6378       0.5785        0.6576  0.0277\n",
      "     19      0.5430    0.4270        0.6297       0.5785        0.6602  0.0288\n",
      "     20      0.5330    0.4186        0.6272       0.5868        0.6711  0.0210\n",
      "     21      0.5598    \u001b[32m0.4694\u001b[0m        0.6293       0.5702        \u001b[94m0.6531\u001b[0m  0.0266\n",
      "     22      0.5924    0.4471        0.6415       0.6116        0.6669  0.0252\n",
      "     23      0.5119    0.4651        \u001b[35m0.6216\u001b[0m       0.6198        0.6738  0.0252\n",
      "     24      0.5722    \u001b[32m0.4742\u001b[0m        0.6286       0.5785        0.6582  0.0232\n",
      "     25      0.6042    0.4375        \u001b[35m0.6180\u001b[0m       0.5537        0.6609  0.0269\n",
      "     26      0.5699    \u001b[32m0.4848\u001b[0m        \u001b[35m0.6125\u001b[0m       0.5785        \u001b[94m0.6501\u001b[0m  0.0269\n",
      "     27      \u001b[36m0.6250\u001b[0m    0.4819        \u001b[35m0.5963\u001b[0m       \u001b[31m0.6446\u001b[0m        0.6702  0.0222\n",
      "     28      \u001b[36m0.6681\u001b[0m    0.4762        0.6313       0.6364        0.6806  0.0253\n",
      "     29      0.6423    \u001b[32m0.5370\u001b[0m        0.6240       0.5868        \u001b[94m0.6411\u001b[0m  0.0242\n",
      "     30      \u001b[36m0.6682\u001b[0m    0.4948        \u001b[35m0.5931\u001b[0m       0.5950        0.6547  0.0215\n",
      "     31      0.6590    \u001b[32m0.5421\u001b[0m        0.6051       0.5950        \u001b[94m0.6382\u001b[0m  0.0216\n",
      "     32      \u001b[36m0.6807\u001b[0m    \u001b[32m0.5745\u001b[0m        \u001b[35m0.5922\u001b[0m       \u001b[31m0.6694\u001b[0m        \u001b[94m0.6250\u001b[0m  0.0209\n",
      "     33      0.6745    0.5745        \u001b[35m0.5802\u001b[0m       0.6694        \u001b[94m0.6078\u001b[0m  0.0259\n",
      "     34      0.6789    0.5714        0.5859       0.6281        0.6235  0.0244\n",
      "     35      \u001b[36m0.7018\u001b[0m    \u001b[32m0.6226\u001b[0m        \u001b[35m0.5626\u001b[0m       0.6694        0.6095  0.0215\n",
      "     36      0.6872    0.5155        0.5671       0.6116        0.6248  0.0228\n",
      "     37      0.6991    0.5476        \u001b[35m0.5619\u001b[0m       \u001b[31m0.6860\u001b[0m        0.6625  0.0276\n",
      "     38      \u001b[36m0.7140\u001b[0m    0.5957        0.5630       0.6860        0.6450  0.0251\n",
      "     39      0.6652    0.6078        0.5866       0.6694        \u001b[94m0.6074\u001b[0m  0.0229\n",
      "     40      0.6286    0.5111        0.5755       0.6364        0.6332  0.0238\n",
      "     41      0.6966    0.5155        0.5710       0.6116        0.6320  0.0211\n",
      "     42      0.6821    \u001b[32m0.6604\u001b[0m        0.5830       \u001b[31m0.7025\u001b[0m        \u001b[94m0.5968\u001b[0m  0.0255\n",
      "     43      0.7031    0.5773        0.5649       0.6612        0.6202  0.0267\n",
      "     44      \u001b[36m0.7289\u001b[0m    0.5000        \u001b[35m0.5405\u001b[0m       0.6364        0.6411  0.0212\n",
      "     45      0.7098    0.4878        0.5745       0.6529        0.6253  0.0318\n",
      "     46      0.5972    0.6429        0.5744       0.6694        0.5994  0.0234\n",
      "     47      0.7082    0.5962        0.5819       0.6529        0.6436  0.0361\n",
      "     48      0.7190    0.6552        0.5782       0.6694        \u001b[94m0.5901\u001b[0m  0.0368\n",
      "     49      \u001b[36m0.7570\u001b[0m    0.5556        \u001b[35m0.5364\u001b[0m       0.6694        0.6142  0.0238\n",
      "     50      0.7126    0.6337        0.5460       0.6942        \u001b[94m0.5831\u001b[0m  0.0238\n",
      "     51      0.7427    0.6316        \u001b[35m0.5304\u001b[0m       \u001b[31m0.7107\u001b[0m        0.5916  0.0271\n",
      "     52      0.7251    0.6200        0.5309       0.6860        \u001b[94m0.5747\u001b[0m  0.0302\n",
      "     53      0.7273    0.5682        0.5419       0.6860        0.5926  0.0348\n",
      "     54      0.7121    0.6408        \u001b[35m0.5255\u001b[0m       0.6942        0.5755  0.0356\n",
      "     55      0.7345    0.6170        \u001b[35m0.5190\u001b[0m       0.7025        0.6465  0.0401\n",
      "     56      0.7177    0.6000        0.5403       0.7025        0.6278  0.0373\n",
      "     57      0.6755    0.6400        0.5555       0.7025        0.5877  0.0285\n",
      "     58      0.7366    0.5517        0.5286       0.6777        0.5959  0.0335\n",
      "     59      0.7103    \u001b[32m0.6792\u001b[0m        0.5201       \u001b[31m0.7190\u001b[0m        0.5811  0.0275\n",
      "     60      0.7477    0.5435        \u001b[35m0.5101\u001b[0m       0.6529        0.5962  0.0234\n",
      "     61      0.7186    0.5833        0.5102       0.6694        0.5859  0.0233\n",
      "     62      0.7400    0.5185        \u001b[35m0.5051\u001b[0m       0.6777        0.6568  0.0277\n",
      "     63      0.7357    \u001b[32m0.7103\u001b[0m        0.5219       \u001b[31m0.7438\u001b[0m        0.6316  0.0242\n",
      "     64      0.7248    \u001b[32m0.7455\u001b[0m        0.5223       \u001b[31m0.7686\u001b[0m        \u001b[94m0.5458\u001b[0m  0.0234\n",
      "     65      0.7028    0.6042        0.5384       0.6860        0.5890  0.0236\n",
      "     66      0.7176    0.5000        0.5469       0.6694        0.5965  0.0227\n",
      "     67      0.6959    0.6600        0.5168       0.7190        0.5584  0.0327\n",
      "     68      0.7100    0.6981        0.5333       0.7355        0.5514  0.0234\n",
      "     69      \u001b[36m0.7696\u001b[0m    0.6923        \u001b[35m0.4969\u001b[0m       0.7355        0.5967  0.0349\n",
      "     70      0.7477    0.6729        \u001b[35m0.4882\u001b[0m       0.7107        0.6216  0.0286\n",
      "     71      0.7583    0.6972        \u001b[35m0.4848\u001b[0m       0.7273        0.6003  0.0234\n",
      "     72      0.7562    0.7103        \u001b[35m0.4830\u001b[0m       0.7438        0.5906  0.0280\n",
      "     73      0.7385    0.5843        0.4917       0.6942        0.6532  0.0364\n",
      "     74      0.7416    0.6667        0.5109       0.7107        0.6047  0.0237\n",
      "     75      0.6948    0.4941        0.5176       0.6446        0.6268  0.0290\n",
      "     76      0.7163    0.6022        0.5034       0.6942        0.6018  0.0231\n",
      "     77      0.7585    0.6796        \u001b[35m0.4544\u001b[0m       0.7273        0.6338  0.0335\n",
      "     78      0.7457    0.6857        0.4878       0.7273        0.6507  0.0368\n",
      "     79      0.7609    0.6604        0.4869       0.7025        0.6009  0.0384\n",
      "     80      0.7400    0.6250        0.4997       0.7025        0.6028  0.0270\n",
      "     81      0.7483    0.6731        0.5139       0.7190        0.5728  0.0220\n",
      "     82      0.7523    0.6731        0.4875       0.7190        0.5779  0.0261\n",
      "     83      0.7572    0.5682        0.4789       0.6860        0.6186  0.0212\n",
      "     84      0.7083    0.6600        0.4946       0.7190        0.5520  0.0309\n",
      "     85      0.7532    0.6392        0.5061       0.7107        0.5606  0.0314\n",
      "     86      0.7143    0.6122        0.4902       0.6860        0.5919  0.0338\n",
      "     87      0.7506    0.6471        0.4957       0.7025        0.5632  0.0282\n",
      "     88      0.7433    0.6990        0.4613       0.7438        0.5731  0.0377\n",
      "     89      0.7631    0.6863        0.4647       0.7355        0.6426  0.0362\n",
      "     90      0.7317    0.6327        0.4767       0.7025        0.6236  0.0397\n",
      "     91      0.7529    0.5714        0.4889       0.6777        0.6396  0.0327\n",
      "     92      0.7165    0.6170        0.4961       0.7025        0.6018  0.0260\n",
      "     93      0.7609    0.5843        0.4872       0.6942        0.6859  0.0206\n",
      "     94      0.7218    0.6600        0.4854       0.7190        0.5748  0.0242\n",
      "     95      0.7562    0.6170        0.4726       0.7025        0.6272  0.0265\n",
      "     96      0.7470    0.6916        0.4624       0.7273        0.5853  0.0261\n",
      "     97      0.7640    0.6392        0.4807       0.7107        0.5866  0.0229\n",
      "     98      0.7475    0.6105        0.4646       0.6942        0.6132  0.0272\n",
      "     99      0.7632    0.6471        0.4641       0.7025        0.6464  0.0230\n",
      "    100      0.7464    0.5287        0.4826       0.6612        0.6590  0.0215\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6207\u001b[0m    \u001b[32m0.6480\u001b[0m        \u001b[35m0.7063\u001b[0m       \u001b[31m0.4793\u001b[0m        \u001b[94m0.6826\u001b[0m  0.0208\n",
      "      2      \u001b[36m0.6499\u001b[0m    0.5769        \u001b[35m0.6815\u001b[0m       \u001b[31m0.6364\u001b[0m        \u001b[94m0.6623\u001b[0m  0.0277\n",
      "      3      0.5366    0.5263        \u001b[35m0.6608\u001b[0m       0.6281        \u001b[94m0.6527\u001b[0m  0.0213\n",
      "      4      0.5907    0.5833        0.6615       0.5868        \u001b[94m0.6502\u001b[0m  0.0212\n",
      "      5      0.5741    0.5391        \u001b[35m0.6593\u001b[0m       0.5620        0.6573  0.0262\n",
      "      6      0.5939    0.5294        0.6701       0.6033        0.6558  0.0213\n",
      "      7      0.4235    0.4146        0.6649       0.6033        0.6639  0.0210\n",
      "      8      0.5391    0.5690        \u001b[35m0.6589\u001b[0m       0.5868        \u001b[94m0.6492\u001b[0m  0.0263\n",
      "      9      0.5789    0.5200        0.6734       0.6033        \u001b[94m0.6491\u001b[0m  0.0229\n",
      "     10      0.4518    0.4286        \u001b[35m0.6582\u001b[0m       0.6033        0.6604  0.0211\n",
      "     11      0.5095    0.5641        0.6674       0.5785        0.6517  0.0328\n",
      "     12      0.6043    0.5517        \u001b[35m0.6565\u001b[0m       0.5702        0.6500  0.0230\n",
      "     13      0.5855    0.5283        \u001b[35m0.6559\u001b[0m       0.5868        \u001b[94m0.6467\u001b[0m  0.0262\n",
      "     14      0.6005    0.5421        \u001b[35m0.6460\u001b[0m       0.5950        \u001b[94m0.6443\u001b[0m  0.0259\n",
      "     15      0.5835    0.5333        0.6497       0.5950        0.6453  0.0255\n",
      "     16      0.5915    0.5333        0.6513       0.5950        0.6489  0.0250\n",
      "     17      0.5855    0.5688        0.6493       0.6116        0.6509  0.0229\n",
      "     18      0.5899    0.5200        0.6480       0.6033        0.6475  0.0238\n",
      "     19      0.6253    0.5000        \u001b[35m0.6418\u001b[0m       0.6033        \u001b[94m0.6410\u001b[0m  0.0247\n",
      "     20      0.5819    0.5872        0.6510       0.6281        \u001b[94m0.6342\u001b[0m  0.0219\n",
      "     21      0.6173    0.5306        \u001b[35m0.6278\u001b[0m       0.6198        0.6385  0.0223\n",
      "     22      0.5929    \u001b[32m0.6560\u001b[0m        0.6600       \u001b[31m0.6446\u001b[0m        0.6364  0.0253\n",
      "     23      0.5877    0.5532        0.6362       \u001b[31m0.6529\u001b[0m        0.6500  0.0257\n",
      "     24      0.6193    \u001b[32m0.6870\u001b[0m        0.6625       \u001b[31m0.6612\u001b[0m        0.6409  0.0241\n",
      "     25      0.6281    0.5625        0.6442       0.6529        0.6353  0.0267\n",
      "     26      0.6024    0.6667        0.6452       0.6612        \u001b[94m0.6175\u001b[0m  0.0214\n",
      "     27      0.6208    0.5872        0.6454       0.6281        0.6255  0.0311\n",
      "     28      0.6061    0.6018        0.6374       0.6281        0.6331  0.0211\n",
      "     29      0.6247    0.5743        0.6375       0.6446        0.6343  0.0273\n",
      "     30      0.6066    0.6071        \u001b[35m0.6271\u001b[0m       0.6364        \u001b[94m0.6124\u001b[0m  0.0232\n",
      "     31      0.6276    0.5833        0.6277       \u001b[31m0.6694\u001b[0m        0.6202  0.0271\n",
      "     32      0.6025    0.5660        \u001b[35m0.6161\u001b[0m       0.6198        0.6153  0.0273\n",
      "     33      \u001b[36m0.6526\u001b[0m    0.6139        0.6297       \u001b[31m0.6777\u001b[0m        \u001b[94m0.6005\u001b[0m  0.0332\n",
      "     34      0.5757    0.6139        0.6198       0.6777        \u001b[94m0.5956\u001b[0m  0.0234\n",
      "     35      0.5928    0.5618        0.6250       0.6777        0.6081  0.0249\n",
      "     36      0.5416    0.6422        0.6254       0.6777        0.5999  0.0233\n",
      "     37      \u001b[36m0.6580\u001b[0m    0.6168        0.6211       0.6612        \u001b[94m0.5775\u001b[0m  0.0279\n",
      "     38      \u001b[36m0.6621\u001b[0m    0.6602        0.6265       \u001b[31m0.7107\u001b[0m        0.6027  0.0210\n",
      "     39      0.6452    0.6667        \u001b[35m0.6068\u001b[0m       0.6860        0.5968  0.0250\n",
      "     40      \u001b[36m0.6887\u001b[0m    0.6364        \u001b[35m0.5940\u001b[0m       0.6694        0.5970  0.0235\n",
      "     41      0.6725    0.6486        0.6050       0.6777        0.5951  0.0250\n",
      "     42      0.6447    \u001b[32m0.6957\u001b[0m        0.6141       0.7107        \u001b[94m0.5678\u001b[0m  0.0283\n",
      "     43      0.6590    \u001b[32m0.7167\u001b[0m        \u001b[35m0.5922\u001b[0m       \u001b[31m0.7190\u001b[0m        \u001b[94m0.5603\u001b[0m  0.0236\n",
      "     44      \u001b[36m0.7038\u001b[0m    0.6731        \u001b[35m0.5918\u001b[0m       0.7190        0.5621  0.0215\n",
      "     45      \u001b[36m0.7091\u001b[0m    0.6733        \u001b[35m0.5812\u001b[0m       \u001b[31m0.7273\u001b[0m        \u001b[94m0.5483\u001b[0m  0.0246\n",
      "     46      0.6878    0.6800        0.5964       \u001b[31m0.7355\u001b[0m        0.5689  0.0256\n",
      "     47      0.5632    0.7027        0.5969       0.7273        0.5623  0.0214\n",
      "     48      0.6998    0.6667        \u001b[35m0.5726\u001b[0m       0.6942        0.5688  0.0323\n",
      "     49      0.7002    0.6724        0.6136       0.6860        0.5985  0.0209\n",
      "     50      0.6729    0.6535        0.5940       0.7107        0.5860  0.0322\n",
      "     51      0.6545    0.6923        0.5867       0.7355        0.5686  0.0232\n",
      "     52      0.6714    0.6667        \u001b[35m0.5629\u001b[0m       0.7190        0.5544  0.0231\n",
      "     53      \u001b[36m0.7146\u001b[0m    0.6598        0.5843       0.7273        0.5807  0.0337\n",
      "     54      0.6536    0.6833        0.6003       0.6860        0.5915  0.0288\n",
      "     55      \u001b[36m0.7276\u001b[0m    0.6942        0.5948       0.6942        0.5877  0.0271\n",
      "     56      0.7140    0.6796        \u001b[35m0.5596\u001b[0m       0.7273        0.5741  0.0281\n",
      "     57      0.7061    0.6897        0.5658       0.7025        0.5723  0.0221\n",
      "     58      0.7228    0.7049        0.5777       0.7025        0.5526  0.0340\n",
      "     59      0.7053    0.6891        \u001b[35m0.5515\u001b[0m       0.6942        \u001b[94m0.5474\u001b[0m  0.0320\n",
      "     60      0.7096    0.7119        0.5870       0.7190        0.5559  0.0394\n",
      "     61      0.6843    0.6847        0.5549       0.7107        \u001b[94m0.5382\u001b[0m  0.0320\n",
      "     62      0.7119    0.6852        0.5652       0.7190        \u001b[94m0.5209\u001b[0m  0.0336\n",
      "     63      0.6843    \u001b[32m0.7387\u001b[0m        0.5631       \u001b[31m0.7603\u001b[0m        0.5289  0.0336\n",
      "     64      \u001b[36m0.7591\u001b[0m    0.7115        \u001b[35m0.5362\u001b[0m       0.7521        0.5379  0.0348\n",
      "     65      0.6683    0.7227        0.5724       0.7273        0.5515  0.0373\n",
      "     66      0.7262    0.7200        0.5644       0.7107        0.5464  0.0358\n",
      "     67      0.7430    0.7257        \u001b[35m0.5274\u001b[0m       0.7438        0.5316  0.0343\n",
      "     68      0.7261    0.6852        0.5396       0.7190        0.5427  0.0319\n",
      "     69      0.7123    0.6903        0.5354       0.7107        0.5669  0.0354\n",
      "     70      0.7195    0.6909        0.5451       0.7190        0.5633  0.0268\n",
      "     71      0.7562    0.6964        0.5353       0.7190        0.5753  0.0339\n",
      "     72      0.7110    0.7154        0.5620       0.7107        0.5549  0.0355\n",
      "     73      0.7209    0.7258        0.5374       0.7190        0.5408  0.0367\n",
      "     74      0.7589    0.7200        \u001b[35m0.5233\u001b[0m       0.7107        0.5758  0.0373\n",
      "     75      0.7216    0.6786        0.5451       0.7025        0.5441  0.0344\n",
      "     76      0.7407    0.7130        0.5529       0.7273        0.5355  0.0380\n",
      "     77      0.7309    0.7304        0.5357       0.7438        0.5249  0.0375\n",
      "     78      0.7379    0.7143        0.5568       0.7355        0.5272  0.0265\n",
      "     79      0.7211    0.7059        0.5320       0.7107        0.5319  0.0323\n",
      "     80      \u001b[36m0.7635\u001b[0m    0.7143        \u001b[35m0.5164\u001b[0m       0.7355        0.5398  0.0240\n",
      "     81      0.7332    0.7143        0.5535       0.6694        0.5819  0.0230\n",
      "     82      0.7297    0.7027        0.5539       0.7273        0.5553  0.0273\n",
      "     83      0.7298    0.7193        0.5271       0.7355        0.5337  0.0234\n",
      "     84      0.7458    0.7027        \u001b[35m0.5144\u001b[0m       0.7273        0.5337  0.0294\n",
      "     85      0.7392    0.7350        0.5248       0.7438        0.5515  0.0228\n",
      "     86      0.7484    0.7027        0.5227       0.7273        0.5462  0.0280\n",
      "     87      0.7512    \u001b[32m0.7442\u001b[0m        \u001b[35m0.5122\u001b[0m       0.7273        0.5349  0.0235\n",
      "     88      0.7530    0.6903        0.5317       0.7107        0.5295  0.0220\n",
      "     89      0.7357    0.7200        0.5178       0.7107        0.5558  0.0274\n",
      "     90      0.7586    0.7027        \u001b[35m0.4986\u001b[0m       0.7273        0.6005  0.0261\n",
      "     91      0.7301    0.6822        0.5572       0.6612        0.5943  0.0261\n",
      "     92      0.7361    0.6783        0.5344       0.6942        0.5582  0.0281\n",
      "     93      0.7532    0.6842        0.5179       0.7025        0.5578  0.0206\n",
      "     94      0.7400    0.6903        0.5258       0.7107        0.5477  0.0257\n",
      "     95      0.7534    0.6909        0.5041       0.7190        0.5598  0.0336\n",
      "     96      0.7215    0.7227        0.5267       0.7273        0.5800  0.0277\n",
      "     97      0.7500    0.6903        0.5421       0.7107        0.5680  0.0234\n",
      "     98      0.7472    0.7000        0.5269       0.7025        0.5744  0.0274\n",
      "     99      0.7552    0.7027        0.5129       0.7273        0.5986  0.0343\n",
      "    100      0.7450    0.6875        0.5020       0.6694        0.5698  0.0270\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6544\u001b[0m    \u001b[32m0.3902\u001b[0m        \u001b[35m0.6804\u001b[0m       \u001b[31m0.5868\u001b[0m        \u001b[94m0.6682\u001b[0m  0.0232\n",
      "      2      0.4987    0.3902        0.6895       0.5868        \u001b[94m0.6666\u001b[0m  0.0211\n",
      "      3      0.2206    0.0968        0.6885       0.5372        0.6912  0.0281\n",
      "      4      0.2369    \u001b[32m0.5600\u001b[0m        0.6889       \u001b[31m0.6364\u001b[0m        0.6715  0.0320\n",
      "      5      0.4488    0.4545        \u001b[35m0.6713\u001b[0m       0.6033        \u001b[94m0.6581\u001b[0m  0.0392\n",
      "      6      0.4230    0.3951        \u001b[35m0.6629\u001b[0m       0.5950        0.6662  0.0385\n",
      "      7      0.3962    0.5319        \u001b[35m0.6618\u001b[0m       0.6364        0.6632  0.0326\n",
      "      8      0.4444    0.5545        0.6705       0.6281        0.6594  0.0312\n",
      "      9      0.4536    0.4835        0.6673       0.6116        \u001b[94m0.6576\u001b[0m  0.0338\n",
      "     10      0.4377    0.3750        0.6632       0.5868        0.6585  0.0400\n",
      "     11      0.4286    0.5417        \u001b[35m0.6598\u001b[0m       0.6364        0.6590  0.0385\n",
      "     12      0.4358    0.3846        0.6717       0.6033        0.6636  0.0357\n",
      "     13      0.4345    0.5000        0.6640       0.6198        \u001b[94m0.6546\u001b[0m  0.0249\n",
      "     14      0.4785    0.5600        0.6606       0.6364        \u001b[94m0.6528\u001b[0m  0.0230\n",
      "     15      0.4835    0.3902        0.6689       0.5868        0.6584  0.0232\n",
      "     16      0.4839    \u001b[32m0.5893\u001b[0m        0.6685       0.6198        0.6545  0.0264\n",
      "     17      0.4946    0.4096        0.6613       0.5950        0.6584  0.0208\n",
      "     18      0.4217    0.5208        0.6607       0.6198        0.6567  0.0210\n",
      "     19      0.5174    \u001b[32m0.5905\u001b[0m        \u001b[35m0.6572\u001b[0m       \u001b[31m0.6446\u001b[0m        0.6560  0.0209\n",
      "     20      0.5042    0.4545        \u001b[35m0.6509\u001b[0m       0.6033        0.6558  0.0215\n",
      "     21      0.4973    \u001b[32m0.6000\u001b[0m        0.6517       0.6033        0.6553  0.0228\n",
      "     22      0.5910    0.5789        \u001b[35m0.6468\u001b[0m       0.6033        \u001b[94m0.6506\u001b[0m  0.0210\n",
      "     23      0.5533    0.5417        0.6527       0.6364        \u001b[94m0.6480\u001b[0m  0.0214\n",
      "     24      0.5441    \u001b[32m0.6379\u001b[0m        0.6558       \u001b[31m0.6529\u001b[0m        \u001b[94m0.6371\u001b[0m  0.0287\n",
      "     25      0.5263    0.5057        \u001b[35m0.6451\u001b[0m       0.6446        0.6383  0.0322\n",
      "     26      0.5579    0.6341        \u001b[35m0.6407\u001b[0m       0.6281        \u001b[94m0.6302\u001b[0m  0.0314\n",
      "     27      0.6023    \u001b[32m0.6667\u001b[0m        \u001b[35m0.6386\u001b[0m       0.6364        0.6334  0.0328\n",
      "     28      0.6023    0.4950        \u001b[35m0.6305\u001b[0m       0.5785        0.6502  0.0311\n",
      "     29      0.5802    \u001b[32m0.6714\u001b[0m        0.6312       0.6198        0.6330  0.0208\n",
      "     30      0.6309    0.6286        \u001b[35m0.6265\u001b[0m       \u001b[31m0.6777\u001b[0m        \u001b[94m0.6292\u001b[0m  0.0206\n",
      "     31      0.6250    \u001b[32m0.7020\u001b[0m        0.6327       0.6281        0.6341  0.0207\n",
      "     32      0.6507    0.6422        \u001b[35m0.6175\u001b[0m       0.6777        \u001b[94m0.6152\u001b[0m  0.0210\n",
      "     33      0.6474    0.6880        0.6275       0.6777        \u001b[94m0.6138\u001b[0m  0.0211\n",
      "     34      0.6056    0.6565        0.6325       0.6281        \u001b[94m0.6097\u001b[0m  0.0209\n",
      "     35      0.6424    \u001b[32m0.7069\u001b[0m        \u001b[35m0.6095\u001b[0m       \u001b[31m0.7190\u001b[0m        \u001b[94m0.5883\u001b[0m  0.0218\n",
      "     36      \u001b[36m0.6667\u001b[0m    \u001b[32m0.7244\u001b[0m        \u001b[35m0.5922\u001b[0m       0.7107        \u001b[94m0.5862\u001b[0m  0.0231\n",
      "     37      \u001b[36m0.6885\u001b[0m    0.7213        \u001b[35m0.5881\u001b[0m       0.7190        \u001b[94m0.5854\u001b[0m  0.0229\n",
      "     38      0.6748    0.6984        0.6076       0.6860        0.5920  0.0246\n",
      "     39      0.6233    0.7194        0.6146       0.6777        0.5986  0.0208\n",
      "     40      \u001b[36m0.7071\u001b[0m    0.6964        \u001b[35m0.5876\u001b[0m       0.7190        \u001b[94m0.5729\u001b[0m  0.0213\n",
      "     41      0.6816    0.7241        \u001b[35m0.5807\u001b[0m       \u001b[31m0.7355\u001b[0m        0.5731  0.0215\n",
      "     42      0.6876    0.7031        \u001b[35m0.5617\u001b[0m       0.6860        0.5996  0.0208\n",
      "     43      0.6566    0.7007        0.6086       0.6612        0.5917  0.0214\n",
      "     44      0.6894    0.7107        0.5751       0.7107        \u001b[94m0.5678\u001b[0m  0.0204\n",
      "     45      0.6975    0.7241        0.5718       0.7355        0.5827  0.0204\n",
      "     46      0.6724    0.7164        0.5781       0.6860        0.5872  0.0206\n",
      "     47      0.7069    0.6796        0.5916       0.7273        0.5774  0.0204\n",
      "     48      0.6729    0.6935        0.5684       0.6860        0.5985  0.0203\n",
      "     49      \u001b[36m0.7097\u001b[0m    \u001b[32m0.7680\u001b[0m        0.5796       \u001b[31m0.7603\u001b[0m        0.5753  0.0220\n",
      "     50      \u001b[36m0.7163\u001b[0m    0.6869        0.5766       0.7438        0.5835  0.0224\n",
      "     51      0.6143    0.7172        0.6268       0.6612        0.6244  0.0216\n",
      "     52      0.6989    0.6214        0.5851       0.6777        0.5921  0.0203\n",
      "     53      0.6853    0.7049        0.5656       0.7025        0.5702  0.0203\n",
      "     54      0.6903    0.7153        0.5683       0.6777        0.5996  0.0212\n",
      "     55      \u001b[36m0.7228\u001b[0m    0.6903        \u001b[35m0.5477\u001b[0m       0.7107        0.5698  0.0223\n",
      "     56      \u001b[36m0.7261\u001b[0m    0.7231        0.5481       0.7025        0.5745  0.0204\n",
      "     57      0.6833    0.6933        0.6061       0.6198        0.5832  0.0211\n",
      "     58      \u001b[36m0.7360\u001b[0m    0.6481        0.5634       0.6860        0.5767  0.0204\n",
      "     59      0.6744    0.6963        0.5774       0.6612        0.6011  0.0209\n",
      "     60      0.7226    0.6607        0.5572       0.6860        \u001b[94m0.5647\u001b[0m  0.0204\n",
      "     61      0.6943    0.7385        0.5517       0.7190        0.5711  0.0203\n",
      "     62      \u001b[36m0.7400\u001b[0m    0.7304        \u001b[35m0.5167\u001b[0m       0.7438        \u001b[94m0.5626\u001b[0m  0.0204\n",
      "     63      0.6869    0.7244        0.5875       0.7107        0.5689  0.0204\n",
      "     64      0.7375    0.7040        0.5420       0.6942        0.5684  0.0213\n",
      "     65      0.7227    0.7442        0.5248       0.7273        0.5661  0.0218\n",
      "     66      0.7397    0.7227        0.5190       0.7273        0.5630  0.0218\n",
      "     67      \u001b[36m0.7521\u001b[0m    0.7031        \u001b[35m0.5078\u001b[0m       0.6860        0.5940  0.0284\n",
      "     68      \u001b[36m0.7526\u001b[0m    0.7273        0.5197       0.7025        0.5812  0.0220\n",
      "     69      0.7214    0.7520        0.5309       0.7438        \u001b[94m0.5610\u001b[0m  0.0220\n",
      "     70      \u001b[36m0.7656\u001b[0m    0.7480        \u001b[35m0.4973\u001b[0m       0.7438        0.5977  0.0208\n",
      "     71      0.7293    0.6992        0.5508       0.6942        \u001b[94m0.5551\u001b[0m  0.0234\n",
      "     72      0.7237    0.7018        0.5202       0.7190        0.5727  0.0275\n",
      "     73      0.7494    0.6842        0.5296       0.7025        0.5639  0.0223\n",
      "     74      0.7185    0.6667        0.5433       0.6860        0.5627  0.0211\n",
      "     75      0.7156    0.7107        0.5309       0.7107        0.5920  0.0201\n",
      "     76      0.7461    0.7167        0.5273       0.7190        \u001b[94m0.5536\u001b[0m  0.0199\n",
      "     77      0.7163    0.7317        0.5260       0.7273        0.5661  0.0197\n",
      "     78      0.7468    0.6364        0.5202       0.6694        0.5809  0.0198\n",
      "     79      0.6828    0.7313        0.5456       0.7025        0.6084  0.0197\n",
      "     80      0.7343    0.6552        0.5246       0.6694        0.5622  0.0203\n",
      "     81      0.7302    0.7077        0.5215       0.6860        0.5869  0.0198\n",
      "     82      0.7500    0.7097        0.5062       0.7025        0.6067  0.0213\n",
      "     83      0.7391    0.6942        0.5213       0.6942        0.5732  0.0237\n",
      "     84      0.7347    0.7049        0.5087       0.7025        0.5658  0.0196\n",
      "     85      \u001b[36m0.7719\u001b[0m    0.6903        \u001b[35m0.4924\u001b[0m       0.7107        0.5625  0.0199\n",
      "     86      0.7534    0.7023        \u001b[35m0.4882\u001b[0m       0.6777        0.6200  0.0214\n",
      "     87      0.7371    0.6847        0.5455       0.7107        0.5688  0.0242\n",
      "     88      0.7140    0.7481        0.5375       0.7273        0.6128  0.0198\n",
      "     89      0.7308    0.6491        0.5158       0.6694        0.5866  0.0200\n",
      "     90      0.7198    0.6970        0.5362       0.6694        0.6263  0.0197\n",
      "     91      0.7483    0.6949        0.5172       0.7025        0.5555  0.0196\n",
      "     92      0.7120    0.7500        0.5300       0.7355        0.5836  0.0197\n",
      "     93      0.7633    0.6549        0.5130       0.6777        0.5612  0.0198\n",
      "     94      0.7007    0.7218        0.5171       0.6942        0.6485  0.0203\n",
      "     95      0.7602    0.6549        0.5056       0.6777        0.5710  0.0205\n",
      "     96      0.7218    0.6772        0.5282       0.6612        0.6122  0.0204\n",
      "     97      0.7467    0.6612        0.5053       0.6612        0.5824  0.0200\n",
      "     98      0.7163    0.6891        0.5281       0.6942        0.5701  0.0222\n",
      "     99      0.7556    0.6825        \u001b[35m0.4763\u001b[0m       0.6694        0.6177  0.0213\n",
      "    100      0.7661    0.6557        0.5120       0.6529        0.5789  0.0256\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6152\u001b[0m    \u001b[32m0.6250\u001b[0m        \u001b[35m0.7187\u001b[0m       \u001b[31m0.4545\u001b[0m        \u001b[94m0.7023\u001b[0m  0.0190\n",
      "      2      0.5687    0.2687        \u001b[35m0.6847\u001b[0m       \u001b[31m0.5950\u001b[0m        \u001b[94m0.6768\u001b[0m  0.0198\n",
      "      3      0.5095    0.5094        \u001b[35m0.6760\u001b[0m       0.5702        0.6782  0.0200\n",
      "      4      0.5917    0.5370        \u001b[35m0.6594\u001b[0m       0.5868        0.6770  0.0196\n",
      "      5      \u001b[36m0.6366\u001b[0m    0.5517        \u001b[35m0.6528\u001b[0m       0.5702        \u001b[94m0.6676\u001b[0m  0.0198\n",
      "      6      0.5972    0.4270        \u001b[35m0.6448\u001b[0m       0.5785        0.6734  0.0194\n",
      "      7      0.4899    0.4222        0.6511       0.5702        0.6676  0.0191\n",
      "      8      0.5736    0.4255        \u001b[35m0.6420\u001b[0m       0.5537        0.6699  0.0200\n",
      "      9      0.6000    0.4902        \u001b[35m0.6349\u001b[0m       0.5702        0.6688  0.0193\n",
      "     10      0.6143    0.4898        0.6396       0.5868        0.6703  0.0202\n",
      "     11      0.5654    0.4091        \u001b[35m0.6248\u001b[0m       0.5702        0.6719  0.0197\n",
      "     12      0.5707    0.4854        0.6345       0.5620        \u001b[94m0.6657\u001b[0m  0.0200\n",
      "     13      0.6259    0.4706        \u001b[35m0.6233\u001b[0m       0.5537        0.6826  0.0200\n",
      "     14      0.6256    0.4762        \u001b[35m0.6221\u001b[0m       0.5455        0.6677  0.0197\n",
      "     15      0.6215    0.4848        0.6296       0.5785        0.6734  0.0198\n",
      "     16      0.5909    0.4706        0.6303       0.5537        0.6722  0.0198\n",
      "     17      0.6029    0.4600        \u001b[35m0.6142\u001b[0m       0.5537        0.6800  0.0198\n",
      "     18      0.6147    0.4694        0.6484       0.5702        0.6671  0.0239\n",
      "     19      0.5479    0.4186        0.6328       0.5868        \u001b[94m0.6575\u001b[0m  0.0195\n",
      "     20      0.5644    0.4694        0.6336       0.5702        0.6584  0.0196\n",
      "     21      0.6005    0.4660        0.6225       0.5455        0.6712  0.0195\n",
      "     22      \u001b[36m0.6384\u001b[0m    0.4717        0.6402       0.5372        0.6690  0.0198\n",
      "     23      0.5848    0.4800        0.6371       0.5702        0.6613  0.0200\n",
      "     24      0.5985    0.4468        0.6174       0.5702        0.6754  0.0197\n",
      "     25      0.6131    0.4660        0.6404       0.5455        0.6599  0.0198\n",
      "     26      0.5922    0.4468        0.6156       0.5702        0.6634  0.0207\n",
      "     27      0.6223    0.4706        0.6173       0.5537        0.6592  0.0222\n",
      "     28      0.6276    0.4660        \u001b[35m0.5907\u001b[0m       0.5455        0.6670  0.0218\n",
      "     29      \u001b[36m0.6723\u001b[0m    0.4471        0.6212       \u001b[31m0.6116\u001b[0m        \u001b[94m0.6516\u001b[0m  0.0222\n",
      "     30      0.6221    0.5455        0.6044       0.5868        \u001b[94m0.6382\u001b[0m  0.0219\n",
      "     31      0.6548    0.5102        0.5987       0.6033        0.6644  0.0220\n",
      "     32      \u001b[36m0.6749\u001b[0m    0.5200        0.6266       0.6033        \u001b[94m0.6263\u001b[0m  0.0219\n",
      "     33      0.5777    0.5487        0.6185       0.5785        0.6388  0.0217\n",
      "     34      \u001b[36m0.6966\u001b[0m    0.4946        0.5936       0.6116        0.6866  0.0218\n",
      "     35      0.6585    0.5200        0.6104       0.6033        0.6361  0.0218\n",
      "     36      0.6416    0.4944        \u001b[35m0.5902\u001b[0m       \u001b[31m0.6281\u001b[0m        0.6310  0.0265\n",
      "     37      0.6571    0.5591        \u001b[35m0.5891\u001b[0m       \u001b[31m0.6612\u001b[0m        \u001b[94m0.6091\u001b[0m  0.0220\n",
      "     38      0.6729    0.4938        \u001b[35m0.5674\u001b[0m       0.6612        0.6138  0.0222\n",
      "     39      0.6586    0.5882        0.5978       0.6529        \u001b[94m0.6007\u001b[0m  0.0222\n",
      "     40      0.6462    0.5872        \u001b[35m0.5663\u001b[0m       0.6281        0.6184  0.0214\n",
      "     41      \u001b[36m0.7016\u001b[0m    0.4872        \u001b[35m0.5633\u001b[0m       \u001b[31m0.6694\u001b[0m        0.6419  0.0218\n",
      "     42      0.6082    \u001b[32m0.6481\u001b[0m        0.5998       \u001b[31m0.6860\u001b[0m        \u001b[94m0.5900\u001b[0m  0.0216\n",
      "     43      0.6765    0.6400        \u001b[35m0.5449\u001b[0m       \u001b[31m0.7025\u001b[0m        \u001b[94m0.5751\u001b[0m  0.0217\n",
      "     44      \u001b[36m0.7182\u001b[0m    0.5682        \u001b[35m0.5349\u001b[0m       0.6860        0.5982  0.0214\n",
      "     45      0.6764    0.5000        0.5475       0.6694        0.5815  0.0210\n",
      "     46      0.6633    0.6346        0.5626       0.6860        0.5816  0.0219\n",
      "     47      0.7009    0.6214        0.5493       0.6777        0.5861  0.0200\n",
      "     48      \u001b[36m0.7319\u001b[0m    0.6186        \u001b[35m0.5298\u001b[0m       0.6942        0.5868  0.0221\n",
      "     49      0.7159    \u001b[32m0.6531\u001b[0m        0.5469       \u001b[31m0.7190\u001b[0m        \u001b[94m0.5647\u001b[0m  0.0223\n",
      "     50      0.7172    0.6304        0.5351       0.7190        0.6212  0.0212\n",
      "     51      0.7126    \u001b[32m0.7115\u001b[0m        0.5524       \u001b[31m0.7521\u001b[0m        0.5697  0.0217\n",
      "     52      0.7220    0.6200        \u001b[35m0.5252\u001b[0m       0.6860        0.5937  0.0215\n",
      "     53      \u001b[36m0.7385\u001b[0m    0.6022        0.5347       0.6942        0.5997  0.0281\n",
      "     54      0.7129    0.6863        \u001b[35m0.5119\u001b[0m       0.7355        \u001b[94m0.5548\u001b[0m  0.0222\n",
      "     55      \u001b[36m0.7400\u001b[0m    0.6990        \u001b[35m0.4937\u001b[0m       0.7438        0.5835  0.0201\n",
      "     56      0.6998    0.5610        0.5275       0.7025        0.5873  0.0199\n",
      "     57      0.6486    0.6731        0.5156       0.7190        0.5769  0.0204\n",
      "     58      0.7282    0.6535        0.5402       0.7107        0.5825  0.0220\n",
      "     59      0.7236    0.5517        0.5156       0.6777        0.6145  0.0217\n",
      "     60      0.7084    0.6337        0.5475       0.6942        0.5781  0.0220\n",
      "     61      0.7268    0.5714        \u001b[35m0.4813\u001b[0m       0.6529        0.6195  0.0271\n",
      "     62      \u001b[36m0.7471\u001b[0m    0.6383        0.4974       0.7190        0.6052  0.0219\n",
      "     63      0.7211    0.6087        0.5088       0.7025        0.6027  0.0219\n",
      "     64      0.7168    0.6667        0.5235       0.7273        0.5696  0.0220\n",
      "     65      0.7404    0.6990        0.4888       0.7438        0.5721  0.0215\n",
      "     66      0.7395    0.6465        0.5065       0.7107        0.6397  0.0204\n",
      "     67      0.7352    0.6458        0.5051       0.7190        0.6647  0.0205\n",
      "     68      0.7113    0.7018        0.5531       0.7190        0.5724  0.0204\n",
      "     69      0.7177    0.6327        0.5095       0.7025        0.5941  0.0242\n",
      "     70      \u001b[36m0.7472\u001b[0m    0.6400        0.5205       0.7025        0.5671  0.0201\n",
      "     71      \u001b[36m0.7543\u001b[0m    0.7027        \u001b[35m0.4500\u001b[0m       0.7273        0.5712  0.0205\n",
      "     72      0.7527    0.6122        0.5081       0.6860        0.6408  0.0208\n",
      "     73      0.7529    0.6729        0.4835       0.7107        0.6148  0.0206\n",
      "     74      \u001b[36m0.7660\u001b[0m    0.6863        0.4762       0.7355        0.6036  0.0202\n",
      "     75      0.7426    0.6667        0.4769       0.7355        0.6075  0.0201\n",
      "     76      0.7571    0.6847        0.4753       0.7107        0.6018  0.0197\n",
      "     77      0.7471    0.6731        0.4758       0.7190        0.6027  0.0204\n",
      "     78      0.7658    0.6316        0.4626       0.7107        0.5959  0.0203\n",
      "     79      0.7385    0.6792        0.5202       0.7190        0.5625  0.0199\n",
      "     80      0.7390    0.6122        0.4768       0.6860        0.6295  0.0199\n",
      "     81      0.7446    0.6667        0.4728       0.6860        0.5907  0.0199\n",
      "     82      0.7323    0.5618        0.5041       0.6777        0.6504  0.0212\n",
      "     83      0.7512    0.6863        0.5014       0.7355        0.5557  0.0205\n",
      "     84      0.7470    0.6526        0.4849       0.7273        0.6036  0.0193\n",
      "     85      0.7506    0.6792        0.4581       0.7190        0.6039  0.0192\n",
      "     86      \u001b[36m0.7810\u001b[0m    0.6400        0.4651       0.7025        0.5961  0.0257\n",
      "     87      0.7709    0.5287        0.4836       0.6612        0.6409  0.0221\n",
      "     88      0.6961    0.6607        0.5214       0.6860        0.5867  0.0220\n",
      "     89      0.7527    0.5934        0.5172       0.6942        0.5950  0.0203\n",
      "     90      0.6810    0.6733        0.5026       0.7273        0.5695  0.0199\n",
      "     91      0.7422    0.6600        0.4657       0.7190        0.5847  0.0201\n",
      "     92      0.7543    0.6392        0.4648       0.7107        0.5896  0.0200\n",
      "     93      0.7518    0.5517        \u001b[35m0.4411\u001b[0m       0.6777        0.6288  0.0211\n",
      "     94      0.7136    0.6022        0.4738       0.6942        0.5939  0.0252\n",
      "     95      0.7470    0.5618        0.4692       0.6777        0.6409  0.0224\n",
      "     96      0.7300    0.6304        0.4553       0.7190        0.6536  0.0219\n",
      "     97      0.7363    0.6042        0.4897       0.6860        0.6455  0.0255\n",
      "     98      0.7594    0.6415        0.4532       0.6860        0.6546  0.0307\n",
      "     99      0.7623    0.6538        0.4672       0.7025        0.6548  0.0266\n",
      "    100      0.7800    0.6535        0.4642       0.7107        0.6088  0.0309\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6301\u001b[0m    \u001b[32m0.2524\u001b[0m        \u001b[35m0.7195\u001b[0m       \u001b[31m0.3636\u001b[0m        \u001b[94m0.7079\u001b[0m  0.0192\n",
      "      2      0.5952    \u001b[32m0.6480\u001b[0m        \u001b[35m0.7032\u001b[0m       \u001b[31m0.4793\u001b[0m        \u001b[94m0.6770\u001b[0m  0.0203\n",
      "      3      0.5904    0.5688        \u001b[35m0.6497\u001b[0m       \u001b[31m0.6116\u001b[0m        \u001b[94m0.6383\u001b[0m  0.0244\n",
      "      4      0.5985    0.6480        0.6992       0.4793        0.6842  0.0295\n",
      "      5      \u001b[36m0.6528\u001b[0m    \u001b[32m0.6497\u001b[0m        0.6805       0.5455        0.6754  0.0336\n",
      "      6      0.6395    0.5347        0.6638       0.6116        0.6515  0.0321\n",
      "      7      0.5368    0.5106        0.6509       \u001b[31m0.6198\u001b[0m        0.6505  0.0273\n",
      "      8      0.5146    0.5536        0.6764       0.5868        0.6617  0.0256\n",
      "      9      0.6223    0.6290        0.6679       0.6198        0.6588  0.0203\n",
      "     10      0.6137    0.5472        0.6500       0.6033        0.6477  0.0235\n",
      "     11      0.5564    0.4946        0.6512       0.6116        0.6466  0.0203\n",
      "     12      0.5477    0.6230        0.6670       0.6198        0.6592  0.0200\n",
      "     13      0.6047    0.4946        0.6706       0.6116        0.6640  0.0199\n",
      "     14      0.5112    0.5000        0.6627       \u001b[31m0.6364\u001b[0m        0.6600  0.0199\n",
      "     15      0.5397    0.5614        0.6545       0.5868        0.6483  0.0196\n",
      "     16      0.6005    0.5370        0.6520       0.5868        0.6468  0.0230\n",
      "     17      0.5941    0.5234        0.6510       0.5785        0.6484  0.0197\n",
      "     18      0.5962    0.6102        0.6512       0.6198        0.6478  0.0196\n",
      "     19      0.5777    0.4948        0.6523       0.5950        0.6478  0.0202\n",
      "     20      0.6009    \u001b[32m0.6562\u001b[0m        0.6566       0.6364        0.6494  0.0219\n",
      "     21      0.6083    0.5766        \u001b[35m0.6459\u001b[0m       0.6116        0.6468  0.0208\n",
      "     22      0.6019    0.5932        \u001b[35m0.6416\u001b[0m       0.6033        0.6411  0.0239\n",
      "     23      0.6435    0.6071        0.6548       0.6364        \u001b[94m0.6355\u001b[0m  0.0199\n",
      "     24      0.5755    0.5965        \u001b[35m0.6387\u001b[0m       0.6198        0.6403  0.0253\n",
      "     25      0.6239    0.6087        0.6467       0.6281        0.6433  0.0294\n",
      "     26      0.5980    0.5636        0.6426       0.6033        0.6487  0.0270\n",
      "     27      0.6364    0.5893        0.6547       0.6198        0.6390  0.0300\n",
      "     28      0.5678    0.6126        0.6543       \u001b[31m0.6446\u001b[0m        0.6375  0.0316\n",
      "     29      0.6181    \u001b[32m0.6667\u001b[0m        0.6527       \u001b[31m0.6612\u001b[0m        \u001b[94m0.6346\u001b[0m  0.0243\n",
      "     30      0.6038    0.5600        0.6444       0.6364        0.6376  0.0297\n",
      "     31      0.5995    0.6179        0.6672       0.6116        0.6477  0.0299\n",
      "     32      0.6267    0.5743        0.6509       0.6446        0.6595  0.0253\n",
      "     33      0.5692    0.5849        0.6472       0.6364        0.6439  0.0316\n",
      "     34      0.6167    0.5946        0.6427       0.6281        0.6348  0.0218\n",
      "     35      0.6024    0.5517        \u001b[35m0.6327\u001b[0m       0.5702        0.6533  0.0215\n",
      "     36      0.6211    0.5893        0.6370       0.6198        \u001b[94m0.6337\u001b[0m  0.0217\n",
      "     37      0.6277    \u001b[32m0.6667\u001b[0m        0.6445       \u001b[31m0.6694\u001b[0m        \u001b[94m0.6172\u001b[0m  0.0197\n",
      "     38      0.6197    0.6111        \u001b[35m0.6256\u001b[0m       0.6529        0.6199  0.0209\n",
      "     39      0.6298    0.5739        \u001b[35m0.6244\u001b[0m       0.5950        0.6410  0.0290\n",
      "     40      0.6484    0.5833        \u001b[35m0.6032\u001b[0m       0.6694        0.6265  0.0205\n",
      "     41      0.6311    0.6542        0.6386       \u001b[31m0.6942\u001b[0m        \u001b[94m0.6159\u001b[0m  0.0206\n",
      "     42      0.6055    0.6606        0.6263       0.6942        \u001b[94m0.6077\u001b[0m  0.0250\n",
      "     43      0.6355    0.6476        0.6092       0.6942        0.6174  0.0303\n",
      "     44      \u001b[36m0.6652\u001b[0m    0.5957        0.6405       0.6860        0.6159  0.0311\n",
      "     45      0.5311    0.6055        0.6261       0.6446        \u001b[94m0.6064\u001b[0m  0.0300\n",
      "     46      \u001b[36m0.6837\u001b[0m    0.6429        0.6162       0.6694        \u001b[94m0.5958\u001b[0m  0.0290\n",
      "     47      0.6333    0.6667        0.6252       0.6942        0.6044  0.0463\n",
      "     48      0.6812    0.6476        0.6159       0.6942        0.6030  0.0296\n",
      "     49      0.6146    0.6296        0.6146       0.6694        0.6086  0.0251\n",
      "     50      0.6486    0.6535        \u001b[35m0.6018\u001b[0m       \u001b[31m0.7107\u001b[0m        0.6003  0.0272\n",
      "     51      0.6633    0.6471        \u001b[35m0.5772\u001b[0m       0.7025        \u001b[94m0.5840\u001b[0m  0.0220\n",
      "     52      0.6306    \u001b[32m0.6792\u001b[0m        0.6104       \u001b[31m0.7190\u001b[0m        \u001b[94m0.5778\u001b[0m  0.0225\n",
      "     53      0.6492    \u001b[32m0.6829\u001b[0m        0.6122       0.6777        0.6012  0.0218\n",
      "     54      \u001b[36m0.7048\u001b[0m    0.6465        \u001b[35m0.5723\u001b[0m       0.7107        0.5877  0.0277\n",
      "     55      0.6841    0.6452        0.5903       \u001b[31m0.7273\u001b[0m        \u001b[94m0.5693\u001b[0m  0.0223\n",
      "     56      0.5745    \u001b[32m0.7241\u001b[0m        0.5855       \u001b[31m0.7355\u001b[0m        \u001b[94m0.5597\u001b[0m  0.0336\n",
      "     57      0.6996    0.6990        0.5812       \u001b[31m0.7438\u001b[0m        0.5617  0.0224\n",
      "     58      0.6878    0.7077        0.6070       0.6860        0.5795  0.0237\n",
      "     59      \u001b[36m0.7195\u001b[0m    0.7170        \u001b[35m0.5540\u001b[0m       \u001b[31m0.7521\u001b[0m        0.5620  0.0268\n",
      "     60      0.6725    0.6383        0.5839       0.7190        0.5815  0.0221\n",
      "     61      0.6747    0.6724        0.5833       0.6860        0.5607  0.0221\n",
      "     62      0.6651    0.7048        0.5632       0.7438        \u001b[94m0.5526\u001b[0m  0.0221\n",
      "     63      0.6932    0.7048        \u001b[35m0.5495\u001b[0m       0.7438        \u001b[94m0.5408\u001b[0m  0.0213\n",
      "     64      0.6953    0.7176        0.5886       0.6942        0.5629  0.0199\n",
      "     65      \u001b[36m0.7227\u001b[0m    0.7103        \u001b[35m0.5379\u001b[0m       0.7438        \u001b[94m0.5319\u001b[0m  0.0198\n",
      "     66      0.6943    0.7241        0.5753       0.7355        \u001b[94m0.5253\u001b[0m  0.0209\n",
      "     67      0.6965    0.7103        0.5515       0.7438        0.5505  0.0196\n",
      "     68      0.7080    0.6964        0.5383       0.7190        0.5559  0.0206\n",
      "     69      \u001b[36m0.7339\u001b[0m    0.6792        0.5609       0.7190        0.5648  0.0219\n",
      "     70      0.7123    \u001b[32m0.7304\u001b[0m        0.5494       0.7438        0.5674  0.0246\n",
      "     71      \u001b[36m0.7505\u001b[0m    0.7130        \u001b[35m0.5202\u001b[0m       0.7273        0.5313  0.0219\n",
      "     72      0.7195    \u001b[32m0.7407\u001b[0m        0.5519       \u001b[31m0.7686\u001b[0m        \u001b[94m0.5106\u001b[0m  0.0209\n",
      "     73      0.6862    \u001b[32m0.7634\u001b[0m        0.5888       0.7438        0.5618  0.0217\n",
      "     74      0.7251    0.6400        0.5637       0.7025        0.5637  0.0196\n",
      "     75      0.6938    0.6847        0.5494       0.7107        0.5466  0.0217\n",
      "     76      0.7252    0.7027        0.5265       0.7273        0.5439  0.0215\n",
      "     77      0.7002    0.7143        0.5471       0.7025        0.5535  0.0196\n",
      "     78      0.6953    0.6949        0.5418       0.7025        0.5371  0.0195\n",
      "     79      0.6911    0.6726        0.5529       0.6942        0.5413  0.0193\n",
      "     80      0.7133    0.6964        0.5395       0.7190        0.5306  0.0194\n",
      "     81      0.6911    0.7183        0.5656       0.6694        0.5546  0.0191\n",
      "     82      0.7479    0.7048        0.5327       0.7438        0.5169  0.0195\n",
      "     83      0.7225    0.6903        0.5598       0.7107        0.5208  0.0193\n",
      "     84      0.7031    0.6838        0.5432       0.6942        0.5514  0.0193\n",
      "     85      0.7333    0.7213        0.5652       0.7190        0.5365  0.0195\n",
      "     86      0.7361    0.7130        0.5320       0.7273        0.5292  0.0195\n",
      "     87      0.7074    0.7143        0.5709       0.7355        0.5219  0.0193\n",
      "     88      0.7309    0.7193        0.5296       0.7355        0.5146  0.0197\n",
      "     89      0.7273    0.7222        0.5252       0.7521        \u001b[94m0.5067\u001b[0m  0.0192\n",
      "     90      0.7427    0.7333        0.5249       0.7355        0.5357  0.0219\n",
      "     91      \u001b[36m0.7511\u001b[0m    0.7339        \u001b[35m0.5017\u001b[0m       0.7603        0.5235  0.0204\n",
      "     92      0.7426    0.7304        0.5045       0.7438        0.5283  0.0198\n",
      "     93      0.7159    0.7257        0.5190       0.7438        0.5310  0.0195\n",
      "     94      0.7377    0.7193        0.5349       0.7355        0.5333  0.0197\n",
      "     95      \u001b[36m0.7588\u001b[0m    0.7167        0.5313       0.7190        0.5356  0.0203\n",
      "     96      0.7368    0.7156        \u001b[35m0.4924\u001b[0m       0.7438        0.5179  0.0207\n",
      "     97      0.7449    0.7333        0.5038       0.7355        0.5239  0.0218\n",
      "     98      0.7537    0.7179        0.5152       0.7273        0.5287  0.0221\n",
      "     99      0.7226    0.7455        0.5136       0.7686        0.5372  0.0217\n",
      "    100      0.7411    0.7407        0.5311       0.7686        0.5287  0.0193\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6585\u001b[0m    \u001b[32m0.5347\u001b[0m        \u001b[35m0.6844\u001b[0m       \u001b[31m0.6116\u001b[0m        \u001b[94m0.6711\u001b[0m  0.0190\n",
      "      2      0.4352    \u001b[32m0.6452\u001b[0m        0.6943       \u001b[31m0.6364\u001b[0m        \u001b[94m0.6637\u001b[0m  0.0195\n",
      "      3      0.5318    0.5319        \u001b[35m0.6736\u001b[0m       0.6364        \u001b[94m0.6573\u001b[0m  0.0199\n",
      "      4      0.4525    0.5872        \u001b[35m0.6635\u001b[0m       0.6281        \u001b[94m0.6520\u001b[0m  0.0197\n",
      "      5      0.4987    0.5319        0.6705       0.6364        \u001b[94m0.6518\u001b[0m  0.0199\n",
      "      6      0.4556    0.5631        0.6667       0.6281        0.6521  0.0195\n",
      "      7      0.5133    0.5983        0.6663       0.6116        \u001b[94m0.6508\u001b[0m  0.0194\n",
      "      8      0.5053    0.4368        0.6687       0.5950        0.6519  0.0196\n",
      "      9      0.4211    0.5657        0.6663       \u001b[31m0.6446\u001b[0m        \u001b[94m0.6498\u001b[0m  0.0216\n",
      "     10      0.4632    0.5510        0.6712       0.6364        0.6518  0.0199\n",
      "     11      0.5000    0.5686        \u001b[35m0.6563\u001b[0m       0.6364        \u001b[94m0.6484\u001b[0m  0.0194\n",
      "     12      0.4637    0.5319        0.6610       0.6364        \u001b[94m0.6462\u001b[0m  0.0195\n",
      "     13      0.4327    0.4889        0.6710       0.6198        0.6501  0.0195\n",
      "     14      0.4576    0.5600        0.6583       0.6364        0.6479  0.0200\n",
      "     15      0.4809    0.5455        0.6629       0.6281        \u001b[94m0.6446\u001b[0m  0.0196\n",
      "     16      0.5056    0.5510        0.6589       0.6364        \u001b[94m0.6434\u001b[0m  0.0199\n",
      "     17      0.4811    0.6435        0.6633       \u001b[31m0.6612\u001b[0m        \u001b[94m0.6416\u001b[0m  0.0194\n",
      "     18      0.5235    0.5400        \u001b[35m0.6508\u001b[0m       0.6198        0.6424  0.0193\n",
      "     19      0.4903    0.6207        0.6542       0.6364        0.6452  0.0194\n",
      "     20      0.5317    0.5306        0.6544       0.6198        0.6475  0.0196\n",
      "     21      0.5127    0.6179        \u001b[35m0.6491\u001b[0m       0.6116        0.6459  0.0194\n",
      "     22      0.5517    0.5437        0.6578       0.6116        0.6437  0.0194\n",
      "     23      0.5013    0.5794        \u001b[35m0.6471\u001b[0m       0.6281        0.6441  0.0191\n",
      "     24      0.5271    0.3951        \u001b[35m0.6375\u001b[0m       0.5950        0.6684  0.0193\n",
      "     25      0.5296    0.6377        0.6508       0.5868        0.6417  0.0192\n",
      "     26      0.5687    0.4944        0.6414       0.6281        0.6425  0.0220\n",
      "     27      0.5620    0.5294        \u001b[35m0.6327\u001b[0m       0.6033        0.6438  0.0216\n",
      "     28      0.5721    0.6418        \u001b[35m0.6312\u001b[0m       0.6033        0.6431  0.0216\n",
      "     29      0.6014    0.6261        \u001b[35m0.6301\u001b[0m       0.6446        \u001b[94m0.6274\u001b[0m  0.0209\n",
      "     30      0.6126    \u001b[32m0.6923\u001b[0m        0.6447       \u001b[31m0.6694\u001b[0m        0.6303  0.0211\n",
      "     31      0.5873    0.5743        0.6351       0.6446        0.6298  0.0215\n",
      "     32      0.6005    0.6923        \u001b[35m0.6239\u001b[0m       0.6694        0.6299  0.0215\n",
      "     33      0.6435    0.5217        \u001b[35m0.6035\u001b[0m       0.6364        0.6548  0.0215\n",
      "     34      0.6052    \u001b[32m0.7042\u001b[0m        0.6675       0.6529        0.6365  0.0216\n",
      "     35      0.6127    0.4819        0.6284       0.6446        \u001b[94m0.6270\u001b[0m  0.0211\n",
      "     36      0.5606    0.6769        0.6095       0.6529        \u001b[94m0.6257\u001b[0m  0.0194\n",
      "     37      \u001b[36m0.6765\u001b[0m    0.7000        \u001b[35m0.6005\u001b[0m       \u001b[31m0.7025\u001b[0m        \u001b[94m0.6176\u001b[0m  0.0193\n",
      "     38      \u001b[36m0.6794\u001b[0m    0.6602        0.6190       \u001b[31m0.7107\u001b[0m        \u001b[94m0.6025\u001b[0m  0.0197\n",
      "     39      0.5649    \u001b[32m0.7049\u001b[0m        0.6024       0.7025        \u001b[94m0.5913\u001b[0m  0.0219\n",
      "     40      \u001b[36m0.6908\u001b[0m    0.6942        \u001b[35m0.5854\u001b[0m       0.6942        0.6056  0.0221\n",
      "     41      0.6694    0.6942        0.5911       0.6942        0.5968  0.0193\n",
      "     42      0.6000    \u001b[32m0.7143\u001b[0m        0.6279       0.7025        0.5952  0.0193\n",
      "     43      0.6492    0.6250        0.6027       0.7025        0.5916  0.0198\n",
      "     44      0.6265    0.6838        0.6041       0.6942        \u001b[94m0.5777\u001b[0m  0.0195\n",
      "     45      0.6071    0.6857        0.5968       \u001b[31m0.7273\u001b[0m        0.5851  0.0193\n",
      "     46      0.6578    0.6897        \u001b[35m0.5756\u001b[0m       0.7025        0.5845  0.0194\n",
      "     47      0.6498    0.7049        0.5825       0.7025        0.5836  0.0218\n",
      "     48      \u001b[36m0.7061\u001b[0m    0.6909        0.5815       0.7190        \u001b[94m0.5756\u001b[0m  0.0199\n",
      "     49      0.6652    0.7111        0.5855       0.6777        0.6087  0.0323\n",
      "     50      0.6588    0.5957        0.5883       0.6860        0.5951  0.0330\n",
      "     51      0.6593    \u001b[32m0.7273\u001b[0m        0.6062       0.7025        0.5865  0.0354\n",
      "     52      0.6572    0.6476        \u001b[35m0.5622\u001b[0m       0.6942        0.5874  0.0427\n",
      "     53      0.6911    0.6909        \u001b[35m0.5539\u001b[0m       0.7190        0.5929  0.0340\n",
      "     54      0.6508    0.7007        0.5985       0.6612        0.5961  0.0340\n",
      "     55      \u001b[36m0.7352\u001b[0m    0.7222        \u001b[35m0.5485\u001b[0m       \u001b[31m0.7521\u001b[0m        \u001b[94m0.5636\u001b[0m  0.0340\n",
      "     56      0.6800    0.7231        0.5837       0.7025        0.5842  0.0221\n",
      "     57      0.6898    0.7257        \u001b[35m0.5442\u001b[0m       0.7438        \u001b[94m0.5568\u001b[0m  0.0213\n",
      "     58      \u001b[36m0.7395\u001b[0m    0.7241        \u001b[35m0.5376\u001b[0m       0.7355        0.5595  0.0219\n",
      "     59      0.6828    \u001b[32m0.7480\u001b[0m        0.5625       0.7438        0.5675  0.0217\n",
      "     60      0.6963    0.6604        0.5413       0.7025        0.5582  0.0216\n",
      "     61      0.7015    0.7288        0.5596       0.7355        \u001b[94m0.5459\u001b[0m  0.0216\n",
      "     62      0.7059    0.7273        0.5479       0.7273        0.5786  0.0210\n",
      "     63      0.7289    0.7227        \u001b[35m0.5309\u001b[0m       0.7273        0.5846  0.0198\n",
      "     64      0.6345    0.6957        0.5626       0.7107        0.5917  0.0219\n",
      "     65      0.6882    0.7091        0.5418       0.7355        0.5561  0.0220\n",
      "     66      0.6946    0.7040        0.5655       0.6942        0.5780  0.0246\n",
      "     67      0.7375    0.6604        \u001b[35m0.5177\u001b[0m       0.7025        0.5693  0.0218\n",
      "     68      0.6955    0.7156        0.5450       0.7438        0.5612  0.0220\n",
      "     69      0.5753    0.7119        0.5635       0.7190        0.5603  0.0220\n",
      "     70      \u001b[36m0.7447\u001b[0m    0.7143        0.5351       0.7355        0.5565  0.0203\n",
      "     71      0.7166    0.7167        0.5335       0.7190        0.5913  0.0197\n",
      "     72      0.6918    0.6847        0.5279       0.7107        0.5499  0.0196\n",
      "     73      0.6955    0.7040        0.5406       0.6942        0.5778  0.0197\n",
      "     74      0.7421    0.7119        \u001b[35m0.5127\u001b[0m       0.7190        0.5812  0.0196\n",
      "     75      0.7364    0.7179        \u001b[35m0.5101\u001b[0m       0.7273        0.5652  0.0194\n",
      "     76      0.7119    0.7429        0.5312       0.7025        0.6512  0.0195\n",
      "     77      \u001b[36m0.7676\u001b[0m    0.7048        0.5108       0.7438        0.5507  0.0195\n",
      "     78      0.7335    0.7385        0.5284       0.7190        0.6258  0.0195\n",
      "     79      0.7243    0.6667        0.5416       0.6942        0.5501  0.0197\n",
      "     80      0.7250    0.7258        0.5122       0.7190        0.5674  0.0196\n",
      "     81      0.7339    0.7154        0.5155       0.7107        0.5696  0.0196\n",
      "     82      0.7527    0.6842        \u001b[35m0.4823\u001b[0m       0.7025        0.5478  0.0195\n",
      "     83      0.7318    0.7419        0.4997       0.7355        0.5841  0.0194\n",
      "     84      0.7333    0.7333        0.5004       0.7355        \u001b[94m0.5442\u001b[0m  0.0194\n",
      "     85      0.7401    0.6984        0.5191       0.6860        0.5764  0.0194\n",
      "     86      0.7289    0.6880        0.4856       0.6777        0.5839  0.0198\n",
      "     87      0.7631    0.6833        0.4859       0.6860        0.5894  0.0196\n",
      "     88      \u001b[36m0.7719\u001b[0m    0.6949        \u001b[35m0.4673\u001b[0m       0.7025        0.6049  0.0209\n",
      "     89      0.6972    0.7368        0.5327       0.7107        0.6319  0.0305\n",
      "     90      0.7330    0.6783        0.5012       0.6942        0.5559  0.0324\n",
      "     91      0.7330    \u001b[32m0.7519\u001b[0m        0.5023       0.7273        0.5858  0.0321\n",
      "     92      0.7505    0.7000        0.5277       0.7025        0.5542  0.0321\n",
      "     93      0.7407    0.7317        0.5261       0.7273        0.5578  0.0313\n",
      "     94      0.7420    0.7167        0.5193       0.7190        0.5484  0.0302\n",
      "     95      0.7516    0.6789        0.4923       0.7107        \u001b[94m0.5319\u001b[0m  0.0281\n",
      "     96      0.7257    0.6847        0.5021       0.7107        0.5410  0.0211\n",
      "     97      0.7371    0.7402        0.5018       0.7273        0.6059  0.0204\n",
      "     98      0.7113    0.7241        0.5554       0.7355        0.5389  0.0201\n",
      "     99      0.7689    0.7288        0.4731       0.7355        0.5404  0.0205\n",
      "    100      0.7290    \u001b[32m0.7581\u001b[0m        0.4952       0.7521        0.5853  0.0198\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6149\u001b[0m    \u001b[32m0.4615\u001b[0m        \u001b[35m0.6960\u001b[0m       \u001b[31m0.5950\u001b[0m        \u001b[94m0.6752\u001b[0m  0.0177\n",
      "      2      0.4151    0.4500        \u001b[35m0.6766\u001b[0m       \u001b[31m0.6364\u001b[0m        \u001b[94m0.6715\u001b[0m  0.0255\n",
      "      3      0.3754    \u001b[32m0.4706\u001b[0m        \u001b[35m0.6555\u001b[0m       0.6281        \u001b[94m0.6660\u001b[0m  0.0189\n",
      "      4      0.5426    0.4494        \u001b[35m0.6494\u001b[0m       0.5950        0.6743  0.0190\n",
      "      5      0.4076    0.3143        \u001b[35m0.6491\u001b[0m       0.6033        0.6747  0.0186\n",
      "      6      0.3754    0.4286        \u001b[35m0.6489\u001b[0m       0.6033        0.6669  0.0189\n",
      "      7      0.5028    0.4091        \u001b[35m0.6459\u001b[0m       0.5702        0.6781  0.0184\n",
      "      8      0.5185    0.4468        \u001b[35m0.6271\u001b[0m       0.5702        0.6744  0.0182\n",
      "      9      0.5835    0.4694        0.6426       0.5702        \u001b[94m0.6653\u001b[0m  0.0213\n",
      "     10      0.5399    0.4235        0.6285       0.5950        0.6763  0.0201\n",
      "     11      0.5337    \u001b[32m0.4800\u001b[0m        0.6312       0.5702        0.6725  0.0185\n",
      "     12      0.5764    0.4554        \u001b[35m0.6233\u001b[0m       0.5455        0.6758  0.0174\n",
      "     13      0.5678    0.4490        0.6339       0.5537        0.6700  0.0214\n",
      "     14      0.6019    0.4490        0.6261       0.5537        0.6712  0.0187\n",
      "     15      0.5374    0.4091        0.6421       0.5702        0.6673  0.0188\n",
      "     16      0.5367    0.4694        0.6320       0.5702        \u001b[94m0.6603\u001b[0m  0.0184\n",
      "     17      0.5911    0.4706        0.6314       0.5537        0.6686  0.0185\n",
      "     18      0.6095    0.4255        0.6334       0.5537        0.6667  0.0215\n",
      "     19      0.5497    0.4348        0.6274       0.5702        0.6672  0.0210\n",
      "     20      0.6025    0.4444        \u001b[35m0.6136\u001b[0m       0.5868        0.6888  0.0213\n",
      "     21      0.6127    0.4742        0.6179       0.5785        0.6686  0.0213\n",
      "     22      \u001b[36m0.6189\u001b[0m    0.4494        0.6294       0.5950        0.6707  0.0196\n",
      "     23      \u001b[36m0.6207\u001b[0m    0.4583        0.6320       0.5702        0.6695  0.0178\n",
      "     24      0.5865    0.4516        0.6265       0.5785        0.6831  0.0180\n",
      "     25      0.6093    \u001b[32m0.4952\u001b[0m        0.6364       0.5620        0.6619  0.0181\n",
      "     26      0.6000    0.4632        0.6147       0.5785        \u001b[94m0.6585\u001b[0m  0.0184\n",
      "     27      0.6067    0.4773        \u001b[35m0.6101\u001b[0m       0.6198        0.6789  0.0207\n",
      "     28      \u001b[36m0.6271\u001b[0m    \u001b[32m0.5179\u001b[0m        0.6266       0.5537        \u001b[94m0.6573\u001b[0m  0.0211\n",
      "     29      0.6098    0.4646        \u001b[35m0.6062\u001b[0m       0.5620        \u001b[94m0.6547\u001b[0m  0.0184\n",
      "     30      0.6190    0.5094        0.6123       0.5702        0.6566  0.0181\n",
      "     31      0.6217    0.5000        0.6082       0.5537        \u001b[94m0.6540\u001b[0m  0.0180\n",
      "     32      0.6036    0.4651        \u001b[35m0.6040\u001b[0m       0.6198        \u001b[94m0.6538\u001b[0m  0.0191\n",
      "     33      \u001b[36m0.6515\u001b[0m    0.4773        0.6092       0.6198        \u001b[94m0.6493\u001b[0m  0.0210\n",
      "     34      0.6336    \u001b[32m0.5490\u001b[0m        0.6127       0.6198        \u001b[94m0.6394\u001b[0m  0.0192\n",
      "     35      \u001b[36m0.6553\u001b[0m    0.5098        \u001b[35m0.5878\u001b[0m       0.5868        \u001b[94m0.6333\u001b[0m  0.0200\n",
      "     36      \u001b[36m0.6609\u001b[0m    0.5208        0.5978       0.6198        0.6364  0.0197\n",
      "     37      0.6050    \u001b[32m0.6034\u001b[0m        0.6232       0.6198        \u001b[94m0.6286\u001b[0m  0.0214\n",
      "     38      \u001b[36m0.6682\u001b[0m    0.4944        \u001b[35m0.5876\u001b[0m       0.6281        0.6360  0.0212\n",
      "     39      0.6388    0.5926        0.6026       0.6364        0.6287  0.0211\n",
      "     40      \u001b[36m0.6743\u001b[0m    0.2899        \u001b[35m0.5676\u001b[0m       0.5950        0.6650  0.0210\n",
      "     41      0.6247    0.5577        0.5933       0.6198        0.6349  0.0204\n",
      "     42      \u001b[36m0.6861\u001b[0m    \u001b[32m0.6271\u001b[0m        0.5841       0.6364        \u001b[94m0.6173\u001b[0m  0.0208\n",
      "     43      \u001b[36m0.6949\u001b[0m    0.5957        0.5850       \u001b[31m0.6860\u001b[0m        0.6203  0.0208\n",
      "     44      0.6818    0.5934        0.5954       \u001b[31m0.6942\u001b[0m        0.6241  0.0208\n",
      "     45      0.6319    \u001b[32m0.6557\u001b[0m        0.5793       0.6529        0.6217  0.0198\n",
      "     46      \u001b[36m0.6953\u001b[0m    0.5818        0.6005       0.6198        0.6386  0.0194\n",
      "     47      0.6837    0.6355        0.5866       0.6777        \u001b[94m0.6025\u001b[0m  0.0308\n",
      "     48      \u001b[36m0.7013\u001b[0m    0.5981        0.5868       0.6446        0.6075  0.0214\n",
      "     49      0.6838    0.6207        \u001b[35m0.5634\u001b[0m       0.6364        0.6228  0.0211\n",
      "     50      0.6959    0.5057        \u001b[35m0.5613\u001b[0m       0.6446        0.6230  0.0195\n",
      "     51      0.6952    0.5895        0.6016       0.6777        \u001b[94m0.5950\u001b[0m  0.0178\n",
      "     52      0.6753    0.6476        \u001b[35m0.5517\u001b[0m       0.6942        0.6021  0.0176\n",
      "     53      0.6907    0.6186        0.5797       0.6942        0.6027  0.0179\n",
      "     54      0.6864    \u001b[32m0.6727\u001b[0m        0.5538       \u001b[31m0.7025\u001b[0m        \u001b[94m0.5813\u001b[0m  0.0175\n",
      "     55      \u001b[36m0.7156\u001b[0m    \u001b[32m0.6735\u001b[0m        0.5589       \u001b[31m0.7355\u001b[0m        0.5894  0.0175\n",
      "     56      0.6803    0.5495        0.5821       0.6612        0.6068  0.0175\n",
      "     57      0.6799    0.6606        \u001b[35m0.5299\u001b[0m       0.6942        0.5979  0.0174\n",
      "     58      0.7082    0.5682        0.5563       0.6860        0.6408  0.0173\n",
      "     59      0.6869    \u001b[32m0.6903\u001b[0m        0.5588       0.7107        0.5902  0.0173\n",
      "     60      0.7149    0.5376        0.5799       0.6446        0.6088  0.0177\n",
      "     61      0.6942    0.6263        0.5565       0.6942        0.5921  0.0176\n",
      "     62      \u001b[36m0.7202\u001b[0m    0.6200        0.5521       0.6860        0.6074  0.0177\n",
      "     63      0.7064    0.6789        0.5645       0.7107        0.5876  0.0176\n",
      "     64      \u001b[36m0.7237\u001b[0m    0.6105        0.5517       0.6942        0.6203  0.0176\n",
      "     65      0.7215    0.6111        0.5629       0.6529        0.6039  0.0179\n",
      "     66      0.6986    0.5412        0.5485       0.6777        0.6386  0.0175\n",
      "     67      0.6735    0.6481        0.5583       0.6860        0.5904  0.0179\n",
      "     68      0.7156    0.5957        0.5519       0.6860        0.6065  0.0176\n",
      "     69      0.6837    \u001b[32m0.7143\u001b[0m        0.5496       0.7355        \u001b[94m0.5757\u001b[0m  0.0178\n",
      "     70      \u001b[36m0.7411\u001b[0m    0.6422        0.5324       0.6777        0.6114  0.0179\n",
      "     71      0.7136    0.6942        0.5450       0.6942        0.5799  0.0196\n",
      "     72      \u001b[36m0.7505\u001b[0m    0.4691        \u001b[35m0.5291\u001b[0m       0.6446        0.6212  0.0332\n",
      "     73      0.6801    0.6727        0.5385       0.7025        0.5911  0.0336\n",
      "     74      0.7156    0.5682        \u001b[35m0.5270\u001b[0m       0.6860        0.6171  0.0438\n",
      "     75      0.7281    0.7130        \u001b[35m0.5268\u001b[0m       0.7273        0.5834  0.0363\n",
      "     76      0.7380    0.7037        0.5277       0.7355        0.5770  0.0381\n",
      "     77      0.7380    0.5934        \u001b[35m0.5144\u001b[0m       0.6942        \u001b[94m0.5735\u001b[0m  0.0345\n",
      "     78      0.7116    0.6392        0.5343       0.7107        0.5746  0.0449\n",
      "     79      0.7212    0.6408        0.5175       0.6942        0.5799  0.0337\n",
      "     80      0.7329    0.5747        0.5698       0.6942        0.5979  0.0328\n",
      "     81      0.5723    0.5778        0.5725       0.6860        0.5905  0.0235\n",
      "     82      0.7111    0.6481        0.5535       0.6860        0.5781  0.0185\n",
      "     83      0.7156    0.5979        0.5415       0.6777        0.6155  0.0179\n",
      "     84      0.7327    0.6465        \u001b[35m0.5097\u001b[0m       0.7107        \u001b[94m0.5557\u001b[0m  0.0183\n",
      "     85      0.7308    0.6237        \u001b[35m0.5022\u001b[0m       0.7107        0.5582  0.0184\n",
      "     86      0.7239    0.5778        0.5339       0.6860        0.5876  0.0185\n",
      "     87      0.6505    0.5591        0.5501       0.6612        0.5903  0.0185\n",
      "     88      0.7007    0.6408        0.5344       0.6942        0.5668  0.0185\n",
      "     89      0.7187    0.6667        0.5079       0.7273        0.5841  0.0239\n",
      "     90      0.7109    0.6383        0.5476       0.7190        0.5812  0.0209\n",
      "     91      0.6839    0.6796        0.5177       0.7273        0.5777  0.0209\n",
      "     92      \u001b[36m0.7506\u001b[0m    0.6923        \u001b[35m0.4972\u001b[0m       0.7355        0.5885  0.0184\n",
      "     93      0.7460    0.6733        0.5190       0.7273        0.5960  0.0182\n",
      "     94      0.7409    0.6981        0.5064       0.7355        \u001b[94m0.5516\u001b[0m  0.0206\n",
      "     95      0.7366    0.6800        0.5253       0.7355        0.5603  0.0196\n",
      "     96      0.7193    \u001b[32m0.7327\u001b[0m        0.5175       \u001b[31m0.7769\u001b[0m        \u001b[94m0.5513\u001b[0m  0.0194\n",
      "     97      0.7356    0.7290        0.5015       0.7603        \u001b[94m0.5205\u001b[0m  0.0189\n",
      "     98      0.7404    0.6392        \u001b[35m0.4861\u001b[0m       0.7107        0.5624  0.0189\n",
      "     99      0.7225    0.5870        0.5164       0.6860        0.5943  0.0184\n",
      "    100      0.7100    0.6731        0.5448       0.7190        0.5851  0.0192\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6351\u001b[0m    \u001b[32m0.0000\u001b[0m        \u001b[35m0.6928\u001b[0m       \u001b[31m0.5207\u001b[0m        \u001b[94m0.7020\u001b[0m  0.0183\n",
      "      2      0.5318    \u001b[32m0.6387\u001b[0m        0.6929       \u001b[31m0.6446\u001b[0m        \u001b[94m0.6633\u001b[0m  0.0187\n",
      "      3      0.5939    0.5102        \u001b[35m0.6645\u001b[0m       0.6033        \u001b[94m0.6567\u001b[0m  0.0200\n",
      "      4      0.4558    0.5055        \u001b[35m0.6618\u001b[0m       0.6281        0.6585  0.0324\n",
      "      5      0.5172    0.6290        0.6633       0.6198        \u001b[94m0.6440\u001b[0m  0.0272\n",
      "      6      0.6122    0.5200        \u001b[35m0.6543\u001b[0m       0.6033        0.6494  0.0338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7      0.5105    0.5200        0.6673       0.6033        0.6479  0.0316\n",
      "      8      0.5610    0.5490        0.6646       0.6198        0.6470  0.0309\n",
      "      9      0.5581    0.4946        0.6565       0.6116        0.6544  0.0237\n",
      "     10      0.5181    0.5200        \u001b[35m0.6516\u001b[0m       0.6033        0.6493  0.0293\n",
      "     11      0.5375    0.5586        0.6554       0.5950        \u001b[94m0.6396\u001b[0m  0.0290\n",
      "     12      0.6063    0.5347        0.6557       0.6116        0.6430  0.0350\n",
      "     13      0.5590    0.5400        \u001b[35m0.6472\u001b[0m       0.6198        0.6403  0.0302\n",
      "     14      0.5904    0.5893        0.6521       0.6198        \u001b[94m0.6352\u001b[0m  0.0207\n",
      "     15      0.5707    0.5370        0.6523       0.5868        0.6417  0.0203\n",
      "     16      0.6055    0.5333        0.6581       0.5950        0.6482  0.0183\n",
      "     17      0.5735    0.5818        0.6591       0.6198        0.6393  0.0184\n",
      "     18      0.5919    0.5607        0.6530       0.6116        0.6353  0.0182\n",
      "     19      0.5972    0.5741        \u001b[35m0.6406\u001b[0m       0.6198        0.6362  0.0184\n",
      "     20      0.6075    0.5577        0.6515       0.6198        0.6403  0.0177\n",
      "     21      0.6064    0.5385        0.6503       0.6033        0.6402  0.0179\n",
      "     22      0.5919    0.5946        0.6457       0.6281        \u001b[94m0.6326\u001b[0m  0.0180\n",
      "     23      0.6032    0.6034        0.6560       0.6198        0.6371  0.0178\n",
      "     24      0.6275    0.5607        0.6434       0.6116        0.6389  0.0182\n",
      "     25      0.6079    0.6071        \u001b[35m0.6374\u001b[0m       0.6364        \u001b[94m0.6230\u001b[0m  0.0240\n",
      "     26      0.5947    0.5636        0.6442       0.6033        0.6410  0.0205\n",
      "     27      0.5962    0.5472        \u001b[35m0.6352\u001b[0m       0.6033        0.6326  0.0204\n",
      "     28      \u001b[36m0.6395\u001b[0m    \u001b[32m0.6552\u001b[0m        0.6409       \u001b[31m0.6694\u001b[0m        \u001b[94m0.6175\u001b[0m  0.0204\n",
      "     29      0.6136    0.5657        \u001b[35m0.6347\u001b[0m       0.6446        \u001b[94m0.6170\u001b[0m  0.0185\n",
      "     30      0.5707    0.5818        0.6460       0.6198        0.6251  0.0187\n",
      "     31      0.6202    0.5556        \u001b[35m0.6320\u001b[0m       0.6694        0.6263  0.0184\n",
      "     32      0.5877    0.6549        0.6453       \u001b[31m0.6777\u001b[0m        \u001b[94m0.5943\u001b[0m  0.0184\n",
      "     33      0.6157    0.6168        \u001b[35m0.6221\u001b[0m       0.6612        0.6254  0.0181\n",
      "     34      \u001b[36m0.6679\u001b[0m    \u001b[32m0.7059\u001b[0m        0.6659       0.6694        0.6166  0.0182\n",
      "     35      0.6286    0.5287        0.6335       0.6612        0.6154  0.0183\n",
      "     36      0.6062    \u001b[32m0.7143\u001b[0m        0.6483       \u001b[31m0.7025\u001b[0m        \u001b[94m0.5939\u001b[0m  0.0182\n",
      "     37      0.6667    0.5941        \u001b[35m0.6117\u001b[0m       0.6612        0.6013  0.0181\n",
      "     38      0.6245    0.7121        0.6388       0.6860        0.6001  0.0184\n",
      "     39      0.6395    0.6038        \u001b[35m0.6070\u001b[0m       0.6529        0.5954  0.0182\n",
      "     40      0.6281    \u001b[32m0.7154\u001b[0m        0.6259       \u001b[31m0.7107\u001b[0m        \u001b[94m0.5848\u001b[0m  0.0183\n",
      "     41      0.6636    0.6408        \u001b[35m0.5892\u001b[0m       0.6942        \u001b[94m0.5808\u001b[0m  0.0182\n",
      "     42      0.6386    \u001b[32m0.7368\u001b[0m        0.6136       0.7107        0.5867  0.0183\n",
      "     43      \u001b[36m0.6739\u001b[0m    0.6327        \u001b[35m0.5834\u001b[0m       0.7025        \u001b[94m0.5784\u001b[0m  0.0184\n",
      "     44      \u001b[36m0.6839\u001b[0m    0.7037        0.5958       \u001b[31m0.7355\u001b[0m        \u001b[94m0.5636\u001b[0m  0.0183\n",
      "     45      0.6471    \u001b[32m0.7419\u001b[0m        0.5927       0.7355        \u001b[94m0.5562\u001b[0m  0.0183\n",
      "     46      \u001b[36m0.7028\u001b[0m    0.7103        \u001b[35m0.5785\u001b[0m       \u001b[31m0.7438\u001b[0m        \u001b[94m0.5328\u001b[0m  0.0182\n",
      "     47      0.6454    \u001b[32m0.7500\u001b[0m        0.6047       \u001b[31m0.7521\u001b[0m        0.5648  0.0184\n",
      "     48      0.6838    0.7130        0.6105       0.7273        0.5683  0.0182\n",
      "     49      0.6799    0.6729        0.5971       0.7107        0.5612  0.0186\n",
      "     50      0.6580    0.6984        0.5801       0.6860        0.5528  0.0184\n",
      "     51      \u001b[36m0.7074\u001b[0m    0.7414        \u001b[35m0.5675\u001b[0m       0.7521        0.5448  0.0183\n",
      "     52      \u001b[36m0.7207\u001b[0m    0.6400        0.5747       0.7025        0.5527  0.0181\n",
      "     53      0.6294    0.6880        0.5912       0.6777        0.5496  0.0183\n",
      "     54      0.6698    0.6733        0.5834       0.7273        0.5686  0.0181\n",
      "     55      0.6881    0.7200        0.5928       0.7107        0.5649  0.0183\n",
      "     56      0.7022    0.6667        \u001b[35m0.5595\u001b[0m       0.7025        0.5454  0.0181\n",
      "     57      0.6964    0.6847        0.5617       0.7107        \u001b[94m0.5323\u001b[0m  0.0177\n",
      "     58      0.6882    0.7377        0.5890       0.7355        0.5495  0.0180\n",
      "     59      0.6951    0.6606        0.5772       0.6942        0.5667  0.0178\n",
      "     60      0.6709    0.7077        0.6012       0.6860        0.5661  0.0181\n",
      "     61      0.7137    0.6721        0.5652       0.6694        0.5488  0.0183\n",
      "     62      \u001b[36m0.7307\u001b[0m    0.6972        \u001b[35m0.5588\u001b[0m       0.7273        0.5395  0.0186\n",
      "     63      \u001b[36m0.7478\u001b[0m    0.6721        \u001b[35m0.5564\u001b[0m       0.6694        0.5567  0.0186\n",
      "     64      0.7273    0.6552        \u001b[35m0.5488\u001b[0m       0.6694        0.5552  0.0183\n",
      "     65      0.7120    0.7077        0.5577       0.6860        0.5487  0.0181\n",
      "     66      \u001b[36m0.7537\u001b[0m    0.7317        \u001b[35m0.5352\u001b[0m       0.7273        \u001b[94m0.5272\u001b[0m  0.0181\n",
      "     67      0.7327    0.7080        0.5555       0.7273        0.5369  0.0180\n",
      "     68      0.6971    0.6786        0.5873       0.7025        0.5654  0.0180\n",
      "     69      0.6833    0.6847        0.5897       0.7107        0.5600  0.0180\n",
      "     70      0.7054    0.7288        0.5506       0.7355        0.5452  0.0179\n",
      "     71      0.6943    0.7321        0.6104       0.7521        0.5652  0.0176\n",
      "     72      0.6810    0.6735        0.5703       0.7355        0.5731  0.0182\n",
      "     73      0.7137    \u001b[32m0.7520\u001b[0m        0.5779       0.7438        0.5420  0.0199\n",
      "     74      0.7056    0.7071        0.5358       \u001b[31m0.7603\u001b[0m        0.5414  0.0198\n",
      "     75      0.7089    0.7360        0.5754       0.7273        0.5431  0.0208\n",
      "     76      0.7086    0.6733        \u001b[35m0.5349\u001b[0m       0.7273        0.5303  0.0204\n",
      "     77      0.7067    0.7350        0.5578       0.7438        \u001b[94m0.5232\u001b[0m  0.0207\n",
      "     78      0.7467    0.7143        0.5549       0.7355        0.5261  0.0195\n",
      "     79      0.7153    0.6838        0.5599       0.6942        0.5510  0.0184\n",
      "     80      0.6993    0.6942        0.5616       0.6942        0.5458  0.0186\n",
      "     81      0.7245    0.7213        0.5360       0.7190        0.5326  0.0187\n",
      "     82      0.7158    0.6842        \u001b[35m0.5334\u001b[0m       0.7025        0.5424  0.0294\n",
      "     83      \u001b[36m0.7538\u001b[0m    0.7059        0.5370       0.7107        0.5340  0.0276\n",
      "     84      0.7241    0.6838        0.5703       0.6942        0.5369  0.0435\n",
      "     85      0.7005    0.7321        0.5563       0.7521        0.5301  0.0356\n",
      "     86      0.7146    0.7385        0.5485       0.7190        0.5348  0.0328\n",
      "     87      0.7389    0.6847        0.5425       0.7107        0.5437  0.0334\n",
      "     88      0.7248    0.7009        0.5441       0.7107        0.5560  0.0335\n",
      "     89      0.6903    0.6392        0.5371       0.7107        0.5458  0.0432\n",
      "     90      0.6794    0.7350        0.5465       0.7438        0.5307  0.0338\n",
      "     91      0.7526    0.7027        \u001b[35m0.5227\u001b[0m       0.7273        0.5384  0.0318\n",
      "     92      0.7130    0.7143        0.5497       0.7355        0.5355  0.0364\n",
      "     93      0.7253    0.7130        0.5242       0.7273        0.5299  0.0298\n",
      "     94      0.7191    0.7414        0.5307       0.7521        \u001b[94m0.5141\u001b[0m  0.0186\n",
      "     95      0.7341    \u001b[32m0.7705\u001b[0m        \u001b[35m0.4999\u001b[0m       \u001b[31m0.7686\u001b[0m        \u001b[94m0.5123\u001b[0m  0.0197\n",
      "     96      0.7531    0.7027        0.5121       0.7273        0.5268  0.0212\n",
      "     97      0.7252    0.7244        0.5299       0.7107        0.5362  0.0192\n",
      "     98      \u001b[36m0.7588\u001b[0m    0.7414        0.5313       0.7521        0.5136  0.0215\n",
      "     99      0.6916    \u001b[32m0.7769\u001b[0m        0.5368       \u001b[31m0.7769\u001b[0m        \u001b[94m0.5106\u001b[0m  0.0184\n",
      "    100      0.7446    0.7395        0.5464       0.7438        \u001b[94m0.5068\u001b[0m  0.0187\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6124\u001b[0m    \u001b[32m0.4471\u001b[0m        \u001b[35m0.7021\u001b[0m       \u001b[31m0.6116\u001b[0m        \u001b[94m0.6629\u001b[0m  0.0205\n",
      "      2      0.5590    \u001b[32m0.4615\u001b[0m        \u001b[35m0.6791\u001b[0m       0.5950        \u001b[94m0.6595\u001b[0m  0.0215\n",
      "      3      0.5086    \u001b[32m0.5417\u001b[0m        \u001b[35m0.6705\u001b[0m       \u001b[31m0.6364\u001b[0m        \u001b[94m0.6550\u001b[0m  0.0207\n",
      "      4      0.4953    \u001b[32m0.5490\u001b[0m        0.6757       0.6198        0.6575  0.0251\n",
      "      5      0.5226    0.4651        0.6742       0.6198        0.6604  0.0221\n",
      "      6      0.5204    0.4524        \u001b[35m0.6653\u001b[0m       0.6198        \u001b[94m0.6540\u001b[0m  0.0228\n",
      "      7      0.4824    0.4651        0.6674       0.6198        \u001b[94m0.6524\u001b[0m  0.0259\n",
      "      8      0.4693    0.4545        \u001b[35m0.6611\u001b[0m       0.6033        0.6526  0.0213\n",
      "      9      0.5106    0.3750        \u001b[35m0.6601\u001b[0m       0.5868        0.6547  0.0214\n",
      "     10      0.4586    0.5376        0.6732       \u001b[31m0.6446\u001b[0m        0.6525  0.0265\n",
      "     11      0.5136    0.5417        0.6640       0.6364        \u001b[94m0.6517\u001b[0m  0.0326\n",
      "     12      0.4961    0.3750        \u001b[35m0.6544\u001b[0m       0.5868        \u001b[94m0.6512\u001b[0m  0.0322\n",
      "     13      0.4802    0.5217        0.6602       0.6364        \u001b[94m0.6507\u001b[0m  0.0356\n",
      "     14      0.5136    0.5417        0.6673       0.6364        0.6524  0.0247\n",
      "     15      0.5481    \u001b[32m0.5600\u001b[0m        \u001b[35m0.6489\u001b[0m       0.6364        \u001b[94m0.6461\u001b[0m  0.0179\n",
      "     16      0.5239    \u001b[32m0.5714\u001b[0m        \u001b[35m0.6480\u001b[0m       \u001b[31m0.6529\u001b[0m        \u001b[94m0.6441\u001b[0m  0.0253\n",
      "     17      0.5667    \u001b[32m0.6239\u001b[0m        0.6534       \u001b[31m0.6612\u001b[0m        \u001b[94m0.6395\u001b[0m  0.0329\n",
      "     18      0.5480    0.5859        \u001b[35m0.6478\u001b[0m       0.6612        0.6396  0.0315\n",
      "     19      0.5409    0.5333        0.6523       0.6529        \u001b[94m0.6386\u001b[0m  0.0468\n",
      "     20      0.5521    0.6087        0.6526       0.6281        0.6394  0.0380\n",
      "     21      \u001b[36m0.6217\u001b[0m    \u001b[32m0.6422\u001b[0m        \u001b[35m0.6355\u001b[0m       \u001b[31m0.6777\u001b[0m        \u001b[94m0.6232\u001b[0m  0.0441\n",
      "     22      0.5874    0.6422        \u001b[35m0.6323\u001b[0m       0.6777        \u001b[94m0.6188\u001b[0m  0.0237\n",
      "     23      0.6085    \u001b[32m0.6481\u001b[0m        0.6401       \u001b[31m0.6860\u001b[0m        \u001b[94m0.6173\u001b[0m  0.0210\n",
      "     24      0.5783    \u001b[32m0.6842\u001b[0m        \u001b[35m0.6285\u001b[0m       \u001b[31m0.7025\u001b[0m        \u001b[94m0.6163\u001b[0m  0.0213\n",
      "     25      \u001b[36m0.6253\u001b[0m    \u001b[32m0.7059\u001b[0m        0.6343       \u001b[31m0.7107\u001b[0m        \u001b[94m0.6110\u001b[0m  0.0218\n",
      "     26      \u001b[36m0.6681\u001b[0m    0.6906        \u001b[35m0.6011\u001b[0m       0.6446        0.6129  0.0327\n",
      "     27      \u001b[36m0.6965\u001b[0m    0.6667        0.6054       0.7107        \u001b[94m0.5928\u001b[0m  0.0286\n",
      "     28      0.6612    0.6863        0.6260       \u001b[31m0.7355\u001b[0m        0.5981  0.0335\n",
      "     29      0.5312    0.6731        0.6408       0.7190        0.6184  0.0324\n",
      "     30      0.6722    0.7000        0.6046       0.7025        0.6081  0.0207\n",
      "     31      0.6411    \u001b[32m0.7107\u001b[0m        0.6150       0.7107        \u001b[94m0.5909\u001b[0m  0.0204\n",
      "     32      0.6861    \u001b[32m0.7143\u001b[0m        \u001b[35m0.5833\u001b[0m       0.7355        \u001b[94m0.5803\u001b[0m  0.0210\n",
      "     33      0.6751    \u001b[32m0.7273\u001b[0m        0.6118       0.7273        0.5807  0.0262\n",
      "     34      0.6928    0.7241        \u001b[35m0.5636\u001b[0m       0.7355        \u001b[94m0.5739\u001b[0m  0.0206\n",
      "     35      \u001b[36m0.7109\u001b[0m    0.6667        0.5729       0.7273        0.5772  0.0184\n",
      "     36      0.6742    0.7049        0.5951       0.7025        0.5770  0.0185\n",
      "     37      \u001b[36m0.7253\u001b[0m    0.6729        0.5695       0.7107        \u001b[94m0.5621\u001b[0m  0.0238\n",
      "     38      0.7155    0.7258        0.5728       0.7190        0.5637  0.0193\n",
      "     39      0.6442    0.7227        0.5831       0.7273        0.5642  0.0189\n",
      "     40      \u001b[36m0.7465\u001b[0m    0.7231        \u001b[35m0.5373\u001b[0m       0.7025        0.5920  0.0232\n",
      "     41      0.6913    \u001b[32m0.7333\u001b[0m        0.5920       0.7355        \u001b[94m0.5591\u001b[0m  0.0216\n",
      "     42      0.7292    0.6903        0.5747       0.7107        0.5659  0.0211\n",
      "     43      0.6774    0.7304        0.5704       \u001b[31m0.7438\u001b[0m        \u001b[94m0.5550\u001b[0m  0.0211\n",
      "     44      0.6985    \u001b[32m0.7414\u001b[0m        0.5476       \u001b[31m0.7521\u001b[0m        0.5609  0.0209\n",
      "     45      0.7391    0.7179        \u001b[35m0.5244\u001b[0m       0.7273        0.5715  0.0210\n",
      "     46      0.7124    0.7360        0.5598       0.7273        0.5621  0.0213\n",
      "     47      0.7293    0.6667        0.5397       0.7190        0.5652  0.0216\n",
      "     48      0.7000    \u001b[32m0.7556\u001b[0m        0.5752       0.7273        0.5757  0.0217\n",
      "     49      \u001b[36m0.7511\u001b[0m    0.7222        0.5508       0.7521        \u001b[94m0.5374\u001b[0m  0.0187\n",
      "     50      0.7177    0.7538        0.5439       0.7355        0.5532  0.0212\n",
      "     51      0.7120    0.7156        0.5626       0.7438        0.5451  0.0220\n",
      "     52      0.6895    0.7000        0.5774       0.7025        0.5697  0.0317\n",
      "     53      0.6701    0.7027        0.5609       0.7273        0.5680  0.0220\n",
      "     54      0.7339    0.6789        0.5452       0.7107        0.5753  0.0216\n",
      "     55      0.6682    0.7360        0.5448       0.7273        0.5883  0.0187\n",
      "     56      0.7399    0.6792        \u001b[35m0.5195\u001b[0m       0.7190        0.5801  0.0186\n",
      "     57      0.7225    0.6963        0.5655       0.6612        0.5864  0.0191\n",
      "     58      0.7293    0.7018        0.5553       0.7190        0.5573  0.0188\n",
      "     59      0.6951    0.7077        0.5657       0.6860        0.5696  0.0213\n",
      "     60      0.7221    0.6909        0.5467       0.7190        0.5500  0.0216\n",
      "     61      0.7297    0.7273        0.5447       0.7273        0.5606  0.0201\n",
      "     62      0.7390    0.6724        0.5210       0.6860        0.5635  0.0191\n",
      "     63      0.7056    0.6667        0.5348       0.6694        0.5734  0.0208\n",
      "     64      0.7454    0.7069        \u001b[35m0.5131\u001b[0m       0.7190        0.5770  0.0214\n",
      "     65      0.7265    0.6957        0.5135       0.7107        0.5616  0.0216\n",
      "     66      0.7442    0.7258        0.5370       0.7190        0.5693  0.0213\n",
      "     67      \u001b[36m0.7556\u001b[0m    0.7069        \u001b[35m0.5125\u001b[0m       0.7190        0.5750  0.0216\n",
      "     68      0.7244    0.7227        0.5225       0.7273        0.5660  0.0210\n",
      "     69      \u001b[36m0.7588\u001b[0m    0.7027        \u001b[35m0.4922\u001b[0m       0.7273        0.5651  0.0210\n",
      "     70      0.7139    0.6833        0.5082       0.6860        0.6167  0.0212\n",
      "     71      0.7233    0.6250        0.5289       0.6529        0.5722  0.0210\n",
      "     72      0.7309    0.7328        0.5292       0.7107        0.5720  0.0185\n",
      "     73      \u001b[36m0.7596\u001b[0m    0.6557        0.5012       0.6529        0.5578  0.0186\n",
      "     74      0.7394    0.6719        0.5012       0.6529        0.5919  0.0186\n",
      "     75      0.7253    0.6880        0.5293       0.6777        0.5844  0.0224\n",
      "     76      0.7416    0.7287        0.5393       0.7107        0.5704  0.0204\n",
      "     77      \u001b[36m0.7702\u001b[0m    0.7040        0.5056       0.6942        0.5838  0.0179\n",
      "     78      0.7467    0.6949        0.5226       0.7025        0.5884  0.0182\n",
      "     79      0.7269    0.6774        0.5087       0.6694        0.5742  0.0186\n",
      "     80      \u001b[36m0.7793\u001b[0m    0.6723        0.5036       0.6777        0.5885  0.0189\n",
      "     81      0.7558    0.6667        \u001b[35m0.4767\u001b[0m       0.6942        0.5841  0.0178\n",
      "     82      0.6917    0.7302        0.5324       0.7190        0.6056  0.0180\n",
      "     83      0.7213    0.6957        0.5300       0.7107        0.5538  0.0184\n",
      "     84      0.7211    0.7333        0.5393       0.7355        \u001b[94m0.5318\u001b[0m  0.0186\n",
      "     85      0.7442    0.7328        0.5331       0.7107        0.5600  0.0207\n",
      "     86      0.7629    0.6667        0.4823       0.6860        0.5694  0.0182\n",
      "     87      0.7354    0.6721        0.5259       0.6694        0.5969  0.0193\n",
      "     88      0.7268    0.6774        0.5203       0.6694        0.5856  0.0178\n",
      "     89      0.7588    0.6949        0.4988       0.7025        0.5529  0.0216\n",
      "     90      0.7335    0.7143        0.5430       0.7025        0.5486  0.0272\n",
      "     91      0.7426    0.7244        0.5179       0.7107        0.5615  0.0215\n",
      "     92      0.7661    0.6825        0.4915       0.6694        0.5739  0.0208\n",
      "     93      0.7383    0.7176        0.4914       0.6942        0.5964  0.0202\n",
      "     94      0.7338    0.6780        0.5297       0.6860        0.5837  0.0255\n",
      "     95      0.7269    0.6325        0.5352       0.6446        0.5850  0.0182\n",
      "     96      0.7371    0.7023        0.5189       0.6777        0.5675  0.0180\n",
      "     97      0.7769    0.6929        0.4931       0.6777        0.5583  0.0181\n",
      "     98      0.7215    \u001b[32m0.7597\u001b[0m        0.5395       0.7438        0.5363  0.0180\n",
      "     99      0.7564    0.6833        0.5044       0.6860        0.5463  0.0202\n",
      "    100      0.7494    0.7200        0.5050       0.7107        0.5751  0.0202\n",
      "  epoch    f1_train    f1_val    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------  --------  ------------  -----------  ------------  ------\n",
      "      1      \u001b[36m0.6308\u001b[0m    \u001b[32m0.0230\u001b[0m        \u001b[35m0.7158\u001b[0m       \u001b[31m0.5304\u001b[0m        \u001b[94m0.6920\u001b[0m  0.0304\n",
      "      2      0.2676    \u001b[32m0.5000\u001b[0m        \u001b[35m0.6859\u001b[0m       \u001b[31m0.5691\u001b[0m        \u001b[94m0.6743\u001b[0m  0.0297\n",
      "      3      0.5932    0.2524        \u001b[35m0.6731\u001b[0m       \u001b[31m0.5746\u001b[0m        0.6758  0.0311\n",
      "      4      0.2051    0.1837        0.6788       0.5580        0.6828  0.0323\n",
      "      5      0.2912    0.3770        0.6759       \u001b[31m0.5801\u001b[0m        \u001b[94m0.6679\u001b[0m  0.0323\n",
      "      6      0.4042    0.3419        \u001b[35m0.6619\u001b[0m       0.5746        \u001b[94m0.6646\u001b[0m  0.0296\n",
      "      7      0.3853    0.3636        0.6639       0.5746        \u001b[94m0.6625\u001b[0m  0.0280\n",
      "      8      0.4100    0.4526        \u001b[35m0.6507\u001b[0m       \u001b[31m0.5856\u001b[0m        \u001b[94m0.6620\u001b[0m  0.0358\n",
      "      9      0.5385    0.4493        0.6569       0.5801        0.6712  0.0318\n",
      "     10      0.4788    0.4478        0.6667       \u001b[31m0.5912\u001b[0m        0.6634  0.0295\n",
      "     11      0.4506    0.4444        \u001b[35m0.6496\u001b[0m       0.5856        0.6644  0.0314\n",
      "     12      0.5500    0.4122        0.6511       0.5746        0.6667  0.0317\n",
      "     13      0.4312    0.2453        0.6550       0.5580        0.6708  0.0315\n",
      "     14      0.2864    0.2752        0.6598       0.5635        0.6720  0.0474\n",
      "     15      0.5026    \u001b[32m0.5316\u001b[0m        0.6548       0.5912        0.6641  0.0491\n",
      "     16      0.5600    0.4361        \u001b[35m0.6415\u001b[0m       0.5856        0.6744  0.0495\n",
      "     17      0.3889    0.3036        0.6692       0.5691        0.6710  0.0482\n",
      "     18      0.5083    0.5283        0.6592       0.5856        0.6630  0.0467\n",
      "     19      0.5795    0.4179        0.6534       0.5691        0.6695  0.0465\n",
      "     20      0.4603    0.4966        0.6489       0.5856        0.6651  0.0450\n",
      "     21      0.5172    0.4932        0.6601       0.5912        0.6622  0.0436\n",
      "     22      0.4971    0.4361        0.6566       0.5856        0.6631  0.0294\n",
      "     23      0.5072    0.4828        0.6473       0.5856        \u001b[94m0.6606\u001b[0m  0.0322\n",
      "     24      0.5331    0.5101        0.6472       \u001b[31m0.5967\u001b[0m        0.6611  0.0284\n",
      "     25      0.5319    0.4444        0.6457       0.5856        0.6608  0.0323\n",
      "     26      0.5083    0.4638        0.6596       0.5912        \u001b[94m0.6593\u001b[0m  0.0271\n",
      "     27      0.5589    0.4604        0.6444       0.5856        0.6600  0.0266\n",
      "     28      0.5596    0.5170        0.6481       \u001b[31m0.6077\u001b[0m        \u001b[94m0.6591\u001b[0m  0.0268\n",
      "     29      0.4892    0.4526        \u001b[35m0.6395\u001b[0m       0.5856        0.6609  0.0325\n",
      "     30      0.5811    \u001b[32m0.5576\u001b[0m        0.6484       0.5967        0.6602  0.0286\n",
      "     31      0.5426    0.5478        0.6572       0.6077        \u001b[94m0.6574\u001b[0m  0.0273\n",
      "     32      0.6024    \u001b[32m0.5896\u001b[0m        0.6438       0.6077        \u001b[94m0.6516\u001b[0m  0.0276\n",
      "     33      0.5917    \u001b[32m0.6396\u001b[0m        0.6412       0.6077        \u001b[94m0.6515\u001b[0m  0.0282\n",
      "     34      \u001b[36m0.6455\u001b[0m    0.6218        \u001b[35m0.6365\u001b[0m       0.5967        \u001b[94m0.6479\u001b[0m  0.0293\n",
      "     35      \u001b[36m0.6592\u001b[0m    0.5556        \u001b[35m0.6275\u001b[0m       0.6022        0.6610  0.0311\n",
      "     36      0.6277    0.5783        0.6418       \u001b[31m0.6133\u001b[0m        \u001b[94m0.6430\u001b[0m  0.0350\n",
      "     37      0.5987    0.5443        0.6374       0.6022        \u001b[94m0.6429\u001b[0m  0.0313\n",
      "     38      0.5559    0.4923        0.6399       \u001b[31m0.6354\u001b[0m        0.6448  0.0306\n",
      "     39      0.5864    0.5605        0.6394       0.6188        \u001b[94m0.6278\u001b[0m  0.0278\n",
      "     40      0.6335    0.5789        \u001b[35m0.6211\u001b[0m       \u001b[31m0.6464\u001b[0m        \u001b[94m0.6194\u001b[0m  0.0276\n",
      "     41      0.6176    0.5468        \u001b[35m0.6191\u001b[0m       \u001b[31m0.6519\u001b[0m        0.6262  0.0284\n",
      "     42      0.6056    0.5517        0.6249       0.6409        0.6223  0.0333\n",
      "     43      0.6187    0.6081        \u001b[35m0.6047\u001b[0m       \u001b[31m0.6796\u001b[0m        \u001b[94m0.6171\u001b[0m  0.0282\n",
      "     44      0.6435    \u001b[32m0.6585\u001b[0m        0.6307       \u001b[31m0.6906\u001b[0m        \u001b[94m0.6080\u001b[0m  0.0282\n",
      "     45      \u001b[36m0.6905\u001b[0m    0.5564        \u001b[35m0.6035\u001b[0m       0.6740        0.6201  0.0296\n",
      "     46      0.6035    0.6225        0.6310       0.6851        \u001b[94m0.6019\u001b[0m  0.0323\n",
      "     47      0.6535    0.5789        \u001b[35m0.5895\u001b[0m       0.6464        0.6124  0.0274\n",
      "     48      0.6458    0.5890        0.6029       0.6685        0.6058  0.0269\n",
      "     49      0.6286    0.6194        0.6060       0.6740        0.6054  0.0272\n",
      "     50      0.6353    0.6517        0.5982       0.6575        0.6170  0.0324\n",
      "     51      0.6834    0.6509        0.6091       0.6740        0.6152  0.0284\n",
      "     52      \u001b[36m0.7015\u001b[0m    \u001b[32m0.6597\u001b[0m        0.6001       0.6409        \u001b[94m0.5904\u001b[0m  0.0282\n",
      "     53      0.7003    0.6514        \u001b[35m0.5802\u001b[0m       0.6630        \u001b[94m0.5886\u001b[0m  0.0316\n",
      "     54      0.6986    0.6543        0.5839       0.6906        \u001b[94m0.5710\u001b[0m  0.0318\n",
      "     55      0.6756    0.6303        0.5841       0.6630        0.5924  0.0303\n",
      "     56      0.6514    0.6056        0.5952       0.6906        0.6015  0.0289\n",
      "     57      0.6509    \u001b[32m0.7120\u001b[0m        0.6030       \u001b[31m0.6961\u001b[0m        0.5922  0.0272\n",
      "     58      0.6686    0.5811        \u001b[35m0.5781\u001b[0m       0.6575        0.6019  0.0270\n",
      "     59      0.6376    0.6624        0.6170       \u001b[31m0.7072\u001b[0m        0.5944  0.0273\n",
      "     60      0.6108    0.6494        0.5978       0.7017        0.5894  0.0270\n",
      "     61      0.6798    0.6301        0.5954       0.7017        0.5909  0.0272\n",
      "     62      0.3964    0.3048        0.6391       0.5967        0.6419  0.0281\n",
      "     63      0.5259    \u001b[32m0.7136\u001b[0m        0.6391       0.6630        0.6344  0.0279\n",
      "     64      0.6757    0.6486        0.6091       0.6409        0.5966  0.0312\n",
      "     65      \u001b[36m0.7067\u001b[0m    0.6228        0.5854       0.6519        0.5817  0.0320\n",
      "     66      0.6656    0.6463        \u001b[35m0.5637\u001b[0m       0.6796        0.5771  0.0318\n",
      "     67      0.6982    0.6893        0.5889       0.6961        0.5725  0.0328\n",
      "     68      \u001b[36m0.7156\u001b[0m    0.6782        \u001b[35m0.5512\u001b[0m       0.6906        \u001b[94m0.5662\u001b[0m  0.0288\n",
      "     69      0.6656    0.6867        0.5801       \u001b[31m0.7127\u001b[0m        \u001b[94m0.5652\u001b[0m  0.0314\n",
      "     70      \u001b[36m0.7242\u001b[0m    0.6538        0.5675       0.7017        0.5652  0.0325\n",
      "     71      0.6364    0.6826        0.5835       0.7072        \u001b[94m0.5631\u001b[0m  0.0317\n",
      "     72      0.7170    0.6447        0.5529       0.7017        0.5738  0.0285\n",
      "     73      0.6720    0.7047        0.5947       0.6851        0.5781  0.0288\n",
      "     74      0.7213    0.6826        0.5516       0.7072        0.5642  0.0294\n",
      "     75      0.7062    0.6447        0.5708       0.7017        0.5787  0.0288\n",
      "     76      0.6754    \u001b[32m0.7310\u001b[0m        0.5556       0.7072        0.5753  0.0287\n",
      "     77      \u001b[36m0.7365\u001b[0m    0.6194        0.5657       0.6740        0.5731  0.0299\n",
      "     78      0.6979    0.6746        0.5774       0.6961        \u001b[94m0.5559\u001b[0m  0.0325\n",
      "     79      0.6598    0.6707        0.5640       0.7017        0.5752  0.0373\n",
      "     80      0.7041    0.6456        0.5613       0.6906        0.5830  0.0292\n",
      "     81      0.5735    0.6982        0.5998       \u001b[31m0.7182\u001b[0m        0.5922  0.0291\n",
      "     82      0.7290    0.6936        0.5798       0.7072        0.5663  0.0284\n",
      "     83      0.7115    0.7120        0.5599       0.6961        0.5624  0.0291\n",
      "     84      0.7059    0.6707        0.5525       0.6961        0.5669  0.0276\n",
      "     85      0.6806    0.7136        0.5846       0.6851        0.5872  0.0305\n",
      "     86      0.7312    0.6790        0.5536       0.7127        0.5605  0.0310\n",
      "     87      0.7083    0.7000        0.5588       0.7017        0.5638  0.0315\n",
      "     88      0.7154    0.7120        \u001b[35m0.5366\u001b[0m       0.6961        0.5735  0.0317\n",
      "     89      0.7223    0.6065        0.5522       0.6630        0.5764  0.0316\n",
      "     90      0.6761    0.6467        0.5605       0.6740        0.5731  0.0367\n",
      "     91      0.6844    0.6780        0.5521       0.6851        0.5673  0.0316\n",
      "     92      \u001b[36m0.7368\u001b[0m    0.6893        \u001b[35m0.5313\u001b[0m       0.6961        0.5738  0.0300\n",
      "     93      0.7114    0.7006        0.5619       0.7072        0.5692  0.0282\n",
      "     94      0.7233    0.6369        \u001b[35m0.5274\u001b[0m       0.6851        0.5888  0.0328\n",
      "     95      0.6867    0.7273        0.5479       0.7182        0.5769  0.0367\n",
      "     96      \u001b[36m0.7410\u001b[0m    0.6463        \u001b[35m0.5232\u001b[0m       0.6796        0.5992  0.0504\n",
      "     97      0.6419    0.6885        0.6096       0.6851        0.6105  0.0560\n",
      "     98      0.6930    0.6818        0.5691       0.6906        0.5855  0.0466\n",
      "     99      0.7174    0.6456        0.5722       0.6906        0.5923  0.0492\n",
      "    100      0.6218    0.7052        0.5913       0.7182        0.5979  0.0488\n",
      "Accuracy of Net: 0.76\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.81      0.78       474\n",
      "          1       0.77      0.69      0.73       426\n",
      "\n",
      "avg / total       0.76      0.76      0.75       900\n",
      "\n",
      "Accuracy of Net: 0.74\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.82      0.77       159\n",
      "          1       0.76      0.66      0.71       138\n",
      "\n",
      "avg / total       0.75      0.74      0.74       297\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## net = None\n",
    "rs = None\n",
    "accuracy_epoch_scoring_val = EpochScoring(scoring='f1',\n",
    "                                          name='f1_val',\n",
    "                                          lower_is_better=False,\n",
    "                                          on_train=False)\n",
    "accuracy_epoch_scoring_train = EpochScoring(scoring='f1',\n",
    "                                            name='f1_train', \n",
    "                                            lower_is_better=False, \n",
    "                                            on_train=True)\n",
    "device = torch.device('cuda:0')\n",
    "n_channels = x_train.shape[1]\n",
    "n_features = x_train.shape[2]\n",
    "n_epochs = 100\n",
    "kernel_size = n_features\n",
    "padding_size = int(n_features/2)\n",
    "net = NeuralNetClassifier(module=LeNet5, criterion=nn.CrossEntropyLoss,\n",
    "                          module__n_channels= n_channels,\n",
    "                          module__n_features=n_features,\n",
    "                          module__C_k_p_s_1=[kernel_size,padding_size,1],\n",
    "                          module__M_k_s_1=[2, 2],\n",
    "                          module__M_k_s_2=[2, 2],\n",
    "                          module__C_k_p_s_2=[kernel_size,padding_size,1],\n",
    "                          module__p = [0.30357368, \n",
    "                                       0.29148488, \n",
    "                                       0.00700351, \n",
    "                                       0.37788387, \n",
    "                                       0.19788962],\n",
    "                          module__mid_layer_channels=39,\n",
    "                          optimizer=optim.Adam, \n",
    "                          optimizer__lr = 0.01,\n",
    "                          #optimizer__weight_decay=0.01,\n",
    "                          max_epochs=n_epochs, \n",
    "                          batch_size=100,\n",
    "                          iterator_train__shuffle=False,\n",
    "                          device=device,\n",
    "                          warm_start=True,#train_split=None,\n",
    "                          callbacks=[accuracy_epoch_scoring_val, \n",
    "                                     accuracy_epoch_scoring_train],\n",
    "                         )\n",
    "model_name = LeNet5.__name__\n",
    "rs = RandomizedSearchCV(net, parameters, refit=True, \n",
    "                        n_iter=5, n_jobs=1,\n",
    "                       cv=3, scoring='accuracy')\n",
    "#rs = GridSearchCV(net, parameters, n_jobs=1, refit=True, \n",
    "#                 scoring='f1', cv=3)\n",
    "rs.fit(x_train, y_train)\n",
    "model = rs.best_estimator_\n",
    "pred_test = model.predict(x_train)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_train, prefix_information=model_name,\n",
    "                          dataset_name='train', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "\n",
    "pred_test = rs.predict(x_val)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, y_val, prefix_information='RF',\n",
    "                          dataset_name='', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Net: 0.84\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88       340\n",
      "          1       0.78      0.77      0.77       182\n",
      "\n",
      "avg / total       0.84      0.84      0.84       522\n",
      "\n",
      "Accuracy of Net: 0.83\n",
      "\n",
      "Classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.87      0.87       113\n",
      "          1       0.77      0.77      0.77        64\n",
      "\n",
      "avg / total       0.83      0.83      0.83       177\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test = model.predict(x_train)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, \n",
    "                                        y_train,\n",
    "                                        prefix_information=model_name,\n",
    "                          dataset_name='train', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "plt.savefig(fname='latex/figures/' + 'AvgLenet_Training_results' + '.pdf',\n",
    "            format='pdf', dpi=300)\n",
    "\n",
    "pred_test = model.predict(x_val)  # Predict labels of test data using the trained classifier\n",
    "accuracy_of_net = plot_confusion_matrix(pred_test, \n",
    "                                        y_val, \n",
    "                                        prefix_information='RF',\n",
    "                          dataset_name='', save_results=False,\n",
    "                     y_pred_is_predicted_classes=True)\n",
    "\n",
    "plt.savefig(fname='latex/figures/' + 'AvgLenet_Test_results' + '.pdf',\n",
    "            format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'module__mid_layer_channels': 39}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.71556, std: 0.02347, params: {'module__mid_layer_channels': 48},\n",
       " mean: 0.73444, std: 0.00786, params: {'module__mid_layer_channels': 39},\n",
       " mean: 0.71333, std: 0.02373, params: {'module__mid_layer_channels': 63},\n",
       " mean: 0.73111, std: 0.00956, params: {'module__mid_layer_channels': 60},\n",
       " mean: 0.71333, std: 0.02625, params: {'module__mid_layer_channels': 29}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l7/dev/tools/anaconda3/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type AvgLeNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model_dir_path = 'models'\n",
    "model_filename = \"{:s}/{}AvgLenet-{:2.3f}_{:s}_FINAL.model\".format(\n",
    "    model_dir_path, 'yahoo_data', accuracy_of_net, strftime(\"%Y_%m_%d_%H_%M_%S\", localtime())\n",
    ")\n",
    "pickle.dump(model, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
